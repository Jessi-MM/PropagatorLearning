{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0a5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "import os\n",
    "#-----\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Enable interactive plot\n",
    "\n",
    "#%matplotlib notebook\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cd442",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c267a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propagator_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, targets, total_data = 200000, sequence_len = 5, transform=True):\n",
    "        \n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.sequence_len = sequence_len\n",
    "        self.total_data = total_data//sequence_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        total_data = self.total_data  # 200 data by file (from 0 to 199), 1000 files(from 0 to 999), total data: 200*100 = 200000\n",
    "        \n",
    "        if index > total_data:\n",
    "            print(\"Error, this data does not exist\")\n",
    "        else:\n",
    "            index_data = (index//40)%40  # because there 0-199=200 data per file / 5 = seq len \n",
    "            index_t = (index*self.sequence_len-200)%200\n",
    "            \n",
    "            X = np.empty((5,96), np.float32)\n",
    "            \n",
    "            for i in range(self.sequence_len):\n",
    "                # Input data: Wavepacket real and imaginary part + Potential at time t\n",
    "                x_r = (np.load(self.data+str(index_data)+'/Wavepacket/'+str(index_t+i)+'-wave.npy')).real\n",
    "                x_i = (np.load(self.data+str(index_data)+'/Wavepacket/'+str(index_t+i)+'-wave.npy')).imag\n",
    "                x_p = np.load(self.data+str(index_data)+'/Potential/'+str(index_t+i)+'-potential.npy')\n",
    "                \n",
    "                X[i] = np.concatenate((x_r, x_i, x_p))  # flat array form\n",
    "                \n",
    "                \n",
    "            # Output data: Wavepacket real and imaginary part at time t+1*step\n",
    "            y_r = (np.load(self.targets+str(index_data)+'/Wavepacket/'+str(index_t+self.sequence_len)+'-wave.npy')).real\n",
    "            y_i = (np.load(self.targets+str(index_data)+'/Wavepacket/'+str(index_t+self.sequence_len)+'-wave.npy')).imag\n",
    "        \n",
    "            y = np.concatenate((y_r, y_i))  # flat array form\n",
    "        \n",
    "            if self.transform:\n",
    "                X = torch.from_numpy(X)\n",
    "                y = torch.from_numpy(y)\n",
    "        \n",
    "            return X, y#[None, :]\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        return self.total_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610614ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../Data_Gaussian/data'  # Directory where are saving our data\n",
    "\n",
    "dataset = Propagator_Dataset(data=path, targets=path, transform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b4cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of data  40000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print('Total of data ', dataset_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed74e6",
   "metadata": {},
   "source": [
    "## Training and Validation data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d3e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = .1  #9:1 ratio\n",
    "shuffle_dataset = True\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aa46ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "# Creating PT data samplers and loaders: Sequential form:\n",
    "#train_sampler = SequentialSampler(train_indices)\n",
    "#test_sampler = SequentialSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab5cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of train samples: 36000\n",
      "Total of test samples: 4000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of train samples: {len(train_sampler)}\")\n",
    "print(f\"Total of test samples: {len(test_sampler)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6460ae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257dd572",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0968aa",
   "metadata": {},
   "source": [
    "## Shape of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d582d214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Shape of X in train loader: torch.Size([16, 5, 96])\n",
      "Shape of y in train loader: torch.Size([16, 64])\n",
      "Batch size: 16\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(\"Train data:\")\n",
    "    print(f\"Shape of X in train loader: {X.shape}\")\n",
    "    print(f\"Shape of y in train loader: {y.shape}\")\n",
    "    print(f\"Batch size: {X.size(0)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c532cd16",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d122a22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a random data\n",
    "for X, y in train_loader:\n",
    "    \n",
    "    X_real_vis = X[0,0,0:32]\n",
    "    X_real_vis1 = X[0,1,0:32]\n",
    "    X_real_vis2 = X[0,2,0:32]\n",
    "    X_real_vis3 = X[0,3,0:32]\n",
    "    X_real_vis4 = X[0,4,0:32]\n",
    "    \n",
    "    X_imag_vis = X[0,0,32:64]\n",
    "    X_imag_vis1 = X[0,1,32:64]\n",
    "    X_imag_vis2 = X[0,2,32:64]\n",
    "    X_imag_vis3 = X[0,3,32:64]\n",
    "    X_imag_vis4 = X[0,4,32:64]\n",
    "    \n",
    "    X_pot_vis = X[0,0,64:96]\n",
    "    X_pot_vis1 = X[0,1,64:96]\n",
    "    X_pot_vis2 = X[0,2,64:96]\n",
    "    X_pot_vis3 = X[0,3,64:96]\n",
    "    X_pot_vis4 = X[0,4,64:96]\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_real_vis = y[0,0:32]\n",
    "    y_imag_vis = y[0,32:64]\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, axs = plt.subplots(2,3)\n",
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "\n",
    "# Input: Sequence of lenght 5 fs\n",
    "axs[0,0].plot(r_n, X_pot_vis*(1/1.5936e-3), \"-\", label=\"V(r,t)\")\n",
    "axs[0,0].plot(r_n, X_real_vis*10, label=\"$\\Psi_{real}(r, t)$\")\n",
    "axs[0,0].plot(r_n, X_imag_vis*10, label=\"$\\Psi_{imag}(r, t)$\")\n",
    "axs[0,0].set_title(\"Input\")\n",
    "\n",
    "axs[0,1].plot(r_n, X_pot_vis1*(1/1.5936e-3), \"-\", label=\"V(r,t+1)\")\n",
    "axs[0,1].plot(r_n, X_real_vis1*10, label=\"$\\Psi_{real}(r, t+1)$\")\n",
    "axs[0,1].plot(r_n, X_imag_vis1*10, label=\"$\\Psi_{imag}(r, t+1)$\")\n",
    "axs[0,1].set_title(\"Input\")\n",
    "\n",
    "axs[0,2].plot(r_n, X_pot_vis2*(1/1.5936e-3), \"-\", label=\"V(r,t+2)\")\n",
    "axs[0,2].plot(r_n, X_real_vis2*10, label=\"$\\Psi_{real}(r, t+2)$\")\n",
    "axs[0,2].plot(r_n, X_imag_vis2*10, label=\"$\\Psi_{imag}(r, t+2)$\")\n",
    "axs[0,2].set_title(\"Input\")\n",
    "\n",
    "axs[1,0].plot(r_n, X_pot_vis3*(1/1.5936e-3), \"-\", label=\"V(r,t+3)\")\n",
    "axs[1,0].plot(r_n, X_real_vis3*10, label=\"$\\Psi_{real}(r, t+3)$\")\n",
    "axs[1,0].plot(r_n, X_imag_vis3*10, label=\"$\\Psi_{imag}(r, t+3)$\")\n",
    "axs[1,0].set_title(\"Input\")\n",
    "\n",
    "axs[1,1].plot(r_n, X_pot_vis4*(1/1.5936e-3), \"-\", label=\"V(r,t+4)\")\n",
    "axs[1,1].plot(r_n, X_real_vis4*10, label=\"$\\Psi_{real}(r, t+4)$\")\n",
    "axs[1,1].plot(r_n, X_imag_vis4*10, label=\"$\\Psi_{imag}(r, t+4)$\")\n",
    "axs[1,1].set_title(\"Input\")\n",
    "\n",
    "\n",
    "# Output\n",
    "axs[1,2].plot(r_n, y_real_vis*10, label=\"$\\Psi_{real}(r, t+5)$\")\n",
    "axs[1,2].plot(r_n, y_imag_vis*10, label=\"$\\Psi_{imag}(r, t+5)$\")\n",
    "axs[1,2].set_title(\"Output\")\n",
    "\n",
    "\n",
    "\n",
    "for axr1 in axs:\n",
    "    for axr11 in axr1:\n",
    "        axr11.set_ylim([-15, 60])\n",
    "        axr11.legend()\n",
    "        axr11.set(xlabel='Position [$\\AA$]', ylabel='Energy [Kcal/mol]')\n",
    "    \n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dae950",
   "metadata": {},
   "source": [
    "## LSTM model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a3c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1716ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_output, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_output = num_output  # number of output\n",
    "        self.num_layers = num_layers  # number of layers\n",
    "        self.input_size = input_size  # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.seq_length = seq_length  # sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True) #lstm\n",
    "        \n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(128, num_output) #fully connected last layer\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = self.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = self.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "203deddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 96  # number of features: 32 real part +32 complex part +32 potential\n",
    "hidden_size = 2  # number of features in hidden state\n",
    "num_layers = 1  # number of stacked lstm layers\n",
    "\n",
    "num_output = 64  # number of output: 32 real part + 32 complex part\n",
    "sequence_len = 5  # lenght of time steps (1 fs each one) toal 5 fs\n",
    "\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "feaf4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(num_output, input_size, hidden_size, num_layers, sequence_len) #our lstm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b5990f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a434ec8",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "612d7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_overlap(Psi_true, Psi_ANN):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Psi_true: Evolution of wavepacket from dataset test\n",
    "    Psi_ANN: Evolution of wavepacket predicted with the model\n",
    "    \n",
    "    Output:\n",
    "    S: Absolute magnitude\n",
    "    angle: phase\n",
    "    Characterizes the quality of the predictions. See equation (11) of Main article\n",
    "    \n",
    "    \"\"\"\n",
    "    S_tot = []\n",
    "    angle_tot = []\n",
    "    for j in range(batch_size):\n",
    "        Psi_true_re = Psi_true[j,0:32]  # real part of wavepacket\n",
    "        Psi_true_im = Psi_true[j,32:64]  # imaginary part of wavepacket\n",
    "        Psi_t = torch.view_as_complex(torch.stack((Psi_true_re,Psi_true_im), -1))\n",
    "    \n",
    "    \n",
    "        Psi_ANN_re = Psi_ANN[j,0:32]  # realpart of wavepacket predicted\n",
    "        Psi_ANN_im = -Psi_ANN[j,32:64]  # imaginary part of wavepacket predicted (- because conjugate)\n",
    "        Psi_A = torch.view_as_complex(torch.stack((Psi_ANN_re,Psi_ANN_im), -1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        overlap = []\n",
    "        for i in range(32):\n",
    "            overlap.append(torch.tensor([Psi_A[i]*Psi_t[i]]))\n",
    "        overl = torch.tensor(overlap)\n",
    "        \n",
    "        # Integrate over r (real integral + complex integral)\n",
    "        # Simpson method in the grid r_n (angstroms -> au)\n",
    "        r_n = np.linspace(-1.5,1.5,32)*(1/0.5291775)\n",
    "        overl_real = overl.real.numpy()\n",
    "        overl_imag = overl.imag.numpy()\n",
    "    \n",
    "        real_integ = integrate.simpson(overl_real, r_n)\n",
    "        imag_integ = integrate.simpson(overl_imag, r_n)\n",
    "    \n",
    "        # Covert to phase and magnitude of the complex result\n",
    "        S_tot.append(np.sqrt(real_integ**2 + imag_integ**2))\n",
    "        angle_tot.append(np.arctan(imag_integ/real_integ))\n",
    "        \n",
    "    S = sum(S_tot)/batch_size\n",
    "    angle = sum(angle_tot)/batch_size\n",
    "    \n",
    "    return S, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "800b0f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test over test loader\n",
    "correct1 = 0\n",
    "for X, y in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "    X, y = X.to(device), y.to(device)\n",
    "    S, angle = S_overlap(y, y)  # Accuracy by equation (11) Main Article       \n",
    "    correct1 += S\n",
    "correct1 /= len(test_loader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct1):>0.1f}%\\n\")  # Should be 100% because y=y => main of |S| = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "94dd93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('LSTM_0-model')  # To use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccac99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in train_loader:\n",
    "    writer.add_graph(model,X)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4501d2",
   "metadata": {},
   "source": [
    "## Train & Test loop definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader)#len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            writer.add_scalar(\"Loss/train\", loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f25084d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y, pred)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    test_loss /= num_batches\n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "    writer.add_scalar('Accuracy Magnitude |S| /test', 100*correctS, epoch)  # Should be 100%\n",
    "    writer.add_scalar('Accuracy phase /test', correct_phase, epoch)  # Should be 0\n",
    "    \n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eebf1e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5f4171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.123176  [    0/ 2250]\n",
      "loss: 0.088819  [ 1600/ 2250]\n",
      "loss: 0.084746  [ 3200/ 2250]\n",
      "loss: 0.085359  [ 4800/ 2250]\n",
      "loss: 0.085711  [ 6400/ 2250]\n",
      "loss: 0.084767  [ 8000/ 2250]\n",
      "loss: 0.085441  [ 9600/ 2250]\n",
      "loss: 0.084771  [11200/ 2250]\n",
      "loss: 0.084947  [12800/ 2250]\n",
      "loss: 0.085409  [14400/ 2250]\n",
      "loss: 0.084990  [16000/ 2250]\n",
      "loss: 0.085099  [17600/ 2250]\n",
      "loss: 0.082092  [19200/ 2250]\n",
      "loss: 0.084514  [20800/ 2250]\n",
      "loss: 0.082924  [22400/ 2250]\n",
      "loss: 0.081980  [24000/ 2250]\n",
      "loss: 0.082976  [25600/ 2250]\n",
      "loss: 0.077690  [27200/ 2250]\n",
      "loss: 0.083266  [28800/ 2250]\n",
      "loss: 0.083742  [30400/ 2250]\n",
      "loss: 0.083077  [32000/ 2250]\n",
      "loss: 0.082342  [33600/ 2250]\n",
      "loss: 0.085991  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.2%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.080594  [    0/ 2250]\n",
      "loss: 0.080755  [ 1600/ 2250]\n",
      "loss: 0.081442  [ 3200/ 2250]\n",
      "loss: 0.082887  [ 4800/ 2250]\n",
      "loss: 0.083996  [ 6400/ 2250]\n",
      "loss: 0.078254  [ 8000/ 2250]\n",
      "loss: 0.081776  [ 9600/ 2250]\n",
      "loss: 0.082486  [11200/ 2250]\n",
      "loss: 0.080948  [12800/ 2250]\n",
      "loss: 0.083137  [14400/ 2250]\n",
      "loss: 0.079332  [16000/ 2250]\n",
      "loss: 0.081129  [17600/ 2250]\n",
      "loss: 0.079891  [19200/ 2250]\n",
      "loss: 0.084363  [20800/ 2250]\n",
      "loss: 0.078999  [22400/ 2250]\n",
      "loss: 0.078431  [24000/ 2250]\n",
      "loss: 0.082307  [25600/ 2250]\n",
      "loss: 0.084548  [27200/ 2250]\n",
      "loss: 0.080261  [28800/ 2250]\n",
      "loss: 0.082688  [30400/ 2250]\n",
      "loss: 0.083942  [32000/ 2250]\n",
      "loss: 0.080746  [33600/ 2250]\n",
      "loss: 0.081687  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 8.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.081212  [    0/ 2250]\n",
      "loss: 0.080885  [ 1600/ 2250]\n",
      "loss: 0.081615  [ 3200/ 2250]\n",
      "loss: 0.082505  [ 4800/ 2250]\n",
      "loss: 0.083362  [ 6400/ 2250]\n",
      "loss: 0.080823  [ 8000/ 2250]\n",
      "loss: 0.075219  [ 9600/ 2250]\n",
      "loss: 0.080630  [11200/ 2250]\n",
      "loss: 0.084014  [12800/ 2250]\n",
      "loss: 0.081930  [14400/ 2250]\n",
      "loss: 0.077543  [16000/ 2250]\n",
      "loss: 0.083371  [17600/ 2250]\n",
      "loss: 0.081167  [19200/ 2250]\n",
      "loss: 0.078602  [20800/ 2250]\n",
      "loss: 0.080283  [22400/ 2250]\n",
      "loss: 0.083418  [24000/ 2250]\n",
      "loss: 0.076606  [25600/ 2250]\n",
      "loss: 0.083694  [27200/ 2250]\n",
      "loss: 0.081157  [28800/ 2250]\n",
      "loss: 0.081307  [30400/ 2250]\n",
      "loss: 0.084887  [32000/ 2250]\n",
      "loss: 0.080053  [33600/ 2250]\n",
      "loss: 0.082319  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 10.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.076979  [    0/ 2250]\n",
      "loss: 0.083269  [ 1600/ 2250]\n",
      "loss: 0.082837  [ 3200/ 2250]\n",
      "loss: 0.085283  [ 4800/ 2250]\n",
      "loss: 0.075875  [ 6400/ 2250]\n",
      "loss: 0.083256  [ 8000/ 2250]\n",
      "loss: 0.079612  [ 9600/ 2250]\n",
      "loss: 0.076692  [11200/ 2250]\n",
      "loss: 0.081305  [12800/ 2250]\n",
      "loss: 0.082043  [14400/ 2250]\n",
      "loss: 0.071597  [16000/ 2250]\n",
      "loss: 0.082437  [17600/ 2250]\n",
      "loss: 0.082496  [19200/ 2250]\n",
      "loss: 0.081791  [20800/ 2250]\n",
      "loss: 0.077169  [22400/ 2250]\n",
      "loss: 0.077518  [24000/ 2250]\n",
      "loss: 0.075221  [25600/ 2250]\n",
      "loss: 0.078590  [27200/ 2250]\n",
      "loss: 0.079493  [28800/ 2250]\n",
      "loss: 0.077353  [30400/ 2250]\n",
      "loss: 0.080970  [32000/ 2250]\n",
      "loss: 0.082631  [33600/ 2250]\n",
      "loss: 0.084485  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 10.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.072500  [    0/ 2250]\n",
      "loss: 0.082728  [ 1600/ 2250]\n",
      "loss: 0.087077  [ 3200/ 2250]\n",
      "loss: 0.078256  [ 4800/ 2250]\n",
      "loss: 0.076259  [ 6400/ 2250]\n",
      "loss: 0.083556  [ 8000/ 2250]\n",
      "loss: 0.076380  [ 9600/ 2250]\n",
      "loss: 0.078842  [11200/ 2250]\n",
      "loss: 0.081113  [12800/ 2250]\n",
      "loss: 0.075765  [14400/ 2250]\n",
      "loss: 0.076495  [16000/ 2250]\n",
      "loss: 0.076271  [17600/ 2250]\n",
      "loss: 0.077499  [19200/ 2250]\n",
      "loss: 0.077817  [20800/ 2250]\n",
      "loss: 0.083238  [22400/ 2250]\n",
      "loss: 0.078979  [24000/ 2250]\n",
      "loss: 0.082032  [25600/ 2250]\n",
      "loss: 0.081107  [27200/ 2250]\n",
      "loss: 0.077955  [28800/ 2250]\n",
      "loss: 0.080086  [30400/ 2250]\n",
      "loss: 0.079522  [32000/ 2250]\n",
      "loss: 0.076894  [33600/ 2250]\n",
      "loss: 0.083070  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 11.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.080623  [    0/ 2250]\n",
      "loss: 0.081504  [ 1600/ 2250]\n",
      "loss: 0.079124  [ 3200/ 2250]\n",
      "loss: 0.079467  [ 4800/ 2250]\n",
      "loss: 0.080868  [ 6400/ 2250]\n",
      "loss: 0.081050  [ 8000/ 2250]\n",
      "loss: 0.081992  [ 9600/ 2250]\n",
      "loss: 0.078042  [11200/ 2250]\n",
      "loss: 0.077397  [12800/ 2250]\n",
      "loss: 0.084606  [14400/ 2250]\n",
      "loss: 0.077359  [16000/ 2250]\n",
      "loss: 0.080185  [17600/ 2250]\n",
      "loss: 0.074989  [19200/ 2250]\n",
      "loss: 0.082473  [20800/ 2250]\n",
      "loss: 0.079130  [22400/ 2250]\n",
      "loss: 0.081702  [24000/ 2250]\n",
      "loss: 0.079960  [25600/ 2250]\n",
      "loss: 0.079095  [27200/ 2250]\n",
      "loss: 0.074608  [28800/ 2250]\n",
      "loss: 0.076007  [30400/ 2250]\n",
      "loss: 0.073697  [32000/ 2250]\n",
      "loss: 0.078310  [33600/ 2250]\n",
      "loss: 0.080176  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 11.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.071295  [    0/ 2250]\n",
      "loss: 0.084032  [ 1600/ 2250]\n",
      "loss: 0.078972  [ 3200/ 2250]\n",
      "loss: 0.071524  [ 4800/ 2250]\n",
      "loss: 0.082117  [ 6400/ 2250]\n",
      "loss: 0.078571  [ 8000/ 2250]\n",
      "loss: 0.078863  [ 9600/ 2250]\n",
      "loss: 0.080943  [11200/ 2250]\n",
      "loss: 0.081212  [12800/ 2250]\n",
      "loss: 0.080050  [14400/ 2250]\n",
      "loss: 0.083027  [16000/ 2250]\n",
      "loss: 0.075803  [17600/ 2250]\n",
      "loss: 0.082767  [19200/ 2250]\n",
      "loss: 0.080276  [20800/ 2250]\n",
      "loss: 0.078484  [22400/ 2250]\n",
      "loss: 0.079765  [24000/ 2250]\n",
      "loss: 0.072900  [25600/ 2250]\n",
      "loss: 0.078086  [27200/ 2250]\n",
      "loss: 0.071742  [28800/ 2250]\n",
      "loss: 0.078266  [30400/ 2250]\n",
      "loss: 0.080767  [32000/ 2250]\n",
      "loss: 0.078624  [33600/ 2250]\n",
      "loss: 0.080215  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 11.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.071247  [    0/ 2250]\n",
      "loss: 0.076315  [ 1600/ 2250]\n",
      "loss: 0.077366  [ 3200/ 2250]\n",
      "loss: 0.080054  [ 4800/ 2250]\n",
      "loss: 0.080354  [ 6400/ 2250]\n",
      "loss: 0.070138  [ 8000/ 2250]\n",
      "loss: 0.079343  [ 9600/ 2250]\n",
      "loss: 0.078765  [11200/ 2250]\n",
      "loss: 0.078353  [12800/ 2250]\n",
      "loss: 0.081664  [14400/ 2250]\n",
      "loss: 0.070717  [16000/ 2250]\n",
      "loss: 0.084354  [17600/ 2250]\n",
      "loss: 0.079751  [19200/ 2250]\n",
      "loss: 0.077549  [20800/ 2250]\n",
      "loss: 0.075653  [22400/ 2250]\n",
      "loss: 0.082704  [24000/ 2250]\n",
      "loss: 0.076059  [25600/ 2250]\n",
      "loss: 0.077551  [27200/ 2250]\n",
      "loss: 0.083325  [28800/ 2250]\n",
      "loss: 0.078184  [30400/ 2250]\n",
      "loss: 0.078167  [32000/ 2250]\n",
      "loss: 0.080492  [33600/ 2250]\n",
      "loss: 0.079272  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 11.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.079110  [    0/ 2250]\n",
      "loss: 0.080882  [ 1600/ 2250]\n",
      "loss: 0.072865  [ 3200/ 2250]\n",
      "loss: 0.073750  [ 4800/ 2250]\n",
      "loss: 0.075035  [ 6400/ 2250]\n",
      "loss: 0.081774  [ 8000/ 2250]\n",
      "loss: 0.077886  [ 9600/ 2250]\n",
      "loss: 0.076220  [11200/ 2250]\n",
      "loss: 0.079952  [12800/ 2250]\n",
      "loss: 0.083829  [14400/ 2250]\n",
      "loss: 0.070661  [16000/ 2250]\n",
      "loss: 0.080688  [17600/ 2250]\n",
      "loss: 0.081934  [19200/ 2250]\n",
      "loss: 0.073430  [20800/ 2250]\n",
      "loss: 0.081929  [22400/ 2250]\n",
      "loss: 0.073167  [24000/ 2250]\n",
      "loss: 0.080344  [25600/ 2250]\n",
      "loss: 0.083507  [27200/ 2250]\n",
      "loss: 0.079063  [28800/ 2250]\n",
      "loss: 0.073829  [30400/ 2250]\n",
      "loss: 0.077390  [32000/ 2250]\n",
      "loss: 0.079511  [33600/ 2250]\n",
      "loss: 0.078341  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 12.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.077352  [    0/ 2250]\n",
      "loss: 0.073539  [ 1600/ 2250]\n",
      "loss: 0.086349  [ 3200/ 2250]\n",
      "loss: 0.079799  [ 4800/ 2250]\n",
      "loss: 0.076208  [ 6400/ 2250]\n",
      "loss: 0.081799  [ 8000/ 2250]\n",
      "loss: 0.079581  [ 9600/ 2250]\n",
      "loss: 0.071989  [11200/ 2250]\n",
      "loss: 0.077878  [12800/ 2250]\n",
      "loss: 0.074599  [14400/ 2250]\n",
      "loss: 0.079314  [16000/ 2250]\n",
      "loss: 0.078579  [17600/ 2250]\n",
      "loss: 0.081182  [19200/ 2250]\n",
      "loss: 0.084873  [20800/ 2250]\n",
      "loss: 0.076806  [22400/ 2250]\n",
      "loss: 0.075917  [24000/ 2250]\n",
      "loss: 0.079510  [25600/ 2250]\n",
      "loss: 0.079228  [27200/ 2250]\n",
      "loss: 0.079919  [28800/ 2250]\n",
      "loss: 0.072566  [30400/ 2250]\n",
      "loss: 0.078006  [32000/ 2250]\n",
      "loss: 0.082678  [33600/ 2250]\n",
      "loss: 0.081842  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 12.4%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.085815  [    0/ 2250]\n",
      "loss: 0.079863  [ 1600/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.070792  [ 3200/ 2250]\n",
      "loss: 0.079107  [ 4800/ 2250]\n",
      "loss: 0.082083  [ 6400/ 2250]\n",
      "loss: 0.078969  [ 8000/ 2250]\n",
      "loss: 0.077922  [ 9600/ 2250]\n",
      "loss: 0.069006  [11200/ 2250]\n",
      "loss: 0.072924  [12800/ 2250]\n",
      "loss: 0.072589  [14400/ 2250]\n",
      "loss: 0.079150  [16000/ 2250]\n",
      "loss: 0.069691  [17600/ 2250]\n",
      "loss: 0.078886  [19200/ 2250]\n",
      "loss: 0.078094  [20800/ 2250]\n",
      "loss: 0.072413  [22400/ 2250]\n",
      "loss: 0.078448  [24000/ 2250]\n",
      "loss: 0.080844  [25600/ 2250]\n",
      "loss: 0.070485  [27200/ 2250]\n",
      "loss: 0.082858  [28800/ 2250]\n",
      "loss: 0.072401  [30400/ 2250]\n",
      "loss: 0.072381  [32000/ 2250]\n",
      "loss: 0.078488  [33600/ 2250]\n",
      "loss: 0.078560  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 12.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.078081  [    0/ 2250]\n",
      "loss: 0.078414  [ 1600/ 2250]\n",
      "loss: 0.076941  [ 3200/ 2250]\n",
      "loss: 0.076540  [ 4800/ 2250]\n",
      "loss: 0.080948  [ 6400/ 2250]\n",
      "loss: 0.079542  [ 8000/ 2250]\n",
      "loss: 0.080105  [ 9600/ 2250]\n",
      "loss: 0.078918  [11200/ 2250]\n",
      "loss: 0.070591  [12800/ 2250]\n",
      "loss: 0.078142  [14400/ 2250]\n",
      "loss: 0.077922  [16000/ 2250]\n",
      "loss: 0.078941  [17600/ 2250]\n",
      "loss: 0.077226  [19200/ 2250]\n",
      "loss: 0.076146  [20800/ 2250]\n",
      "loss: 0.074505  [22400/ 2250]\n",
      "loss: 0.069375  [24000/ 2250]\n",
      "loss: 0.076927  [25600/ 2250]\n",
      "loss: 0.075166  [27200/ 2250]\n",
      "loss: 0.073655  [28800/ 2250]\n",
      "loss: 0.076822  [30400/ 2250]\n",
      "loss: 0.078085  [32000/ 2250]\n",
      "loss: 0.074241  [33600/ 2250]\n",
      "loss: 0.075779  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 13.2%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.076124  [    0/ 2250]\n",
      "loss: 0.071067  [ 1600/ 2250]\n",
      "loss: 0.075380  [ 3200/ 2250]\n",
      "loss: 0.074318  [ 4800/ 2250]\n",
      "loss: 0.069206  [ 6400/ 2250]\n",
      "loss: 0.073092  [ 8000/ 2250]\n",
      "loss: 0.078148  [ 9600/ 2250]\n",
      "loss: 0.078298  [11200/ 2250]\n",
      "loss: 0.083532  [12800/ 2250]\n",
      "loss: 0.077168  [14400/ 2250]\n",
      "loss: 0.070223  [16000/ 2250]\n",
      "loss: 0.076034  [17600/ 2250]\n",
      "loss: 0.079910  [19200/ 2250]\n",
      "loss: 0.074830  [20800/ 2250]\n",
      "loss: 0.079092  [22400/ 2250]\n",
      "loss: 0.071210  [24000/ 2250]\n",
      "loss: 0.079059  [25600/ 2250]\n",
      "loss: 0.074002  [27200/ 2250]\n",
      "loss: 0.072757  [28800/ 2250]\n",
      "loss: 0.067558  [30400/ 2250]\n",
      "loss: 0.079037  [32000/ 2250]\n",
      "loss: 0.068465  [33600/ 2250]\n",
      "loss: 0.075336  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 13.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.079783  [    0/ 2250]\n",
      "loss: 0.075857  [ 1600/ 2250]\n",
      "loss: 0.073348  [ 3200/ 2250]\n",
      "loss: 0.075571  [ 4800/ 2250]\n",
      "loss: 0.076351  [ 6400/ 2250]\n",
      "loss: 0.079151  [ 8000/ 2250]\n",
      "loss: 0.072133  [ 9600/ 2250]\n",
      "loss: 0.076518  [11200/ 2250]\n",
      "loss: 0.080203  [12800/ 2250]\n",
      "loss: 0.074309  [14400/ 2250]\n",
      "loss: 0.079339  [16000/ 2250]\n",
      "loss: 0.076725  [17600/ 2250]\n",
      "loss: 0.073510  [19200/ 2250]\n",
      "loss: 0.077753  [20800/ 2250]\n",
      "loss: 0.078363  [22400/ 2250]\n",
      "loss: 0.076829  [24000/ 2250]\n",
      "loss: 0.081991  [25600/ 2250]\n",
      "loss: 0.074822  [27200/ 2250]\n",
      "loss: 0.079193  [28800/ 2250]\n",
      "loss: 0.078031  [30400/ 2250]\n",
      "loss: 0.080566  [32000/ 2250]\n",
      "loss: 0.074346  [33600/ 2250]\n",
      "loss: 0.079391  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 13.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.079096  [    0/ 2250]\n",
      "loss: 0.075965  [ 1600/ 2250]\n",
      "loss: 0.080899  [ 3200/ 2250]\n",
      "loss: 0.073745  [ 4800/ 2250]\n",
      "loss: 0.076218  [ 6400/ 2250]\n",
      "loss: 0.071279  [ 8000/ 2250]\n",
      "loss: 0.077341  [ 9600/ 2250]\n",
      "loss: 0.073540  [11200/ 2250]\n",
      "loss: 0.076793  [12800/ 2250]\n",
      "loss: 0.071976  [14400/ 2250]\n",
      "loss: 0.076499  [16000/ 2250]\n",
      "loss: 0.074624  [17600/ 2250]\n",
      "loss: 0.082838  [19200/ 2250]\n",
      "loss: 0.075894  [20800/ 2250]\n",
      "loss: 0.074631  [22400/ 2250]\n",
      "loss: 0.074830  [24000/ 2250]\n",
      "loss: 0.077606  [25600/ 2250]\n",
      "loss: 0.080544  [27200/ 2250]\n",
      "loss: 0.078836  [28800/ 2250]\n",
      "loss: 0.079243  [30400/ 2250]\n",
      "loss: 0.071953  [32000/ 2250]\n",
      "loss: 0.074321  [33600/ 2250]\n",
      "loss: 0.074758  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 13.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.079759  [    0/ 2250]\n",
      "loss: 0.079103  [ 1600/ 2250]\n",
      "loss: 0.072451  [ 3200/ 2250]\n",
      "loss: 0.076881  [ 4800/ 2250]\n",
      "loss: 0.073717  [ 6400/ 2250]\n",
      "loss: 0.073598  [ 8000/ 2250]\n",
      "loss: 0.070944  [ 9600/ 2250]\n",
      "loss: 0.074484  [11200/ 2250]\n",
      "loss: 0.065786  [12800/ 2250]\n",
      "loss: 0.078227  [14400/ 2250]\n",
      "loss: 0.074284  [16000/ 2250]\n",
      "loss: 0.084171  [17600/ 2250]\n",
      "loss: 0.079724  [19200/ 2250]\n",
      "loss: 0.074600  [20800/ 2250]\n",
      "loss: 0.076595  [22400/ 2250]\n",
      "loss: 0.074654  [24000/ 2250]\n",
      "loss: 0.072024  [25600/ 2250]\n",
      "loss: 0.075500  [27200/ 2250]\n",
      "loss: 0.070092  [28800/ 2250]\n",
      "loss: 0.071065  [30400/ 2250]\n",
      "loss: 0.074502  [32000/ 2250]\n",
      "loss: 0.087738  [33600/ 2250]\n",
      "loss: 0.066583  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 14.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.076281  [    0/ 2250]\n",
      "loss: 0.076302  [ 1600/ 2250]\n",
      "loss: 0.075301  [ 3200/ 2250]\n",
      "loss: 0.081208  [ 4800/ 2250]\n",
      "loss: 0.078037  [ 6400/ 2250]\n",
      "loss: 0.075215  [ 8000/ 2250]\n",
      "loss: 0.078845  [ 9600/ 2250]\n",
      "loss: 0.069172  [11200/ 2250]\n",
      "loss: 0.077750  [12800/ 2250]\n",
      "loss: 0.077486  [14400/ 2250]\n",
      "loss: 0.077729  [16000/ 2250]\n",
      "loss: 0.078994  [17600/ 2250]\n",
      "loss: 0.078796  [19200/ 2250]\n",
      "loss: 0.070967  [20800/ 2250]\n",
      "loss: 0.068487  [22400/ 2250]\n",
      "loss: 0.073614  [24000/ 2250]\n",
      "loss: 0.069796  [25600/ 2250]\n",
      "loss: 0.072350  [27200/ 2250]\n",
      "loss: 0.086308  [28800/ 2250]\n",
      "loss: 0.071213  [30400/ 2250]\n",
      "loss: 0.082246  [32000/ 2250]\n",
      "loss: 0.076955  [33600/ 2250]\n",
      "loss: 0.079492  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 14.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.083082  [    0/ 2250]\n",
      "loss: 0.075373  [ 1600/ 2250]\n",
      "loss: 0.076715  [ 3200/ 2250]\n",
      "loss: 0.077154  [ 4800/ 2250]\n",
      "loss: 0.079138  [ 6400/ 2250]\n",
      "loss: 0.074996  [ 8000/ 2250]\n",
      "loss: 0.079892  [ 9600/ 2250]\n",
      "loss: 0.070141  [11200/ 2250]\n",
      "loss: 0.072046  [12800/ 2250]\n",
      "loss: 0.078976  [14400/ 2250]\n",
      "loss: 0.079188  [16000/ 2250]\n",
      "loss: 0.075065  [17600/ 2250]\n",
      "loss: 0.075168  [19200/ 2250]\n",
      "loss: 0.082528  [20800/ 2250]\n",
      "loss: 0.075460  [22400/ 2250]\n",
      "loss: 0.079820  [24000/ 2250]\n",
      "loss: 0.076609  [25600/ 2250]\n",
      "loss: 0.077988  [27200/ 2250]\n",
      "loss: 0.073729  [28800/ 2250]\n",
      "loss: 0.072668  [30400/ 2250]\n",
      "loss: 0.076150  [32000/ 2250]\n",
      "loss: 0.078230  [33600/ 2250]\n",
      "loss: 0.076514  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 14.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.075380  [    0/ 2250]\n",
      "loss: 0.081924  [ 1600/ 2250]\n",
      "loss: 0.081188  [ 3200/ 2250]\n",
      "loss: 0.073273  [ 4800/ 2250]\n",
      "loss: 0.071787  [ 6400/ 2250]\n",
      "loss: 0.073992  [ 8000/ 2250]\n",
      "loss: 0.073316  [ 9600/ 2250]\n",
      "loss: 0.080326  [11200/ 2250]\n",
      "loss: 0.077782  [12800/ 2250]\n",
      "loss: 0.072407  [14400/ 2250]\n",
      "loss: 0.078855  [16000/ 2250]\n",
      "loss: 0.078886  [17600/ 2250]\n",
      "loss: 0.071739  [19200/ 2250]\n",
      "loss: 0.068300  [20800/ 2250]\n",
      "loss: 0.075019  [22400/ 2250]\n",
      "loss: 0.076342  [24000/ 2250]\n",
      "loss: 0.080447  [25600/ 2250]\n",
      "loss: 0.076866  [27200/ 2250]\n",
      "loss: 0.064900  [28800/ 2250]\n",
      "loss: 0.067527  [30400/ 2250]\n",
      "loss: 0.078729  [32000/ 2250]\n",
      "loss: 0.074719  [33600/ 2250]\n",
      "loss: 0.072647  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 14.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.078862  [    0/ 2250]\n",
      "loss: 0.085148  [ 1600/ 2250]\n",
      "loss: 0.072277  [ 3200/ 2250]\n",
      "loss: 0.079435  [ 4800/ 2250]\n",
      "loss: 0.077788  [ 6400/ 2250]\n",
      "loss: 0.086711  [ 8000/ 2250]\n",
      "loss: 0.080132  [ 9600/ 2250]\n",
      "loss: 0.072904  [11200/ 2250]\n",
      "loss: 0.081148  [12800/ 2250]\n",
      "loss: 0.070733  [14400/ 2250]\n",
      "loss: 0.078847  [16000/ 2250]\n",
      "loss: 0.080534  [17600/ 2250]\n",
      "loss: 0.078479  [19200/ 2250]\n",
      "loss: 0.072589  [20800/ 2250]\n",
      "loss: 0.077522  [22400/ 2250]\n",
      "loss: 0.069897  [24000/ 2250]\n",
      "loss: 0.078974  [25600/ 2250]\n",
      "loss: 0.080903  [27200/ 2250]\n",
      "loss: 0.071941  [28800/ 2250]\n",
      "loss: 0.074201  [30400/ 2250]\n",
      "loss: 0.070319  [32000/ 2250]\n",
      "loss: 0.072543  [33600/ 2250]\n",
      "loss: 0.071077  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 15.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.073405  [    0/ 2250]\n",
      "loss: 0.076195  [ 1600/ 2250]\n",
      "loss: 0.072731  [ 3200/ 2250]\n",
      "loss: 0.076850  [ 4800/ 2250]\n",
      "loss: 0.074008  [ 6400/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.079362  [ 8000/ 2250]\n",
      "loss: 0.073904  [ 9600/ 2250]\n",
      "loss: 0.072946  [11200/ 2250]\n",
      "loss: 0.077656  [12800/ 2250]\n",
      "loss: 0.079025  [14400/ 2250]\n",
      "loss: 0.076186  [16000/ 2250]\n",
      "loss: 0.075576  [17600/ 2250]\n",
      "loss: 0.075055  [19200/ 2250]\n",
      "loss: 0.078826  [20800/ 2250]\n",
      "loss: 0.083826  [22400/ 2250]\n",
      "loss: 0.077338  [24000/ 2250]\n",
      "loss: 0.076491  [25600/ 2250]\n",
      "loss: 0.075854  [27200/ 2250]\n",
      "loss: 0.072584  [28800/ 2250]\n",
      "loss: 0.078394  [30400/ 2250]\n",
      "loss: 0.076856  [32000/ 2250]\n",
      "loss: 0.078166  [33600/ 2250]\n",
      "loss: 0.074073  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 15.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.074429  [    0/ 2250]\n",
      "loss: 0.072427  [ 1600/ 2250]\n",
      "loss: 0.067663  [ 3200/ 2250]\n",
      "loss: 0.076107  [ 4800/ 2250]\n",
      "loss: 0.072471  [ 6400/ 2250]\n",
      "loss: 0.076727  [ 8000/ 2250]\n",
      "loss: 0.072046  [ 9600/ 2250]\n",
      "loss: 0.075487  [11200/ 2250]\n",
      "loss: 0.068139  [12800/ 2250]\n",
      "loss: 0.077747  [14400/ 2250]\n",
      "loss: 0.075048  [16000/ 2250]\n",
      "loss: 0.069572  [17600/ 2250]\n",
      "loss: 0.075253  [19200/ 2250]\n",
      "loss: 0.073033  [20800/ 2250]\n",
      "loss: 0.073743  [22400/ 2250]\n",
      "loss: 0.070859  [24000/ 2250]\n",
      "loss: 0.071457  [25600/ 2250]\n",
      "loss: 0.068152  [27200/ 2250]\n",
      "loss: 0.075280  [28800/ 2250]\n",
      "loss: 0.071320  [30400/ 2250]\n",
      "loss: 0.076441  [32000/ 2250]\n",
      "loss: 0.075387  [33600/ 2250]\n",
      "loss: 0.072633  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 15.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.075586  [    0/ 2250]\n",
      "loss: 0.073164  [ 1600/ 2250]\n",
      "loss: 0.079552  [ 3200/ 2250]\n",
      "loss: 0.077558  [ 4800/ 2250]\n",
      "loss: 0.075011  [ 6400/ 2250]\n",
      "loss: 0.074832  [ 8000/ 2250]\n",
      "loss: 0.075193  [ 9600/ 2250]\n",
      "loss: 0.074360  [11200/ 2250]\n",
      "loss: 0.075498  [12800/ 2250]\n",
      "loss: 0.072378  [14400/ 2250]\n",
      "loss: 0.067808  [16000/ 2250]\n",
      "loss: 0.073838  [17600/ 2250]\n",
      "loss: 0.078326  [19200/ 2250]\n",
      "loss: 0.075008  [20800/ 2250]\n",
      "loss: 0.076399  [22400/ 2250]\n",
      "loss: 0.073466  [24000/ 2250]\n",
      "loss: 0.072303  [25600/ 2250]\n",
      "loss: 0.080683  [27200/ 2250]\n",
      "loss: 0.076390  [28800/ 2250]\n",
      "loss: 0.073714  [30400/ 2250]\n",
      "loss: 0.076805  [32000/ 2250]\n",
      "loss: 0.076981  [33600/ 2250]\n",
      "loss: 0.072843  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 15.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.080027  [    0/ 2250]\n",
      "loss: 0.076888  [ 1600/ 2250]\n",
      "loss: 0.076249  [ 3200/ 2250]\n",
      "loss: 0.073571  [ 4800/ 2250]\n",
      "loss: 0.074821  [ 6400/ 2250]\n",
      "loss: 0.073096  [ 8000/ 2250]\n",
      "loss: 0.070516  [ 9600/ 2250]\n",
      "loss: 0.068055  [11200/ 2250]\n",
      "loss: 0.068008  [12800/ 2250]\n",
      "loss: 0.068335  [14400/ 2250]\n",
      "loss: 0.074004  [16000/ 2250]\n",
      "loss: 0.073972  [17600/ 2250]\n",
      "loss: 0.074722  [19200/ 2250]\n",
      "loss: 0.072312  [20800/ 2250]\n",
      "loss: 0.077113  [22400/ 2250]\n",
      "loss: 0.067643  [24000/ 2250]\n",
      "loss: 0.066409  [25600/ 2250]\n",
      "loss: 0.076807  [27200/ 2250]\n",
      "loss: 0.077231  [28800/ 2250]\n",
      "loss: 0.071562  [30400/ 2250]\n",
      "loss: 0.081662  [32000/ 2250]\n",
      "loss: 0.073662  [33600/ 2250]\n",
      "loss: 0.075714  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 15.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.078443  [    0/ 2250]\n",
      "loss: 0.073844  [ 1600/ 2250]\n",
      "loss: 0.075941  [ 3200/ 2250]\n",
      "loss: 0.080761  [ 4800/ 2250]\n",
      "loss: 0.070220  [ 6400/ 2250]\n",
      "loss: 0.073884  [ 8000/ 2250]\n",
      "loss: 0.066542  [ 9600/ 2250]\n",
      "loss: 0.074022  [11200/ 2250]\n",
      "loss: 0.077150  [12800/ 2250]\n",
      "loss: 0.072680  [14400/ 2250]\n",
      "loss: 0.084029  [16000/ 2250]\n",
      "loss: 0.073752  [17600/ 2250]\n",
      "loss: 0.076405  [19200/ 2250]\n",
      "loss: 0.072347  [20800/ 2250]\n",
      "loss: 0.076214  [22400/ 2250]\n",
      "loss: 0.076191  [24000/ 2250]\n",
      "loss: 0.078111  [25600/ 2250]\n",
      "loss: 0.074916  [27200/ 2250]\n",
      "loss: 0.066783  [28800/ 2250]\n",
      "loss: 0.073806  [30400/ 2250]\n",
      "loss: 0.073865  [32000/ 2250]\n",
      "loss: 0.074096  [33600/ 2250]\n",
      "loss: 0.078111  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.080493  [    0/ 2250]\n",
      "loss: 0.070196  [ 1600/ 2250]\n",
      "loss: 0.071143  [ 3200/ 2250]\n",
      "loss: 0.066827  [ 4800/ 2250]\n",
      "loss: 0.068999  [ 6400/ 2250]\n",
      "loss: 0.069822  [ 8000/ 2250]\n",
      "loss: 0.067650  [ 9600/ 2250]\n",
      "loss: 0.074398  [11200/ 2250]\n",
      "loss: 0.078813  [12800/ 2250]\n",
      "loss: 0.073284  [14400/ 2250]\n",
      "loss: 0.070142  [16000/ 2250]\n",
      "loss: 0.070502  [17600/ 2250]\n",
      "loss: 0.080028  [19200/ 2250]\n",
      "loss: 0.074989  [20800/ 2250]\n",
      "loss: 0.075189  [22400/ 2250]\n",
      "loss: 0.075630  [24000/ 2250]\n",
      "loss: 0.080768  [25600/ 2250]\n",
      "loss: 0.078662  [27200/ 2250]\n",
      "loss: 0.074294  [28800/ 2250]\n",
      "loss: 0.070983  [30400/ 2250]\n",
      "loss: 0.083843  [32000/ 2250]\n",
      "loss: 0.077577  [33600/ 2250]\n",
      "loss: 0.074719  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.068825  [    0/ 2250]\n",
      "loss: 0.072040  [ 1600/ 2250]\n",
      "loss: 0.078581  [ 3200/ 2250]\n",
      "loss: 0.076407  [ 4800/ 2250]\n",
      "loss: 0.076499  [ 6400/ 2250]\n",
      "loss: 0.079022  [ 8000/ 2250]\n",
      "loss: 0.074541  [ 9600/ 2250]\n",
      "loss: 0.077855  [11200/ 2250]\n",
      "loss: 0.076156  [12800/ 2250]\n",
      "loss: 0.076032  [14400/ 2250]\n",
      "loss: 0.074848  [16000/ 2250]\n",
      "loss: 0.071572  [17600/ 2250]\n",
      "loss: 0.078328  [19200/ 2250]\n",
      "loss: 0.071904  [20800/ 2250]\n",
      "loss: 0.082406  [22400/ 2250]\n",
      "loss: 0.069494  [24000/ 2250]\n",
      "loss: 0.067952  [25600/ 2250]\n",
      "loss: 0.077397  [27200/ 2250]\n",
      "loss: 0.074930  [28800/ 2250]\n",
      "loss: 0.072306  [30400/ 2250]\n",
      "loss: 0.078129  [32000/ 2250]\n",
      "loss: 0.079106  [33600/ 2250]\n",
      "loss: 0.062429  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.2%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.071974  [    0/ 2250]\n",
      "loss: 0.072384  [ 1600/ 2250]\n",
      "loss: 0.072952  [ 3200/ 2250]\n",
      "loss: 0.083280  [ 4800/ 2250]\n",
      "loss: 0.069061  [ 6400/ 2250]\n",
      "loss: 0.077526  [ 8000/ 2250]\n",
      "loss: 0.073791  [ 9600/ 2250]\n",
      "loss: 0.077354  [11200/ 2250]\n",
      "loss: 0.078756  [12800/ 2250]\n",
      "loss: 0.068709  [14400/ 2250]\n",
      "loss: 0.077100  [16000/ 2250]\n",
      "loss: 0.077194  [17600/ 2250]\n",
      "loss: 0.075783  [19200/ 2250]\n",
      "loss: 0.078254  [20800/ 2250]\n",
      "loss: 0.076340  [22400/ 2250]\n",
      "loss: 0.080979  [24000/ 2250]\n",
      "loss: 0.071504  [25600/ 2250]\n",
      "loss: 0.076001  [27200/ 2250]\n",
      "loss: 0.080078  [28800/ 2250]\n",
      "loss: 0.080585  [30400/ 2250]\n",
      "loss: 0.077277  [32000/ 2250]\n",
      "loss: 0.080269  [33600/ 2250]\n",
      "loss: 0.077272  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.075110  [    0/ 2250]\n",
      "loss: 0.077034  [ 1600/ 2250]\n",
      "loss: 0.067289  [ 3200/ 2250]\n",
      "loss: 0.072467  [ 4800/ 2250]\n",
      "loss: 0.075574  [ 6400/ 2250]\n",
      "loss: 0.072804  [ 8000/ 2250]\n",
      "loss: 0.071434  [ 9600/ 2250]\n",
      "loss: 0.076436  [11200/ 2250]\n",
      "loss: 0.080968  [12800/ 2250]\n",
      "loss: 0.074826  [14400/ 2250]\n",
      "loss: 0.075076  [16000/ 2250]\n",
      "loss: 0.076180  [17600/ 2250]\n",
      "loss: 0.071081  [19200/ 2250]\n",
      "loss: 0.075804  [20800/ 2250]\n",
      "loss: 0.068134  [22400/ 2250]\n",
      "loss: 0.075333  [24000/ 2250]\n",
      "loss: 0.071469  [25600/ 2250]\n",
      "loss: 0.069700  [27200/ 2250]\n",
      "loss: 0.070454  [28800/ 2250]\n",
      "loss: 0.075307  [30400/ 2250]\n",
      "loss: 0.072109  [32000/ 2250]\n",
      "loss: 0.083515  [33600/ 2250]\n",
      "loss: 0.075988  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.068593  [    0/ 2250]\n",
      "loss: 0.075455  [ 1600/ 2250]\n",
      "loss: 0.080887  [ 3200/ 2250]\n",
      "loss: 0.069652  [ 4800/ 2250]\n",
      "loss: 0.073586  [ 6400/ 2250]\n",
      "loss: 0.070810  [ 8000/ 2250]\n",
      "loss: 0.073684  [ 9600/ 2250]\n",
      "loss: 0.072875  [11200/ 2250]\n",
      "loss: 0.073386  [12800/ 2250]\n",
      "loss: 0.073281  [14400/ 2250]\n",
      "loss: 0.071421  [16000/ 2250]\n",
      "loss: 0.078795  [17600/ 2250]\n",
      "loss: 0.066472  [19200/ 2250]\n",
      "loss: 0.077671  [20800/ 2250]\n",
      "loss: 0.068445  [22400/ 2250]\n",
      "loss: 0.076250  [24000/ 2250]\n",
      "loss: 0.070843  [25600/ 2250]\n",
      "loss: 0.076119  [27200/ 2250]\n",
      "loss: 0.076362  [28800/ 2250]\n",
      "loss: 0.078485  [30400/ 2250]\n",
      "loss: 0.075785  [32000/ 2250]\n",
      "loss: 0.073551  [33600/ 2250]\n",
      "loss: 0.066930  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.071575  [    0/ 2250]\n",
      "loss: 0.074166  [ 1600/ 2250]\n",
      "loss: 0.076193  [ 3200/ 2250]\n",
      "loss: 0.078591  [ 4800/ 2250]\n",
      "loss: 0.075328  [ 6400/ 2250]\n",
      "loss: 0.083989  [ 8000/ 2250]\n",
      "loss: 0.065677  [ 9600/ 2250]\n",
      "loss: 0.078176  [11200/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.073775  [12800/ 2250]\n",
      "loss: 0.071025  [14400/ 2250]\n",
      "loss: 0.066154  [16000/ 2250]\n",
      "loss: 0.073905  [17600/ 2250]\n",
      "loss: 0.082102  [19200/ 2250]\n",
      "loss: 0.069601  [20800/ 2250]\n",
      "loss: 0.072850  [22400/ 2250]\n",
      "loss: 0.072766  [24000/ 2250]\n",
      "loss: 0.070174  [25600/ 2250]\n",
      "loss: 0.079809  [27200/ 2250]\n",
      "loss: 0.075852  [28800/ 2250]\n",
      "loss: 0.085916  [30400/ 2250]\n",
      "loss: 0.072325  [32000/ 2250]\n",
      "loss: 0.072694  [33600/ 2250]\n",
      "loss: 0.073675  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.071186  [    0/ 2250]\n",
      "loss: 0.070823  [ 1600/ 2250]\n",
      "loss: 0.074290  [ 3200/ 2250]\n",
      "loss: 0.082120  [ 4800/ 2250]\n",
      "loss: 0.072902  [ 6400/ 2250]\n",
      "loss: 0.074649  [ 8000/ 2250]\n",
      "loss: 0.073795  [ 9600/ 2250]\n",
      "loss: 0.068305  [11200/ 2250]\n",
      "loss: 0.080871  [12800/ 2250]\n",
      "loss: 0.076676  [14400/ 2250]\n",
      "loss: 0.078006  [16000/ 2250]\n",
      "loss: 0.071089  [17600/ 2250]\n",
      "loss: 0.072079  [19200/ 2250]\n",
      "loss: 0.068712  [20800/ 2250]\n",
      "loss: 0.071151  [22400/ 2250]\n",
      "loss: 0.071746  [24000/ 2250]\n",
      "loss: 0.075673  [25600/ 2250]\n",
      "loss: 0.083856  [27200/ 2250]\n",
      "loss: 0.077337  [28800/ 2250]\n",
      "loss: 0.076649  [30400/ 2250]\n",
      "loss: 0.071846  [32000/ 2250]\n",
      "loss: 0.071043  [33600/ 2250]\n",
      "loss: 0.068872  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.7%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.063334  [    0/ 2250]\n",
      "loss: 0.072204  [ 1600/ 2250]\n",
      "loss: 0.072859  [ 3200/ 2250]\n",
      "loss: 0.081301  [ 4800/ 2250]\n",
      "loss: 0.078068  [ 6400/ 2250]\n",
      "loss: 0.069861  [ 8000/ 2250]\n",
      "loss: 0.074832  [ 9600/ 2250]\n",
      "loss: 0.074701  [11200/ 2250]\n",
      "loss: 0.075089  [12800/ 2250]\n",
      "loss: 0.071885  [14400/ 2250]\n",
      "loss: 0.074596  [16000/ 2250]\n",
      "loss: 0.075760  [17600/ 2250]\n",
      "loss: 0.073208  [19200/ 2250]\n",
      "loss: 0.075167  [20800/ 2250]\n",
      "loss: 0.069321  [22400/ 2250]\n",
      "loss: 0.077703  [24000/ 2250]\n",
      "loss: 0.079006  [25600/ 2250]\n",
      "loss: 0.071224  [27200/ 2250]\n",
      "loss: 0.077087  [28800/ 2250]\n",
      "loss: 0.073859  [30400/ 2250]\n",
      "loss: 0.076710  [32000/ 2250]\n",
      "loss: 0.073379  [33600/ 2250]\n",
      "loss: 0.077285  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.077506  [    0/ 2250]\n",
      "loss: 0.074607  [ 1600/ 2250]\n",
      "loss: 0.073402  [ 3200/ 2250]\n",
      "loss: 0.082790  [ 4800/ 2250]\n",
      "loss: 0.061012  [ 6400/ 2250]\n",
      "loss: 0.078238  [ 8000/ 2250]\n",
      "loss: 0.079579  [ 9600/ 2250]\n",
      "loss: 0.070032  [11200/ 2250]\n",
      "loss: 0.070229  [12800/ 2250]\n",
      "loss: 0.077241  [14400/ 2250]\n",
      "loss: 0.073173  [16000/ 2250]\n",
      "loss: 0.076341  [17600/ 2250]\n",
      "loss: 0.074121  [19200/ 2250]\n",
      "loss: 0.080914  [20800/ 2250]\n",
      "loss: 0.070609  [22400/ 2250]\n",
      "loss: 0.080099  [24000/ 2250]\n",
      "loss: 0.077081  [25600/ 2250]\n",
      "loss: 0.067848  [27200/ 2250]\n",
      "loss: 0.085486  [28800/ 2250]\n",
      "loss: 0.072375  [30400/ 2250]\n",
      "loss: 0.071804  [32000/ 2250]\n",
      "loss: 0.082113  [33600/ 2250]\n",
      "loss: 0.074517  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 16.9%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.068483  [    0/ 2250]\n",
      "loss: 0.072288  [ 1600/ 2250]\n",
      "loss: 0.080606  [ 3200/ 2250]\n",
      "loss: 0.070939  [ 4800/ 2250]\n",
      "loss: 0.066529  [ 6400/ 2250]\n",
      "loss: 0.081659  [ 8000/ 2250]\n",
      "loss: 0.069161  [ 9600/ 2250]\n",
      "loss: 0.081265  [11200/ 2250]\n",
      "loss: 0.072775  [12800/ 2250]\n",
      "loss: 0.067356  [14400/ 2250]\n",
      "loss: 0.075748  [16000/ 2250]\n",
      "loss: 0.076610  [17600/ 2250]\n",
      "loss: 0.077134  [19200/ 2250]\n",
      "loss: 0.077729  [20800/ 2250]\n",
      "loss: 0.077032  [22400/ 2250]\n",
      "loss: 0.073754  [24000/ 2250]\n",
      "loss: 0.078022  [25600/ 2250]\n",
      "loss: 0.066379  [27200/ 2250]\n",
      "loss: 0.075197  [28800/ 2250]\n",
      "loss: 0.069378  [30400/ 2250]\n",
      "loss: 0.081207  [32000/ 2250]\n",
      "loss: 0.079058  [33600/ 2250]\n",
      "loss: 0.076709  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.1%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.073573  [    0/ 2250]\n",
      "loss: 0.075257  [ 1600/ 2250]\n",
      "loss: 0.079191  [ 3200/ 2250]\n",
      "loss: 0.073613  [ 4800/ 2250]\n",
      "loss: 0.075172  [ 6400/ 2250]\n",
      "loss: 0.075177  [ 8000/ 2250]\n",
      "loss: 0.065816  [ 9600/ 2250]\n",
      "loss: 0.068565  [11200/ 2250]\n",
      "loss: 0.075147  [12800/ 2250]\n",
      "loss: 0.074093  [14400/ 2250]\n",
      "loss: 0.066873  [16000/ 2250]\n",
      "loss: 0.079317  [17600/ 2250]\n",
      "loss: 0.076518  [19200/ 2250]\n",
      "loss: 0.067073  [20800/ 2250]\n",
      "loss: 0.075450  [22400/ 2250]\n",
      "loss: 0.064693  [24000/ 2250]\n",
      "loss: 0.073614  [25600/ 2250]\n",
      "loss: 0.070146  [27200/ 2250]\n",
      "loss: 0.071828  [28800/ 2250]\n",
      "loss: 0.066413  [30400/ 2250]\n",
      "loss: 0.063962  [32000/ 2250]\n",
      "loss: 0.067251  [33600/ 2250]\n",
      "loss: 0.076837  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.075483  [    0/ 2250]\n",
      "loss: 0.075789  [ 1600/ 2250]\n",
      "loss: 0.077737  [ 3200/ 2250]\n",
      "loss: 0.074027  [ 4800/ 2250]\n",
      "loss: 0.072198  [ 6400/ 2250]\n",
      "loss: 0.077520  [ 8000/ 2250]\n",
      "loss: 0.070945  [ 9600/ 2250]\n",
      "loss: 0.074335  [11200/ 2250]\n",
      "loss: 0.072305  [12800/ 2250]\n",
      "loss: 0.079876  [14400/ 2250]\n",
      "loss: 0.083375  [16000/ 2250]\n",
      "loss: 0.076144  [17600/ 2250]\n",
      "loss: 0.070106  [19200/ 2250]\n",
      "loss: 0.073191  [20800/ 2250]\n",
      "loss: 0.078042  [22400/ 2250]\n",
      "loss: 0.063908  [24000/ 2250]\n",
      "loss: 0.073468  [25600/ 2250]\n",
      "loss: 0.080391  [27200/ 2250]\n",
      "loss: 0.068929  [28800/ 2250]\n",
      "loss: 0.077055  [30400/ 2250]\n",
      "loss: 0.075928  [32000/ 2250]\n",
      "loss: 0.080542  [33600/ 2250]\n",
      "loss: 0.072114  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.4%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.076171  [    0/ 2250]\n",
      "loss: 0.068261  [ 1600/ 2250]\n",
      "loss: 0.071311  [ 3200/ 2250]\n",
      "loss: 0.072225  [ 4800/ 2250]\n",
      "loss: 0.071469  [ 6400/ 2250]\n",
      "loss: 0.077534  [ 8000/ 2250]\n",
      "loss: 0.081121  [ 9600/ 2250]\n",
      "loss: 0.075663  [11200/ 2250]\n",
      "loss: 0.073309  [12800/ 2250]\n",
      "loss: 0.068935  [14400/ 2250]\n",
      "loss: 0.074789  [16000/ 2250]\n",
      "loss: 0.073239  [17600/ 2250]\n",
      "loss: 0.067953  [19200/ 2250]\n",
      "loss: 0.072335  [20800/ 2250]\n",
      "loss: 0.074827  [22400/ 2250]\n",
      "loss: 0.082363  [24000/ 2250]\n",
      "loss: 0.066011  [25600/ 2250]\n",
      "loss: 0.075851  [27200/ 2250]\n",
      "loss: 0.074228  [28800/ 2250]\n",
      "loss: 0.075389  [30400/ 2250]\n",
      "loss: 0.073273  [32000/ 2250]\n",
      "loss: 0.080939  [33600/ 2250]\n",
      "loss: 0.077852  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.075546  [    0/ 2250]\n",
      "loss: 0.073956  [ 1600/ 2250]\n",
      "loss: 0.076544  [ 3200/ 2250]\n",
      "loss: 0.069561  [ 4800/ 2250]\n",
      "loss: 0.068147  [ 6400/ 2250]\n",
      "loss: 0.074931  [ 8000/ 2250]\n",
      "loss: 0.061043  [ 9600/ 2250]\n",
      "loss: 0.080305  [11200/ 2250]\n",
      "loss: 0.075766  [12800/ 2250]\n",
      "loss: 0.072649  [14400/ 2250]\n",
      "loss: 0.063257  [16000/ 2250]\n",
      "loss: 0.075739  [17600/ 2250]\n",
      "loss: 0.070526  [19200/ 2250]\n",
      "loss: 0.074369  [20800/ 2250]\n",
      "loss: 0.078275  [22400/ 2250]\n",
      "loss: 0.071620  [24000/ 2250]\n",
      "loss: 0.068245  [25600/ 2250]\n",
      "loss: 0.076699  [27200/ 2250]\n",
      "loss: 0.076812  [28800/ 2250]\n",
      "loss: 0.071076  [30400/ 2250]\n",
      "loss: 0.078589  [32000/ 2250]\n",
      "loss: 0.072224  [33600/ 2250]\n",
      "loss: 0.076346  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.067167  [    0/ 2250]\n",
      "loss: 0.067646  [ 1600/ 2250]\n",
      "loss: 0.070048  [ 3200/ 2250]\n",
      "loss: 0.075240  [ 4800/ 2250]\n",
      "loss: 0.078604  [ 6400/ 2250]\n",
      "loss: 0.074675  [ 8000/ 2250]\n",
      "loss: 0.069119  [ 9600/ 2250]\n",
      "loss: 0.073157  [11200/ 2250]\n",
      "loss: 0.073104  [12800/ 2250]\n",
      "loss: 0.076213  [14400/ 2250]\n",
      "loss: 0.069400  [16000/ 2250]\n",
      "loss: 0.073704  [17600/ 2250]\n",
      "loss: 0.071902  [19200/ 2250]\n",
      "loss: 0.072249  [20800/ 2250]\n",
      "loss: 0.078302  [22400/ 2250]\n",
      "loss: 0.074443  [24000/ 2250]\n",
      "loss: 0.078336  [25600/ 2250]\n",
      "loss: 0.075507  [27200/ 2250]\n",
      "loss: 0.079421  [28800/ 2250]\n",
      "loss: 0.066501  [30400/ 2250]\n",
      "loss: 0.077488  [32000/ 2250]\n",
      "loss: 0.075947  [33600/ 2250]\n",
      "loss: 0.076687  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.075481  [    0/ 2250]\n",
      "loss: 0.077126  [ 1600/ 2250]\n",
      "loss: 0.072981  [ 3200/ 2250]\n",
      "loss: 0.075271  [ 4800/ 2250]\n",
      "loss: 0.075060  [ 6400/ 2250]\n",
      "loss: 0.066747  [ 8000/ 2250]\n",
      "loss: 0.079672  [ 9600/ 2250]\n",
      "loss: 0.079435  [11200/ 2250]\n",
      "loss: 0.062888  [12800/ 2250]\n",
      "loss: 0.071161  [14400/ 2250]\n",
      "loss: 0.068699  [16000/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.077755  [17600/ 2250]\n",
      "loss: 0.074821  [19200/ 2250]\n",
      "loss: 0.075207  [20800/ 2250]\n",
      "loss: 0.062682  [22400/ 2250]\n",
      "loss: 0.076637  [24000/ 2250]\n",
      "loss: 0.075590  [25600/ 2250]\n",
      "loss: 0.070957  [27200/ 2250]\n",
      "loss: 0.081761  [28800/ 2250]\n",
      "loss: 0.077133  [30400/ 2250]\n",
      "loss: 0.068102  [32000/ 2250]\n",
      "loss: 0.082840  [33600/ 2250]\n",
      "loss: 0.076969  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.076144  [    0/ 2250]\n",
      "loss: 0.076682  [ 1600/ 2250]\n",
      "loss: 0.072150  [ 3200/ 2250]\n",
      "loss: 0.074875  [ 4800/ 2250]\n",
      "loss: 0.072277  [ 6400/ 2250]\n",
      "loss: 0.078831  [ 8000/ 2250]\n",
      "loss: 0.071853  [ 9600/ 2250]\n",
      "loss: 0.073575  [11200/ 2250]\n",
      "loss: 0.071717  [12800/ 2250]\n",
      "loss: 0.077442  [14400/ 2250]\n",
      "loss: 0.062098  [16000/ 2250]\n",
      "loss: 0.071189  [17600/ 2250]\n",
      "loss: 0.079017  [19200/ 2250]\n",
      "loss: 0.076053  [20800/ 2250]\n",
      "loss: 0.070165  [22400/ 2250]\n",
      "loss: 0.076321  [24000/ 2250]\n",
      "loss: 0.064136  [25600/ 2250]\n",
      "loss: 0.061902  [27200/ 2250]\n",
      "loss: 0.071930  [28800/ 2250]\n",
      "loss: 0.074710  [30400/ 2250]\n",
      "loss: 0.077993  [32000/ 2250]\n",
      "loss: 0.069225  [33600/ 2250]\n",
      "loss: 0.073587  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.7%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.075796  [    0/ 2250]\n",
      "loss: 0.073689  [ 1600/ 2250]\n",
      "loss: 0.069771  [ 3200/ 2250]\n",
      "loss: 0.067856  [ 4800/ 2250]\n",
      "loss: 0.078375  [ 6400/ 2250]\n",
      "loss: 0.082309  [ 8000/ 2250]\n",
      "loss: 0.077626  [ 9600/ 2250]\n",
      "loss: 0.068733  [11200/ 2250]\n",
      "loss: 0.074933  [12800/ 2250]\n",
      "loss: 0.070544  [14400/ 2250]\n",
      "loss: 0.073142  [16000/ 2250]\n",
      "loss: 0.066998  [17600/ 2250]\n",
      "loss: 0.064437  [19200/ 2250]\n",
      "loss: 0.072993  [20800/ 2250]\n",
      "loss: 0.074564  [22400/ 2250]\n",
      "loss: 0.074755  [24000/ 2250]\n",
      "loss: 0.063695  [25600/ 2250]\n",
      "loss: 0.076974  [27200/ 2250]\n",
      "loss: 0.074539  [28800/ 2250]\n",
      "loss: 0.066121  [30400/ 2250]\n",
      "loss: 0.072379  [32000/ 2250]\n",
      "loss: 0.077578  [33600/ 2250]\n",
      "loss: 0.071929  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.7%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.071437  [    0/ 2250]\n",
      "loss: 0.080485  [ 1600/ 2250]\n",
      "loss: 0.076169  [ 3200/ 2250]\n",
      "loss: 0.074669  [ 4800/ 2250]\n",
      "loss: 0.074446  [ 6400/ 2250]\n",
      "loss: 0.070720  [ 8000/ 2250]\n",
      "loss: 0.074199  [ 9600/ 2250]\n",
      "loss: 0.066106  [11200/ 2250]\n",
      "loss: 0.078200  [12800/ 2250]\n",
      "loss: 0.067092  [14400/ 2250]\n",
      "loss: 0.066332  [16000/ 2250]\n",
      "loss: 0.073642  [17600/ 2250]\n",
      "loss: 0.079599  [19200/ 2250]\n",
      "loss: 0.069145  [20800/ 2250]\n",
      "loss: 0.074275  [22400/ 2250]\n",
      "loss: 0.080076  [24000/ 2250]\n",
      "loss: 0.079918  [25600/ 2250]\n",
      "loss: 0.070054  [27200/ 2250]\n",
      "loss: 0.074918  [28800/ 2250]\n",
      "loss: 0.070207  [30400/ 2250]\n",
      "loss: 0.077469  [32000/ 2250]\n",
      "loss: 0.073975  [33600/ 2250]\n",
      "loss: 0.083958  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.078321  [    0/ 2250]\n",
      "loss: 0.064913  [ 1600/ 2250]\n",
      "loss: 0.053804  [ 3200/ 2250]\n",
      "loss: 0.078625  [ 4800/ 2250]\n",
      "loss: 0.073102  [ 6400/ 2250]\n",
      "loss: 0.078170  [ 8000/ 2250]\n",
      "loss: 0.082584  [ 9600/ 2250]\n",
      "loss: 0.075440  [11200/ 2250]\n",
      "loss: 0.076642  [12800/ 2250]\n",
      "loss: 0.066159  [14400/ 2250]\n",
      "loss: 0.072261  [16000/ 2250]\n",
      "loss: 0.070883  [17600/ 2250]\n",
      "loss: 0.075181  [19200/ 2250]\n",
      "loss: 0.081406  [20800/ 2250]\n",
      "loss: 0.075403  [22400/ 2250]\n",
      "loss: 0.068504  [24000/ 2250]\n",
      "loss: 0.067067  [25600/ 2250]\n",
      "loss: 0.082004  [27200/ 2250]\n",
      "loss: 0.072436  [28800/ 2250]\n",
      "loss: 0.073047  [30400/ 2250]\n",
      "loss: 0.071403  [32000/ 2250]\n",
      "loss: 0.072946  [33600/ 2250]\n",
      "loss: 0.067515  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.073777  [    0/ 2250]\n",
      "loss: 0.075831  [ 1600/ 2250]\n",
      "loss: 0.069201  [ 3200/ 2250]\n",
      "loss: 0.073398  [ 4800/ 2250]\n",
      "loss: 0.077185  [ 6400/ 2250]\n",
      "loss: 0.077764  [ 8000/ 2250]\n",
      "loss: 0.074020  [ 9600/ 2250]\n",
      "loss: 0.070578  [11200/ 2250]\n",
      "loss: 0.079094  [12800/ 2250]\n",
      "loss: 0.074827  [14400/ 2250]\n",
      "loss: 0.070738  [16000/ 2250]\n",
      "loss: 0.075207  [17600/ 2250]\n",
      "loss: 0.085912  [19200/ 2250]\n",
      "loss: 0.074092  [20800/ 2250]\n",
      "loss: 0.073986  [22400/ 2250]\n",
      "loss: 0.072009  [24000/ 2250]\n",
      "loss: 0.079570  [25600/ 2250]\n",
      "loss: 0.073215  [27200/ 2250]\n",
      "loss: 0.070307  [28800/ 2250]\n",
      "loss: 0.073863  [30400/ 2250]\n",
      "loss: 0.076326  [32000/ 2250]\n",
      "loss: 0.068503  [33600/ 2250]\n",
      "loss: 0.080928  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.079070  [    0/ 2250]\n",
      "loss: 0.066045  [ 1600/ 2250]\n",
      "loss: 0.070472  [ 3200/ 2250]\n",
      "loss: 0.077133  [ 4800/ 2250]\n",
      "loss: 0.071725  [ 6400/ 2250]\n",
      "loss: 0.075783  [ 8000/ 2250]\n",
      "loss: 0.074804  [ 9600/ 2250]\n",
      "loss: 0.076010  [11200/ 2250]\n",
      "loss: 0.069998  [12800/ 2250]\n",
      "loss: 0.069229  [14400/ 2250]\n",
      "loss: 0.064036  [16000/ 2250]\n",
      "loss: 0.078399  [17600/ 2250]\n",
      "loss: 0.062801  [19200/ 2250]\n",
      "loss: 0.078055  [20800/ 2250]\n",
      "loss: 0.077355  [22400/ 2250]\n",
      "loss: 0.080364  [24000/ 2250]\n",
      "loss: 0.067755  [25600/ 2250]\n",
      "loss: 0.072543  [27200/ 2250]\n",
      "loss: 0.071726  [28800/ 2250]\n",
      "loss: 0.071312  [30400/ 2250]\n",
      "loss: 0.070558  [32000/ 2250]\n",
      "loss: 0.074622  [33600/ 2250]\n",
      "loss: 0.074577  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 17.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.076549  [    0/ 2250]\n",
      "loss: 0.070952  [ 1600/ 2250]\n",
      "loss: 0.077156  [ 3200/ 2250]\n",
      "loss: 0.068467  [ 4800/ 2250]\n",
      "loss: 0.072382  [ 6400/ 2250]\n",
      "loss: 0.078597  [ 8000/ 2250]\n",
      "loss: 0.082290  [ 9600/ 2250]\n",
      "loss: 0.077339  [11200/ 2250]\n",
      "loss: 0.068373  [12800/ 2250]\n",
      "loss: 0.073703  [14400/ 2250]\n",
      "loss: 0.071276  [16000/ 2250]\n",
      "loss: 0.068159  [17600/ 2250]\n",
      "loss: 0.072376  [19200/ 2250]\n",
      "loss: 0.074860  [20800/ 2250]\n",
      "loss: 0.073807  [22400/ 2250]\n",
      "loss: 0.070930  [24000/ 2250]\n",
      "loss: 0.071702  [25600/ 2250]\n",
      "loss: 0.075341  [27200/ 2250]\n",
      "loss: 0.075442  [28800/ 2250]\n",
      "loss: 0.077012  [30400/ 2250]\n",
      "loss: 0.072268  [32000/ 2250]\n",
      "loss: 0.073942  [33600/ 2250]\n",
      "loss: 0.068162  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.072861  [    0/ 2250]\n",
      "loss: 0.074165  [ 1600/ 2250]\n",
      "loss: 0.081726  [ 3200/ 2250]\n",
      "loss: 0.072783  [ 4800/ 2250]\n",
      "loss: 0.075876  [ 6400/ 2250]\n",
      "loss: 0.073236  [ 8000/ 2250]\n",
      "loss: 0.068841  [ 9600/ 2250]\n",
      "loss: 0.079917  [11200/ 2250]\n",
      "loss: 0.074969  [12800/ 2250]\n",
      "loss: 0.074077  [14400/ 2250]\n",
      "loss: 0.067819  [16000/ 2250]\n",
      "loss: 0.076501  [17600/ 2250]\n",
      "loss: 0.076317  [19200/ 2250]\n",
      "loss: 0.075113  [20800/ 2250]\n",
      "loss: 0.071517  [22400/ 2250]\n",
      "loss: 0.076018  [24000/ 2250]\n",
      "loss: 0.079219  [25600/ 2250]\n",
      "loss: 0.075436  [27200/ 2250]\n",
      "loss: 0.083458  [28800/ 2250]\n",
      "loss: 0.070680  [30400/ 2250]\n",
      "loss: 0.073454  [32000/ 2250]\n",
      "loss: 0.069304  [33600/ 2250]\n",
      "loss: 0.074324  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.068882  [    0/ 2250]\n",
      "loss: 0.073282  [ 1600/ 2250]\n",
      "loss: 0.074407  [ 3200/ 2250]\n",
      "loss: 0.078872  [ 4800/ 2250]\n",
      "loss: 0.075838  [ 6400/ 2250]\n",
      "loss: 0.067165  [ 8000/ 2250]\n",
      "loss: 0.073274  [ 9600/ 2250]\n",
      "loss: 0.069052  [11200/ 2250]\n",
      "loss: 0.065546  [12800/ 2250]\n",
      "loss: 0.075869  [14400/ 2250]\n",
      "loss: 0.071818  [16000/ 2250]\n",
      "loss: 0.079777  [17600/ 2250]\n",
      "loss: 0.074367  [19200/ 2250]\n",
      "loss: 0.057820  [20800/ 2250]\n",
      "loss: 0.077743  [22400/ 2250]\n",
      "loss: 0.073857  [24000/ 2250]\n",
      "loss: 0.069328  [25600/ 2250]\n",
      "loss: 0.072468  [27200/ 2250]\n",
      "loss: 0.073379  [28800/ 2250]\n",
      "loss: 0.078665  [30400/ 2250]\n",
      "loss: 0.069510  [32000/ 2250]\n",
      "loss: 0.075410  [33600/ 2250]\n",
      "loss: 0.070827  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.069859  [    0/ 2250]\n",
      "loss: 0.059679  [ 1600/ 2250]\n",
      "loss: 0.076508  [ 3200/ 2250]\n",
      "loss: 0.067527  [ 4800/ 2250]\n",
      "loss: 0.076880  [ 6400/ 2250]\n",
      "loss: 0.072287  [ 8000/ 2250]\n",
      "loss: 0.081943  [ 9600/ 2250]\n",
      "loss: 0.072863  [11200/ 2250]\n",
      "loss: 0.067085  [12800/ 2250]\n",
      "loss: 0.068681  [14400/ 2250]\n",
      "loss: 0.073185  [16000/ 2250]\n",
      "loss: 0.075531  [17600/ 2250]\n",
      "loss: 0.077313  [19200/ 2250]\n",
      "loss: 0.069035  [20800/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.069731  [22400/ 2250]\n",
      "loss: 0.071418  [24000/ 2250]\n",
      "loss: 0.075165  [25600/ 2250]\n",
      "loss: 0.069474  [27200/ 2250]\n",
      "loss: 0.073427  [28800/ 2250]\n",
      "loss: 0.057636  [30400/ 2250]\n",
      "loss: 0.073126  [32000/ 2250]\n",
      "loss: 0.071675  [33600/ 2250]\n",
      "loss: 0.076640  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.071586  [    0/ 2250]\n",
      "loss: 0.067751  [ 1600/ 2250]\n",
      "loss: 0.069369  [ 3200/ 2250]\n",
      "loss: 0.078727  [ 4800/ 2250]\n",
      "loss: 0.077224  [ 6400/ 2250]\n",
      "loss: 0.071173  [ 8000/ 2250]\n",
      "loss: 0.078593  [ 9600/ 2250]\n",
      "loss: 0.077449  [11200/ 2250]\n",
      "loss: 0.076601  [12800/ 2250]\n",
      "loss: 0.081317  [14400/ 2250]\n",
      "loss: 0.069160  [16000/ 2250]\n",
      "loss: 0.074117  [17600/ 2250]\n",
      "loss: 0.068724  [19200/ 2250]\n",
      "loss: 0.073459  [20800/ 2250]\n",
      "loss: 0.078530  [22400/ 2250]\n",
      "loss: 0.066438  [24000/ 2250]\n",
      "loss: 0.078017  [25600/ 2250]\n",
      "loss: 0.081093  [27200/ 2250]\n",
      "loss: 0.066668  [28800/ 2250]\n",
      "loss: 0.071769  [30400/ 2250]\n",
      "loss: 0.074391  [32000/ 2250]\n",
      "loss: 0.073302  [33600/ 2250]\n",
      "loss: 0.067267  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.1%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.069846  [    0/ 2250]\n",
      "loss: 0.078953  [ 1600/ 2250]\n",
      "loss: 0.067331  [ 3200/ 2250]\n",
      "loss: 0.076801  [ 4800/ 2250]\n",
      "loss: 0.075709  [ 6400/ 2250]\n",
      "loss: 0.071728  [ 8000/ 2250]\n",
      "loss: 0.074360  [ 9600/ 2250]\n",
      "loss: 0.065852  [11200/ 2250]\n",
      "loss: 0.078646  [12800/ 2250]\n",
      "loss: 0.077615  [14400/ 2250]\n",
      "loss: 0.079621  [16000/ 2250]\n",
      "loss: 0.069062  [17600/ 2250]\n",
      "loss: 0.070388  [19200/ 2250]\n",
      "loss: 0.074096  [20800/ 2250]\n",
      "loss: 0.075636  [22400/ 2250]\n",
      "loss: 0.078079  [24000/ 2250]\n",
      "loss: 0.067100  [25600/ 2250]\n",
      "loss: 0.074521  [27200/ 2250]\n",
      "loss: 0.078377  [28800/ 2250]\n",
      "loss: 0.075277  [30400/ 2250]\n",
      "loss: 0.072250  [32000/ 2250]\n",
      "loss: 0.068031  [33600/ 2250]\n",
      "loss: 0.075838  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.1%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.075006  [    0/ 2250]\n",
      "loss: 0.078832  [ 1600/ 2250]\n",
      "loss: 0.077746  [ 3200/ 2250]\n",
      "loss: 0.073505  [ 4800/ 2250]\n",
      "loss: 0.067953  [ 6400/ 2250]\n",
      "loss: 0.071438  [ 8000/ 2250]\n",
      "loss: 0.073238  [ 9600/ 2250]\n",
      "loss: 0.069032  [11200/ 2250]\n",
      "loss: 0.070443  [12800/ 2250]\n",
      "loss: 0.071221  [14400/ 2250]\n",
      "loss: 0.073889  [16000/ 2250]\n",
      "loss: 0.073099  [17600/ 2250]\n",
      "loss: 0.066127  [19200/ 2250]\n",
      "loss: 0.080574  [20800/ 2250]\n",
      "loss: 0.073847  [22400/ 2250]\n",
      "loss: 0.076484  [24000/ 2250]\n",
      "loss: 0.076086  [25600/ 2250]\n",
      "loss: 0.065875  [27200/ 2250]\n",
      "loss: 0.071591  [28800/ 2250]\n",
      "loss: 0.077835  [30400/ 2250]\n",
      "loss: 0.068827  [32000/ 2250]\n",
      "loss: 0.072661  [33600/ 2250]\n",
      "loss: 0.066170  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.070292  [    0/ 2250]\n",
      "loss: 0.073788  [ 1600/ 2250]\n",
      "loss: 0.073445  [ 3200/ 2250]\n",
      "loss: 0.071069  [ 4800/ 2250]\n",
      "loss: 0.072472  [ 6400/ 2250]\n",
      "loss: 0.073183  [ 8000/ 2250]\n",
      "loss: 0.065823  [ 9600/ 2250]\n",
      "loss: 0.078704  [11200/ 2250]\n",
      "loss: 0.075720  [12800/ 2250]\n",
      "loss: 0.066727  [14400/ 2250]\n",
      "loss: 0.073971  [16000/ 2250]\n",
      "loss: 0.075750  [17600/ 2250]\n",
      "loss: 0.077656  [19200/ 2250]\n",
      "loss: 0.058461  [20800/ 2250]\n",
      "loss: 0.079548  [22400/ 2250]\n",
      "loss: 0.063507  [24000/ 2250]\n",
      "loss: 0.073201  [25600/ 2250]\n",
      "loss: 0.071634  [27200/ 2250]\n",
      "loss: 0.073327  [28800/ 2250]\n",
      "loss: 0.075819  [30400/ 2250]\n",
      "loss: 0.069698  [32000/ 2250]\n",
      "loss: 0.070050  [33600/ 2250]\n",
      "loss: 0.078691  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.074784  [    0/ 2250]\n",
      "loss: 0.075428  [ 1600/ 2250]\n",
      "loss: 0.075845  [ 3200/ 2250]\n",
      "loss: 0.074794  [ 4800/ 2250]\n",
      "loss: 0.077754  [ 6400/ 2250]\n",
      "loss: 0.072249  [ 8000/ 2250]\n",
      "loss: 0.065219  [ 9600/ 2250]\n",
      "loss: 0.065595  [11200/ 2250]\n",
      "loss: 0.073248  [12800/ 2250]\n",
      "loss: 0.076162  [14400/ 2250]\n",
      "loss: 0.078020  [16000/ 2250]\n",
      "loss: 0.077748  [17600/ 2250]\n",
      "loss: 0.070850  [19200/ 2250]\n",
      "loss: 0.075101  [20800/ 2250]\n",
      "loss: 0.080325  [22400/ 2250]\n",
      "loss: 0.065566  [24000/ 2250]\n",
      "loss: 0.069070  [25600/ 2250]\n",
      "loss: 0.073902  [27200/ 2250]\n",
      "loss: 0.077848  [28800/ 2250]\n",
      "loss: 0.080559  [30400/ 2250]\n",
      "loss: 0.072869  [32000/ 2250]\n",
      "loss: 0.075923  [33600/ 2250]\n",
      "loss: 0.075353  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.2%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.068284  [    0/ 2250]\n",
      "loss: 0.074209  [ 1600/ 2250]\n",
      "loss: 0.071572  [ 3200/ 2250]\n",
      "loss: 0.074684  [ 4800/ 2250]\n",
      "loss: 0.072881  [ 6400/ 2250]\n",
      "loss: 0.069750  [ 8000/ 2250]\n",
      "loss: 0.071640  [ 9600/ 2250]\n",
      "loss: 0.071584  [11200/ 2250]\n",
      "loss: 0.083829  [12800/ 2250]\n",
      "loss: 0.072636  [14400/ 2250]\n",
      "loss: 0.068363  [16000/ 2250]\n",
      "loss: 0.077640  [17600/ 2250]\n",
      "loss: 0.070186  [19200/ 2250]\n",
      "loss: 0.069932  [20800/ 2250]\n",
      "loss: 0.078332  [22400/ 2250]\n",
      "loss: 0.074730  [24000/ 2250]\n",
      "loss: 0.074525  [25600/ 2250]\n",
      "loss: 0.074542  [27200/ 2250]\n",
      "loss: 0.071344  [28800/ 2250]\n",
      "loss: 0.069027  [30400/ 2250]\n",
      "loss: 0.064958  [32000/ 2250]\n",
      "loss: 0.072915  [33600/ 2250]\n",
      "loss: 0.069763  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.3%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.068355  [    0/ 2250]\n",
      "loss: 0.062808  [ 1600/ 2250]\n",
      "loss: 0.073207  [ 3200/ 2250]\n",
      "loss: 0.074786  [ 4800/ 2250]\n",
      "loss: 0.076137  [ 6400/ 2250]\n",
      "loss: 0.072716  [ 8000/ 2250]\n",
      "loss: 0.076960  [ 9600/ 2250]\n",
      "loss: 0.067063  [11200/ 2250]\n",
      "loss: 0.079716  [12800/ 2250]\n",
      "loss: 0.074916  [14400/ 2250]\n",
      "loss: 0.075447  [16000/ 2250]\n",
      "loss: 0.075733  [17600/ 2250]\n",
      "loss: 0.070899  [19200/ 2250]\n",
      "loss: 0.066556  [20800/ 2250]\n",
      "loss: 0.074085  [22400/ 2250]\n",
      "loss: 0.072685  [24000/ 2250]\n",
      "loss: 0.071820  [25600/ 2250]\n",
      "loss: 0.073748  [27200/ 2250]\n",
      "loss: 0.072783  [28800/ 2250]\n",
      "loss: 0.074534  [30400/ 2250]\n",
      "loss: 0.067766  [32000/ 2250]\n",
      "loss: 0.075413  [33600/ 2250]\n",
      "loss: 0.073731  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.071854  [    0/ 2250]\n",
      "loss: 0.070301  [ 1600/ 2250]\n",
      "loss: 0.070904  [ 3200/ 2250]\n",
      "loss: 0.078805  [ 4800/ 2250]\n",
      "loss: 0.078195  [ 6400/ 2250]\n",
      "loss: 0.077498  [ 8000/ 2250]\n",
      "loss: 0.073547  [ 9600/ 2250]\n",
      "loss: 0.078382  [11200/ 2250]\n",
      "loss: 0.078083  [12800/ 2250]\n",
      "loss: 0.071978  [14400/ 2250]\n",
      "loss: 0.069721  [16000/ 2250]\n",
      "loss: 0.076592  [17600/ 2250]\n",
      "loss: 0.074306  [19200/ 2250]\n",
      "loss: 0.077741  [20800/ 2250]\n",
      "loss: 0.081210  [22400/ 2250]\n",
      "loss: 0.061868  [24000/ 2250]\n",
      "loss: 0.072711  [25600/ 2250]\n",
      "loss: 0.069856  [27200/ 2250]\n",
      "loss: 0.080354  [28800/ 2250]\n",
      "loss: 0.078604  [30400/ 2250]\n",
      "loss: 0.080941  [32000/ 2250]\n",
      "loss: 0.070855  [33600/ 2250]\n",
      "loss: 0.076022  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.4%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.073316  [    0/ 2250]\n",
      "loss: 0.074837  [ 1600/ 2250]\n",
      "loss: 0.071353  [ 3200/ 2250]\n",
      "loss: 0.073522  [ 4800/ 2250]\n",
      "loss: 0.073582  [ 6400/ 2250]\n",
      "loss: 0.080014  [ 8000/ 2250]\n",
      "loss: 0.075378  [ 9600/ 2250]\n",
      "loss: 0.078083  [11200/ 2250]\n",
      "loss: 0.070275  [12800/ 2250]\n",
      "loss: 0.067498  [14400/ 2250]\n",
      "loss: 0.070947  [16000/ 2250]\n",
      "loss: 0.069823  [17600/ 2250]\n",
      "loss: 0.078390  [19200/ 2250]\n",
      "loss: 0.072382  [20800/ 2250]\n",
      "loss: 0.083824  [22400/ 2250]\n",
      "loss: 0.070741  [24000/ 2250]\n",
      "loss: 0.064735  [25600/ 2250]\n",
      "loss: 0.071565  [27200/ 2250]\n",
      "loss: 0.078040  [28800/ 2250]\n",
      "loss: 0.080197  [30400/ 2250]\n",
      "loss: 0.076145  [32000/ 2250]\n",
      "loss: 0.075173  [33600/ 2250]\n",
      "loss: 0.075684  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.5%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.064689  [    0/ 2250]\n",
      "loss: 0.071427  [ 1600/ 2250]\n",
      "loss: 0.071155  [ 3200/ 2250]\n",
      "loss: 0.069642  [ 4800/ 2250]\n",
      "loss: 0.074926  [ 6400/ 2250]\n",
      "loss: 0.063681  [ 8000/ 2250]\n",
      "loss: 0.072896  [ 9600/ 2250]\n",
      "loss: 0.066403  [11200/ 2250]\n",
      "loss: 0.075628  [12800/ 2250]\n",
      "loss: 0.078151  [14400/ 2250]\n",
      "loss: 0.081843  [16000/ 2250]\n",
      "loss: 0.069807  [17600/ 2250]\n",
      "loss: 0.070884  [19200/ 2250]\n",
      "loss: 0.076476  [20800/ 2250]\n",
      "loss: 0.081288  [22400/ 2250]\n",
      "loss: 0.069893  [24000/ 2250]\n",
      "loss: 0.087033  [25600/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.071455  [27200/ 2250]\n",
      "loss: 0.069436  [28800/ 2250]\n",
      "loss: 0.071673  [30400/ 2250]\n",
      "loss: 0.075963  [32000/ 2250]\n",
      "loss: 0.079163  [33600/ 2250]\n",
      "loss: 0.072639  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.4%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.080763  [    0/ 2250]\n",
      "loss: 0.077480  [ 1600/ 2250]\n",
      "loss: 0.069932  [ 3200/ 2250]\n",
      "loss: 0.071323  [ 4800/ 2250]\n",
      "loss: 0.072591  [ 6400/ 2250]\n",
      "loss: 0.070769  [ 8000/ 2250]\n",
      "loss: 0.072259  [ 9600/ 2250]\n",
      "loss: 0.070804  [11200/ 2250]\n",
      "loss: 0.074268  [12800/ 2250]\n",
      "loss: 0.067586  [14400/ 2250]\n",
      "loss: 0.070520  [16000/ 2250]\n",
      "loss: 0.080120  [17600/ 2250]\n",
      "loss: 0.087525  [19200/ 2250]\n",
      "loss: 0.075590  [20800/ 2250]\n",
      "loss: 0.073325  [22400/ 2250]\n",
      "loss: 0.073982  [24000/ 2250]\n",
      "loss: 0.071759  [25600/ 2250]\n",
      "loss: 0.076244  [27200/ 2250]\n",
      "loss: 0.069125  [28800/ 2250]\n",
      "loss: 0.077931  [30400/ 2250]\n",
      "loss: 0.069301  [32000/ 2250]\n",
      "loss: 0.066165  [33600/ 2250]\n",
      "loss: 0.079193  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.066884  [    0/ 2250]\n",
      "loss: 0.066530  [ 1600/ 2250]\n",
      "loss: 0.071829  [ 3200/ 2250]\n",
      "loss: 0.071964  [ 4800/ 2250]\n",
      "loss: 0.075737  [ 6400/ 2250]\n",
      "loss: 0.081807  [ 8000/ 2250]\n",
      "loss: 0.073545  [ 9600/ 2250]\n",
      "loss: 0.072019  [11200/ 2250]\n",
      "loss: 0.066668  [12800/ 2250]\n",
      "loss: 0.076915  [14400/ 2250]\n",
      "loss: 0.072149  [16000/ 2250]\n",
      "loss: 0.070973  [17600/ 2250]\n",
      "loss: 0.068904  [19200/ 2250]\n",
      "loss: 0.066247  [20800/ 2250]\n",
      "loss: 0.073356  [22400/ 2250]\n",
      "loss: 0.075300  [24000/ 2250]\n",
      "loss: 0.075945  [25600/ 2250]\n",
      "loss: 0.069561  [27200/ 2250]\n",
      "loss: 0.070297  [28800/ 2250]\n",
      "loss: 0.071979  [30400/ 2250]\n",
      "loss: 0.072849  [32000/ 2250]\n",
      "loss: 0.065665  [33600/ 2250]\n",
      "loss: 0.071846  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.4%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.072024  [    0/ 2250]\n",
      "loss: 0.078298  [ 1600/ 2250]\n",
      "loss: 0.069173  [ 3200/ 2250]\n",
      "loss: 0.075914  [ 4800/ 2250]\n",
      "loss: 0.074363  [ 6400/ 2250]\n",
      "loss: 0.078863  [ 8000/ 2250]\n",
      "loss: 0.067895  [ 9600/ 2250]\n",
      "loss: 0.069543  [11200/ 2250]\n",
      "loss: 0.082853  [12800/ 2250]\n",
      "loss: 0.073146  [14400/ 2250]\n",
      "loss: 0.070145  [16000/ 2250]\n",
      "loss: 0.073455  [17600/ 2250]\n",
      "loss: 0.077661  [19200/ 2250]\n",
      "loss: 0.074617  [20800/ 2250]\n",
      "loss: 0.074026  [22400/ 2250]\n",
      "loss: 0.077527  [24000/ 2250]\n",
      "loss: 0.081957  [25600/ 2250]\n",
      "loss: 0.084518  [27200/ 2250]\n",
      "loss: 0.078245  [28800/ 2250]\n",
      "loss: 0.059559  [30400/ 2250]\n",
      "loss: 0.069659  [32000/ 2250]\n",
      "loss: 0.070882  [33600/ 2250]\n",
      "loss: 0.060479  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.066384  [    0/ 2250]\n",
      "loss: 0.079269  [ 1600/ 2250]\n",
      "loss: 0.075574  [ 3200/ 2250]\n",
      "loss: 0.073020  [ 4800/ 2250]\n",
      "loss: 0.069718  [ 6400/ 2250]\n",
      "loss: 0.075674  [ 8000/ 2250]\n",
      "loss: 0.068280  [ 9600/ 2250]\n",
      "loss: 0.071141  [11200/ 2250]\n",
      "loss: 0.075458  [12800/ 2250]\n",
      "loss: 0.070637  [14400/ 2250]\n",
      "loss: 0.071772  [16000/ 2250]\n",
      "loss: 0.077381  [17600/ 2250]\n",
      "loss: 0.065849  [19200/ 2250]\n",
      "loss: 0.072407  [20800/ 2250]\n",
      "loss: 0.072263  [22400/ 2250]\n",
      "loss: 0.082230  [24000/ 2250]\n",
      "loss: 0.073463  [25600/ 2250]\n",
      "loss: 0.074598  [27200/ 2250]\n",
      "loss: 0.078800  [28800/ 2250]\n",
      "loss: 0.070233  [30400/ 2250]\n",
      "loss: 0.066524  [32000/ 2250]\n",
      "loss: 0.077235  [33600/ 2250]\n",
      "loss: 0.078838  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.5%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.065342  [    0/ 2250]\n",
      "loss: 0.074451  [ 1600/ 2250]\n",
      "loss: 0.076616  [ 3200/ 2250]\n",
      "loss: 0.074602  [ 4800/ 2250]\n",
      "loss: 0.082277  [ 6400/ 2250]\n",
      "loss: 0.070622  [ 8000/ 2250]\n",
      "loss: 0.070913  [ 9600/ 2250]\n",
      "loss: 0.082530  [11200/ 2250]\n",
      "loss: 0.073372  [12800/ 2250]\n",
      "loss: 0.069604  [14400/ 2250]\n",
      "loss: 0.075044  [16000/ 2250]\n",
      "loss: 0.069522  [17600/ 2250]\n",
      "loss: 0.077272  [19200/ 2250]\n",
      "loss: 0.070203  [20800/ 2250]\n",
      "loss: 0.071926  [22400/ 2250]\n",
      "loss: 0.077787  [24000/ 2250]\n",
      "loss: 0.072796  [25600/ 2250]\n",
      "loss: 0.073468  [27200/ 2250]\n",
      "loss: 0.079271  [28800/ 2250]\n",
      "loss: 0.071125  [30400/ 2250]\n",
      "loss: 0.077262  [32000/ 2250]\n",
      "loss: 0.078572  [33600/ 2250]\n",
      "loss: 0.070174  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.078080  [    0/ 2250]\n",
      "loss: 0.072593  [ 1600/ 2250]\n",
      "loss: 0.066433  [ 3200/ 2250]\n",
      "loss: 0.072305  [ 4800/ 2250]\n",
      "loss: 0.074478  [ 6400/ 2250]\n",
      "loss: 0.075989  [ 8000/ 2250]\n",
      "loss: 0.067612  [ 9600/ 2250]\n",
      "loss: 0.077580  [11200/ 2250]\n",
      "loss: 0.074248  [12800/ 2250]\n",
      "loss: 0.077739  [14400/ 2250]\n",
      "loss: 0.072779  [16000/ 2250]\n",
      "loss: 0.067630  [17600/ 2250]\n",
      "loss: 0.074648  [19200/ 2250]\n",
      "loss: 0.078072  [20800/ 2250]\n",
      "loss: 0.075894  [22400/ 2250]\n",
      "loss: 0.075308  [24000/ 2250]\n",
      "loss: 0.073550  [25600/ 2250]\n",
      "loss: 0.072936  [27200/ 2250]\n",
      "loss: 0.077159  [28800/ 2250]\n",
      "loss: 0.078995  [30400/ 2250]\n",
      "loss: 0.075813  [32000/ 2250]\n",
      "loss: 0.069545  [33600/ 2250]\n",
      "loss: 0.076211  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.070842  [    0/ 2250]\n",
      "loss: 0.067843  [ 1600/ 2250]\n",
      "loss: 0.071368  [ 3200/ 2250]\n",
      "loss: 0.078422  [ 4800/ 2250]\n",
      "loss: 0.073688  [ 6400/ 2250]\n",
      "loss: 0.073170  [ 8000/ 2250]\n",
      "loss: 0.069175  [ 9600/ 2250]\n",
      "loss: 0.074605  [11200/ 2250]\n",
      "loss: 0.075458  [12800/ 2250]\n",
      "loss: 0.077018  [14400/ 2250]\n",
      "loss: 0.078355  [16000/ 2250]\n",
      "loss: 0.069744  [17600/ 2250]\n",
      "loss: 0.079170  [19200/ 2250]\n",
      "loss: 0.075039  [20800/ 2250]\n",
      "loss: 0.068666  [22400/ 2250]\n",
      "loss: 0.071822  [24000/ 2250]\n",
      "loss: 0.072462  [25600/ 2250]\n",
      "loss: 0.072531  [27200/ 2250]\n",
      "loss: 0.065259  [28800/ 2250]\n",
      "loss: 0.070324  [30400/ 2250]\n",
      "loss: 0.080719  [32000/ 2250]\n",
      "loss: 0.064747  [33600/ 2250]\n",
      "loss: 0.074164  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.7%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.076875  [    0/ 2250]\n",
      "loss: 0.077809  [ 1600/ 2250]\n",
      "loss: 0.077862  [ 3200/ 2250]\n",
      "loss: 0.061865  [ 4800/ 2250]\n",
      "loss: 0.069577  [ 6400/ 2250]\n",
      "loss: 0.080560  [ 8000/ 2250]\n",
      "loss: 0.075008  [ 9600/ 2250]\n",
      "loss: 0.070667  [11200/ 2250]\n",
      "loss: 0.068731  [12800/ 2250]\n",
      "loss: 0.075601  [14400/ 2250]\n",
      "loss: 0.075110  [16000/ 2250]\n",
      "loss: 0.066111  [17600/ 2250]\n",
      "loss: 0.080027  [19200/ 2250]\n",
      "loss: 0.074624  [20800/ 2250]\n",
      "loss: 0.078336  [22400/ 2250]\n",
      "loss: 0.066049  [24000/ 2250]\n",
      "loss: 0.070402  [25600/ 2250]\n",
      "loss: 0.076568  [27200/ 2250]\n",
      "loss: 0.076920  [28800/ 2250]\n",
      "loss: 0.079124  [30400/ 2250]\n",
      "loss: 0.067722  [32000/ 2250]\n",
      "loss: 0.072716  [33600/ 2250]\n",
      "loss: 0.069185  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.073301  [    0/ 2250]\n",
      "loss: 0.078726  [ 1600/ 2250]\n",
      "loss: 0.077129  [ 3200/ 2250]\n",
      "loss: 0.069438  [ 4800/ 2250]\n",
      "loss: 0.070101  [ 6400/ 2250]\n",
      "loss: 0.071807  [ 8000/ 2250]\n",
      "loss: 0.071312  [ 9600/ 2250]\n",
      "loss: 0.078592  [11200/ 2250]\n",
      "loss: 0.068049  [12800/ 2250]\n",
      "loss: 0.082537  [14400/ 2250]\n",
      "loss: 0.069183  [16000/ 2250]\n",
      "loss: 0.072604  [17600/ 2250]\n",
      "loss: 0.071801  [19200/ 2250]\n",
      "loss: 0.077577  [20800/ 2250]\n",
      "loss: 0.077220  [22400/ 2250]\n",
      "loss: 0.079925  [24000/ 2250]\n",
      "loss: 0.067520  [25600/ 2250]\n",
      "loss: 0.072978  [27200/ 2250]\n",
      "loss: 0.070378  [28800/ 2250]\n",
      "loss: 0.070611  [30400/ 2250]\n",
      "loss: 0.073624  [32000/ 2250]\n",
      "loss: 0.068237  [33600/ 2250]\n",
      "loss: 0.073072  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.7%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.068918  [    0/ 2250]\n",
      "loss: 0.069276  [ 1600/ 2250]\n",
      "loss: 0.069819  [ 3200/ 2250]\n",
      "loss: 0.063340  [ 4800/ 2250]\n",
      "loss: 0.076567  [ 6400/ 2250]\n",
      "loss: 0.072790  [ 8000/ 2250]\n",
      "loss: 0.070071  [ 9600/ 2250]\n",
      "loss: 0.063016  [11200/ 2250]\n",
      "loss: 0.069235  [12800/ 2250]\n",
      "loss: 0.074570  [14400/ 2250]\n",
      "loss: 0.076863  [16000/ 2250]\n",
      "loss: 0.076575  [17600/ 2250]\n",
      "loss: 0.074196  [19200/ 2250]\n",
      "loss: 0.069905  [20800/ 2250]\n",
      "loss: 0.071044  [22400/ 2250]\n",
      "loss: 0.068742  [24000/ 2250]\n",
      "loss: 0.069977  [25600/ 2250]\n",
      "loss: 0.080568  [27200/ 2250]\n",
      "loss: 0.082139  [28800/ 2250]\n",
      "loss: 0.073494  [30400/ 2250]\n",
      "loss: 0.071372  [32000/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.076773  [33600/ 2250]\n",
      "loss: 0.080716  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.078340  [    0/ 2250]\n",
      "loss: 0.077293  [ 1600/ 2250]\n",
      "loss: 0.072254  [ 3200/ 2250]\n",
      "loss: 0.070802  [ 4800/ 2250]\n",
      "loss: 0.078236  [ 6400/ 2250]\n",
      "loss: 0.072041  [ 8000/ 2250]\n",
      "loss: 0.080031  [ 9600/ 2250]\n",
      "loss: 0.072277  [11200/ 2250]\n",
      "loss: 0.076768  [12800/ 2250]\n",
      "loss: 0.079298  [14400/ 2250]\n",
      "loss: 0.072668  [16000/ 2250]\n",
      "loss: 0.078039  [17600/ 2250]\n",
      "loss: 0.070568  [19200/ 2250]\n",
      "loss: 0.073073  [20800/ 2250]\n",
      "loss: 0.071590  [22400/ 2250]\n",
      "loss: 0.069308  [24000/ 2250]\n",
      "loss: 0.074207  [25600/ 2250]\n",
      "loss: 0.080982  [27200/ 2250]\n",
      "loss: 0.075193  [28800/ 2250]\n",
      "loss: 0.079600  [30400/ 2250]\n",
      "loss: 0.064208  [32000/ 2250]\n",
      "loss: 0.069510  [33600/ 2250]\n",
      "loss: 0.070140  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.6%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.064912  [    0/ 2250]\n",
      "loss: 0.074100  [ 1600/ 2250]\n",
      "loss: 0.071646  [ 3200/ 2250]\n",
      "loss: 0.067105  [ 4800/ 2250]\n",
      "loss: 0.073758  [ 6400/ 2250]\n",
      "loss: 0.068867  [ 8000/ 2250]\n",
      "loss: 0.076239  [ 9600/ 2250]\n",
      "loss: 0.075640  [11200/ 2250]\n",
      "loss: 0.075754  [12800/ 2250]\n",
      "loss: 0.071154  [14400/ 2250]\n",
      "loss: 0.074506  [16000/ 2250]\n",
      "loss: 0.074259  [17600/ 2250]\n",
      "loss: 0.073993  [19200/ 2250]\n",
      "loss: 0.076734  [20800/ 2250]\n",
      "loss: 0.073486  [22400/ 2250]\n",
      "loss: 0.070913  [24000/ 2250]\n",
      "loss: 0.063082  [25600/ 2250]\n",
      "loss: 0.067312  [27200/ 2250]\n",
      "loss: 0.080567  [28800/ 2250]\n",
      "loss: 0.074937  [30400/ 2250]\n",
      "loss: 0.069050  [32000/ 2250]\n",
      "loss: 0.076336  [33600/ 2250]\n",
      "loss: 0.077936  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.070654  [    0/ 2250]\n",
      "loss: 0.065610  [ 1600/ 2250]\n",
      "loss: 0.068240  [ 3200/ 2250]\n",
      "loss: 0.064782  [ 4800/ 2250]\n",
      "loss: 0.069744  [ 6400/ 2250]\n",
      "loss: 0.068306  [ 8000/ 2250]\n",
      "loss: 0.068996  [ 9600/ 2250]\n",
      "loss: 0.070388  [11200/ 2250]\n",
      "loss: 0.064462  [12800/ 2250]\n",
      "loss: 0.075757  [14400/ 2250]\n",
      "loss: 0.064624  [16000/ 2250]\n",
      "loss: 0.071538  [17600/ 2250]\n",
      "loss: 0.072838  [19200/ 2250]\n",
      "loss: 0.072774  [20800/ 2250]\n",
      "loss: 0.071597  [22400/ 2250]\n",
      "loss: 0.072071  [24000/ 2250]\n",
      "loss: 0.074066  [25600/ 2250]\n",
      "loss: 0.067330  [27200/ 2250]\n",
      "loss: 0.072809  [28800/ 2250]\n",
      "loss: 0.081791  [30400/ 2250]\n",
      "loss: 0.059428  [32000/ 2250]\n",
      "loss: 0.072065  [33600/ 2250]\n",
      "loss: 0.063905  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.7%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.072275  [    0/ 2250]\n",
      "loss: 0.070445  [ 1600/ 2250]\n",
      "loss: 0.068800  [ 3200/ 2250]\n",
      "loss: 0.073500  [ 4800/ 2250]\n",
      "loss: 0.075280  [ 6400/ 2250]\n",
      "loss: 0.074669  [ 8000/ 2250]\n",
      "loss: 0.066957  [ 9600/ 2250]\n",
      "loss: 0.081676  [11200/ 2250]\n",
      "loss: 0.075920  [12800/ 2250]\n",
      "loss: 0.066027  [14400/ 2250]\n",
      "loss: 0.073434  [16000/ 2250]\n",
      "loss: 0.070442  [17600/ 2250]\n",
      "loss: 0.077112  [19200/ 2250]\n",
      "loss: 0.074521  [20800/ 2250]\n",
      "loss: 0.076990  [22400/ 2250]\n",
      "loss: 0.074002  [24000/ 2250]\n",
      "loss: 0.078045  [25600/ 2250]\n",
      "loss: 0.072507  [27200/ 2250]\n",
      "loss: 0.066358  [28800/ 2250]\n",
      "loss: 0.076200  [30400/ 2250]\n",
      "loss: 0.071772  [32000/ 2250]\n",
      "loss: 0.067599  [33600/ 2250]\n",
      "loss: 0.077696  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.069783  [    0/ 2250]\n",
      "loss: 0.077778  [ 1600/ 2250]\n",
      "loss: 0.077210  [ 3200/ 2250]\n",
      "loss: 0.066284  [ 4800/ 2250]\n",
      "loss: 0.078649  [ 6400/ 2250]\n",
      "loss: 0.069341  [ 8000/ 2250]\n",
      "loss: 0.078167  [ 9600/ 2250]\n",
      "loss: 0.068436  [11200/ 2250]\n",
      "loss: 0.073586  [12800/ 2250]\n",
      "loss: 0.073904  [14400/ 2250]\n",
      "loss: 0.067184  [16000/ 2250]\n",
      "loss: 0.070944  [17600/ 2250]\n",
      "loss: 0.061354  [19200/ 2250]\n",
      "loss: 0.063151  [20800/ 2250]\n",
      "loss: 0.071495  [22400/ 2250]\n",
      "loss: 0.075145  [24000/ 2250]\n",
      "loss: 0.075884  [25600/ 2250]\n",
      "loss: 0.065985  [27200/ 2250]\n",
      "loss: 0.064797  [28800/ 2250]\n",
      "loss: 0.069643  [30400/ 2250]\n",
      "loss: 0.077105  [32000/ 2250]\n",
      "loss: 0.076194  [33600/ 2250]\n",
      "loss: 0.077206  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.070330  [    0/ 2250]\n",
      "loss: 0.083213  [ 1600/ 2250]\n",
      "loss: 0.073054  [ 3200/ 2250]\n",
      "loss: 0.069905  [ 4800/ 2250]\n",
      "loss: 0.068340  [ 6400/ 2250]\n",
      "loss: 0.077463  [ 8000/ 2250]\n",
      "loss: 0.070720  [ 9600/ 2250]\n",
      "loss: 0.078870  [11200/ 2250]\n",
      "loss: 0.060918  [12800/ 2250]\n",
      "loss: 0.068198  [14400/ 2250]\n",
      "loss: 0.071948  [16000/ 2250]\n",
      "loss: 0.070759  [17600/ 2250]\n",
      "loss: 0.074106  [19200/ 2250]\n",
      "loss: 0.074265  [20800/ 2250]\n",
      "loss: 0.077096  [22400/ 2250]\n",
      "loss: 0.073822  [24000/ 2250]\n",
      "loss: 0.067009  [25600/ 2250]\n",
      "loss: 0.077503  [27200/ 2250]\n",
      "loss: 0.077197  [28800/ 2250]\n",
      "loss: 0.073626  [30400/ 2250]\n",
      "loss: 0.073357  [32000/ 2250]\n",
      "loss: 0.077306  [33600/ 2250]\n",
      "loss: 0.081122  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.076476  [    0/ 2250]\n",
      "loss: 0.069287  [ 1600/ 2250]\n",
      "loss: 0.071214  [ 3200/ 2250]\n",
      "loss: 0.068619  [ 4800/ 2250]\n",
      "loss: 0.068457  [ 6400/ 2250]\n",
      "loss: 0.069055  [ 8000/ 2250]\n",
      "loss: 0.076452  [ 9600/ 2250]\n",
      "loss: 0.066870  [11200/ 2250]\n",
      "loss: 0.070211  [12800/ 2250]\n",
      "loss: 0.077009  [14400/ 2250]\n",
      "loss: 0.066170  [16000/ 2250]\n",
      "loss: 0.061407  [17600/ 2250]\n",
      "loss: 0.057831  [19200/ 2250]\n",
      "loss: 0.067131  [20800/ 2250]\n",
      "loss: 0.067569  [22400/ 2250]\n",
      "loss: 0.066642  [24000/ 2250]\n",
      "loss: 0.068575  [25600/ 2250]\n",
      "loss: 0.076574  [27200/ 2250]\n",
      "loss: 0.078466  [28800/ 2250]\n",
      "loss: 0.063440  [30400/ 2250]\n",
      "loss: 0.077866  [32000/ 2250]\n",
      "loss: 0.066815  [33600/ 2250]\n",
      "loss: 0.075851  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.058035  [    0/ 2250]\n",
      "loss: 0.067156  [ 1600/ 2250]\n",
      "loss: 0.066489  [ 3200/ 2250]\n",
      "loss: 0.076353  [ 4800/ 2250]\n",
      "loss: 0.080750  [ 6400/ 2250]\n",
      "loss: 0.073602  [ 8000/ 2250]\n",
      "loss: 0.066306  [ 9600/ 2250]\n",
      "loss: 0.068783  [11200/ 2250]\n",
      "loss: 0.059901  [12800/ 2250]\n",
      "loss: 0.069457  [14400/ 2250]\n",
      "loss: 0.076641  [16000/ 2250]\n",
      "loss: 0.068337  [17600/ 2250]\n",
      "loss: 0.078666  [19200/ 2250]\n",
      "loss: 0.070959  [20800/ 2250]\n",
      "loss: 0.069327  [22400/ 2250]\n",
      "loss: 0.073401  [24000/ 2250]\n",
      "loss: 0.066553  [25600/ 2250]\n",
      "loss: 0.077428  [27200/ 2250]\n",
      "loss: 0.074770  [28800/ 2250]\n",
      "loss: 0.066815  [30400/ 2250]\n",
      "loss: 0.068840  [32000/ 2250]\n",
      "loss: 0.075942  [33600/ 2250]\n",
      "loss: 0.070988  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.073629  [    0/ 2250]\n",
      "loss: 0.074512  [ 1600/ 2250]\n",
      "loss: 0.066172  [ 3200/ 2250]\n",
      "loss: 0.064256  [ 4800/ 2250]\n",
      "loss: 0.071445  [ 6400/ 2250]\n",
      "loss: 0.067443  [ 8000/ 2250]\n",
      "loss: 0.071138  [ 9600/ 2250]\n",
      "loss: 0.076077  [11200/ 2250]\n",
      "loss: 0.075872  [12800/ 2250]\n",
      "loss: 0.069711  [14400/ 2250]\n",
      "loss: 0.067636  [16000/ 2250]\n",
      "loss: 0.073967  [17600/ 2250]\n",
      "loss: 0.067071  [19200/ 2250]\n",
      "loss: 0.065613  [20800/ 2250]\n",
      "loss: 0.069993  [22400/ 2250]\n",
      "loss: 0.064968  [24000/ 2250]\n",
      "loss: 0.074135  [25600/ 2250]\n",
      "loss: 0.071546  [27200/ 2250]\n",
      "loss: 0.074222  [28800/ 2250]\n",
      "loss: 0.065797  [30400/ 2250]\n",
      "loss: 0.070990  [32000/ 2250]\n",
      "loss: 0.076772  [33600/ 2250]\n",
      "loss: 0.075853  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.065467  [    0/ 2250]\n",
      "loss: 0.065882  [ 1600/ 2250]\n",
      "loss: 0.074639  [ 3200/ 2250]\n",
      "loss: 0.073728  [ 4800/ 2250]\n",
      "loss: 0.078112  [ 6400/ 2250]\n",
      "loss: 0.073465  [ 8000/ 2250]\n",
      "loss: 0.071841  [ 9600/ 2250]\n",
      "loss: 0.066943  [11200/ 2250]\n",
      "loss: 0.069482  [12800/ 2250]\n",
      "loss: 0.071418  [14400/ 2250]\n",
      "loss: 0.075478  [16000/ 2250]\n",
      "loss: 0.073481  [17600/ 2250]\n",
      "loss: 0.078459  [19200/ 2250]\n",
      "loss: 0.072546  [20800/ 2250]\n",
      "loss: 0.071614  [22400/ 2250]\n",
      "loss: 0.070924  [24000/ 2250]\n",
      "loss: 0.075729  [25600/ 2250]\n",
      "loss: 0.073272  [27200/ 2250]\n",
      "loss: 0.069481  [28800/ 2250]\n",
      "loss: 0.074284  [30400/ 2250]\n",
      "loss: 0.070896  [32000/ 2250]\n",
      "loss: 0.077419  [33600/ 2250]\n",
      "loss: 0.062964  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.078330  [    0/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.077782  [ 1600/ 2250]\n",
      "loss: 0.075349  [ 3200/ 2250]\n",
      "loss: 0.080528  [ 4800/ 2250]\n",
      "loss: 0.065525  [ 6400/ 2250]\n",
      "loss: 0.065608  [ 8000/ 2250]\n",
      "loss: 0.074004  [ 9600/ 2250]\n",
      "loss: 0.074714  [11200/ 2250]\n",
      "loss: 0.070245  [12800/ 2250]\n",
      "loss: 0.070631  [14400/ 2250]\n",
      "loss: 0.071445  [16000/ 2250]\n",
      "loss: 0.069435  [17600/ 2250]\n",
      "loss: 0.070617  [19200/ 2250]\n",
      "loss: 0.063663  [20800/ 2250]\n",
      "loss: 0.071228  [22400/ 2250]\n",
      "loss: 0.077875  [24000/ 2250]\n",
      "loss: 0.078397  [25600/ 2250]\n",
      "loss: 0.075496  [27200/ 2250]\n",
      "loss: 0.077710  [28800/ 2250]\n",
      "loss: 0.069177  [30400/ 2250]\n",
      "loss: 0.067714  [32000/ 2250]\n",
      "loss: 0.078463  [33600/ 2250]\n",
      "loss: 0.083086  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.068458  [    0/ 2250]\n",
      "loss: 0.072175  [ 1600/ 2250]\n",
      "loss: 0.065857  [ 3200/ 2250]\n",
      "loss: 0.069572  [ 4800/ 2250]\n",
      "loss: 0.082774  [ 6400/ 2250]\n",
      "loss: 0.075764  [ 8000/ 2250]\n",
      "loss: 0.073606  [ 9600/ 2250]\n",
      "loss: 0.081761  [11200/ 2250]\n",
      "loss: 0.072605  [12800/ 2250]\n",
      "loss: 0.078126  [14400/ 2250]\n",
      "loss: 0.072456  [16000/ 2250]\n",
      "loss: 0.072747  [17600/ 2250]\n",
      "loss: 0.065372  [19200/ 2250]\n",
      "loss: 0.074001  [20800/ 2250]\n",
      "loss: 0.075398  [22400/ 2250]\n",
      "loss: 0.074823  [24000/ 2250]\n",
      "loss: 0.071107  [25600/ 2250]\n",
      "loss: 0.068125  [27200/ 2250]\n",
      "loss: 0.076671  [28800/ 2250]\n",
      "loss: 0.072512  [30400/ 2250]\n",
      "loss: 0.080548  [32000/ 2250]\n",
      "loss: 0.071855  [33600/ 2250]\n",
      "loss: 0.073026  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.080076  [    0/ 2250]\n",
      "loss: 0.073717  [ 1600/ 2250]\n",
      "loss: 0.074382  [ 3200/ 2250]\n",
      "loss: 0.081684  [ 4800/ 2250]\n",
      "loss: 0.064507  [ 6400/ 2250]\n",
      "loss: 0.072206  [ 8000/ 2250]\n",
      "loss: 0.077143  [ 9600/ 2250]\n",
      "loss: 0.071728  [11200/ 2250]\n",
      "loss: 0.073807  [12800/ 2250]\n",
      "loss: 0.071030  [14400/ 2250]\n",
      "loss: 0.063632  [16000/ 2250]\n",
      "loss: 0.071293  [17600/ 2250]\n",
      "loss: 0.068990  [19200/ 2250]\n",
      "loss: 0.065609  [20800/ 2250]\n",
      "loss: 0.067895  [22400/ 2250]\n",
      "loss: 0.072428  [24000/ 2250]\n",
      "loss: 0.068392  [25600/ 2250]\n",
      "loss: 0.072209  [27200/ 2250]\n",
      "loss: 0.079434  [28800/ 2250]\n",
      "loss: 0.066324  [30400/ 2250]\n",
      "loss: 0.071100  [32000/ 2250]\n",
      "loss: 0.058462  [33600/ 2250]\n",
      "loss: 0.065857  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.068972  [    0/ 2250]\n",
      "loss: 0.073299  [ 1600/ 2250]\n",
      "loss: 0.070497  [ 3200/ 2250]\n",
      "loss: 0.077851  [ 4800/ 2250]\n",
      "loss: 0.073499  [ 6400/ 2250]\n",
      "loss: 0.071733  [ 8000/ 2250]\n",
      "loss: 0.075203  [ 9600/ 2250]\n",
      "loss: 0.070824  [11200/ 2250]\n",
      "loss: 0.076913  [12800/ 2250]\n",
      "loss: 0.074412  [14400/ 2250]\n",
      "loss: 0.068167  [16000/ 2250]\n",
      "loss: 0.065639  [17600/ 2250]\n",
      "loss: 0.069857  [19200/ 2250]\n",
      "loss: 0.073415  [20800/ 2250]\n",
      "loss: 0.069064  [22400/ 2250]\n",
      "loss: 0.059543  [24000/ 2250]\n",
      "loss: 0.070632  [25600/ 2250]\n",
      "loss: 0.074017  [27200/ 2250]\n",
      "loss: 0.070975  [28800/ 2250]\n",
      "loss: 0.069502  [30400/ 2250]\n",
      "loss: 0.069600  [32000/ 2250]\n",
      "loss: 0.081914  [33600/ 2250]\n",
      "loss: 0.076093  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.077596  [    0/ 2250]\n",
      "loss: 0.071220  [ 1600/ 2250]\n",
      "loss: 0.074812  [ 3200/ 2250]\n",
      "loss: 0.081859  [ 4800/ 2250]\n",
      "loss: 0.081878  [ 6400/ 2250]\n",
      "loss: 0.072363  [ 8000/ 2250]\n",
      "loss: 0.066995  [ 9600/ 2250]\n",
      "loss: 0.067056  [11200/ 2250]\n",
      "loss: 0.070554  [12800/ 2250]\n",
      "loss: 0.076453  [14400/ 2250]\n",
      "loss: 0.078172  [16000/ 2250]\n",
      "loss: 0.074091  [17600/ 2250]\n",
      "loss: 0.067594  [19200/ 2250]\n",
      "loss: 0.069735  [20800/ 2250]\n",
      "loss: 0.078566  [22400/ 2250]\n",
      "loss: 0.070696  [24000/ 2250]\n",
      "loss: 0.072933  [25600/ 2250]\n",
      "loss: 0.074804  [27200/ 2250]\n",
      "loss: 0.073260  [28800/ 2250]\n",
      "loss: 0.075785  [30400/ 2250]\n",
      "loss: 0.072940  [32000/ 2250]\n",
      "loss: 0.083597  [33600/ 2250]\n",
      "loss: 0.071265  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.071190  [    0/ 2250]\n",
      "loss: 0.072511  [ 1600/ 2250]\n",
      "loss: 0.073848  [ 3200/ 2250]\n",
      "loss: 0.077317  [ 4800/ 2250]\n",
      "loss: 0.076520  [ 6400/ 2250]\n",
      "loss: 0.068870  [ 8000/ 2250]\n",
      "loss: 0.071773  [ 9600/ 2250]\n",
      "loss: 0.072415  [11200/ 2250]\n",
      "loss: 0.068783  [12800/ 2250]\n",
      "loss: 0.079111  [14400/ 2250]\n",
      "loss: 0.066773  [16000/ 2250]\n",
      "loss: 0.077087  [17600/ 2250]\n",
      "loss: 0.063595  [19200/ 2250]\n",
      "loss: 0.069884  [20800/ 2250]\n",
      "loss: 0.073935  [22400/ 2250]\n",
      "loss: 0.068874  [24000/ 2250]\n",
      "loss: 0.076319  [25600/ 2250]\n",
      "loss: 0.071449  [27200/ 2250]\n",
      "loss: 0.076326  [28800/ 2250]\n",
      "loss: 0.069619  [30400/ 2250]\n",
      "loss: 0.069797  [32000/ 2250]\n",
      "loss: 0.073319  [33600/ 2250]\n",
      "loss: 0.069264  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.0%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.079596  [    0/ 2250]\n",
      "loss: 0.077241  [ 1600/ 2250]\n",
      "loss: 0.067896  [ 3200/ 2250]\n",
      "loss: 0.075554  [ 4800/ 2250]\n",
      "loss: 0.069597  [ 6400/ 2250]\n",
      "loss: 0.079852  [ 8000/ 2250]\n",
      "loss: 0.073971  [ 9600/ 2250]\n",
      "loss: 0.077999  [11200/ 2250]\n",
      "loss: 0.076487  [12800/ 2250]\n",
      "loss: 0.068809  [14400/ 2250]\n",
      "loss: 0.062836  [16000/ 2250]\n",
      "loss: 0.080486  [17600/ 2250]\n",
      "loss: 0.074037  [19200/ 2250]\n",
      "loss: 0.070971  [20800/ 2250]\n",
      "loss: 0.070514  [22400/ 2250]\n",
      "loss: 0.071081  [24000/ 2250]\n",
      "loss: 0.072259  [25600/ 2250]\n",
      "loss: 0.077426  [27200/ 2250]\n",
      "loss: 0.074055  [28800/ 2250]\n",
      "loss: 0.074224  [30400/ 2250]\n",
      "loss: 0.074261  [32000/ 2250]\n",
      "loss: 0.060570  [33600/ 2250]\n",
      "loss: 0.069166  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.074187  [    0/ 2250]\n",
      "loss: 0.071317  [ 1600/ 2250]\n",
      "loss: 0.074853  [ 3200/ 2250]\n",
      "loss: 0.075367  [ 4800/ 2250]\n",
      "loss: 0.067148  [ 6400/ 2250]\n",
      "loss: 0.067435  [ 8000/ 2250]\n",
      "loss: 0.074163  [ 9600/ 2250]\n",
      "loss: 0.067552  [11200/ 2250]\n",
      "loss: 0.064626  [12800/ 2250]\n",
      "loss: 0.076859  [14400/ 2250]\n",
      "loss: 0.075232  [16000/ 2250]\n",
      "loss: 0.077266  [17600/ 2250]\n",
      "loss: 0.070067  [19200/ 2250]\n",
      "loss: 0.070622  [20800/ 2250]\n",
      "loss: 0.078852  [22400/ 2250]\n",
      "loss: 0.072591  [24000/ 2250]\n",
      "loss: 0.070652  [25600/ 2250]\n",
      "loss: 0.075916  [27200/ 2250]\n",
      "loss: 0.074033  [28800/ 2250]\n",
      "loss: 0.079024  [30400/ 2250]\n",
      "loss: 0.080728  [32000/ 2250]\n",
      "loss: 0.078581  [33600/ 2250]\n",
      "loss: 0.076374  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.1%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.070325  [    0/ 2250]\n",
      "loss: 0.073382  [ 1600/ 2250]\n",
      "loss: 0.076515  [ 3200/ 2250]\n",
      "loss: 0.077327  [ 4800/ 2250]\n",
      "loss: 0.071378  [ 6400/ 2250]\n",
      "loss: 0.076341  [ 8000/ 2250]\n",
      "loss: 0.070034  [ 9600/ 2250]\n",
      "loss: 0.071829  [11200/ 2250]\n",
      "loss: 0.071765  [12800/ 2250]\n",
      "loss: 0.079719  [14400/ 2250]\n",
      "loss: 0.072716  [16000/ 2250]\n",
      "loss: 0.077069  [17600/ 2250]\n",
      "loss: 0.075139  [19200/ 2250]\n",
      "loss: 0.064718  [20800/ 2250]\n",
      "loss: 0.066595  [22400/ 2250]\n",
      "loss: 0.066254  [24000/ 2250]\n",
      "loss: 0.071723  [25600/ 2250]\n",
      "loss: 0.069025  [27200/ 2250]\n",
      "loss: 0.076175  [28800/ 2250]\n",
      "loss: 0.075788  [30400/ 2250]\n",
      "loss: 0.070298  [32000/ 2250]\n",
      "loss: 0.081607  [33600/ 2250]\n",
      "loss: 0.068174  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.066874  [    0/ 2250]\n",
      "loss: 0.070823  [ 1600/ 2250]\n",
      "loss: 0.079542  [ 3200/ 2250]\n",
      "loss: 0.069337  [ 4800/ 2250]\n",
      "loss: 0.069431  [ 6400/ 2250]\n",
      "loss: 0.073562  [ 8000/ 2250]\n",
      "loss: 0.066585  [ 9600/ 2250]\n",
      "loss: 0.072206  [11200/ 2250]\n",
      "loss: 0.071770  [12800/ 2250]\n",
      "loss: 0.081077  [14400/ 2250]\n",
      "loss: 0.064337  [16000/ 2250]\n",
      "loss: 0.076597  [17600/ 2250]\n",
      "loss: 0.078377  [19200/ 2250]\n",
      "loss: 0.074323  [20800/ 2250]\n",
      "loss: 0.074870  [22400/ 2250]\n",
      "loss: 0.069100  [24000/ 2250]\n",
      "loss: 0.071170  [25600/ 2250]\n",
      "loss: 0.079307  [27200/ 2250]\n",
      "loss: 0.076232  [28800/ 2250]\n",
      "loss: 0.074486  [30400/ 2250]\n",
      "loss: 0.067689  [32000/ 2250]\n",
      "loss: 0.076506  [33600/ 2250]\n",
      "loss: 0.063904  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 18.9%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.071093  [    0/ 2250]\n",
      "loss: 0.080496  [ 1600/ 2250]\n",
      "loss: 0.071609  [ 3200/ 2250]\n",
      "loss: 0.066208  [ 4800/ 2250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.074397  [ 6400/ 2250]\n",
      "loss: 0.068781  [ 8000/ 2250]\n",
      "loss: 0.079687  [ 9600/ 2250]\n",
      "loss: 0.075589  [11200/ 2250]\n",
      "loss: 0.063588  [12800/ 2250]\n",
      "loss: 0.065401  [14400/ 2250]\n",
      "loss: 0.076493  [16000/ 2250]\n",
      "loss: 0.070031  [17600/ 2250]\n",
      "loss: 0.070679  [19200/ 2250]\n",
      "loss: 0.075656  [20800/ 2250]\n",
      "loss: 0.067460  [22400/ 2250]\n",
      "loss: 0.078855  [24000/ 2250]\n",
      "loss: 0.072949  [25600/ 2250]\n",
      "loss: 0.071675  [27200/ 2250]\n",
      "loss: 0.065764  [28800/ 2250]\n",
      "loss: 0.061190  [30400/ 2250]\n",
      "loss: 0.080365  [32000/ 2250]\n",
      "loss: 0.073705  [33600/ 2250]\n",
      "loss: 0.067835  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.1%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.074738  [    0/ 2250]\n",
      "loss: 0.081127  [ 1600/ 2250]\n",
      "loss: 0.069955  [ 3200/ 2250]\n",
      "loss: 0.067837  [ 4800/ 2250]\n",
      "loss: 0.075640  [ 6400/ 2250]\n",
      "loss: 0.071510  [ 8000/ 2250]\n",
      "loss: 0.081251  [ 9600/ 2250]\n",
      "loss: 0.069640  [11200/ 2250]\n",
      "loss: 0.064356  [12800/ 2250]\n",
      "loss: 0.068070  [14400/ 2250]\n",
      "loss: 0.069986  [16000/ 2250]\n",
      "loss: 0.068546  [17600/ 2250]\n",
      "loss: 0.076252  [19200/ 2250]\n",
      "loss: 0.072485  [20800/ 2250]\n",
      "loss: 0.064474  [22400/ 2250]\n",
      "loss: 0.079011  [24000/ 2250]\n",
      "loss: 0.069410  [25600/ 2250]\n",
      "loss: 0.074619  [27200/ 2250]\n",
      "loss: 0.061756  [28800/ 2250]\n",
      "loss: 0.074396  [30400/ 2250]\n",
      "loss: 0.085910  [32000/ 2250]\n",
      "loss: 0.064710  [33600/ 2250]\n",
      "loss: 0.074219  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.068846  [    0/ 2250]\n",
      "loss: 0.068588  [ 1600/ 2250]\n",
      "loss: 0.069071  [ 3200/ 2250]\n",
      "loss: 0.080007  [ 4800/ 2250]\n",
      "loss: 0.068280  [ 6400/ 2250]\n",
      "loss: 0.081119  [ 8000/ 2250]\n",
      "loss: 0.066185  [ 9600/ 2250]\n",
      "loss: 0.075875  [11200/ 2250]\n",
      "loss: 0.070201  [12800/ 2250]\n",
      "loss: 0.070545  [14400/ 2250]\n",
      "loss: 0.072881  [16000/ 2250]\n",
      "loss: 0.070353  [17600/ 2250]\n",
      "loss: 0.075367  [19200/ 2250]\n",
      "loss: 0.071324  [20800/ 2250]\n",
      "loss: 0.069333  [22400/ 2250]\n",
      "loss: 0.077530  [24000/ 2250]\n",
      "loss: 0.067820  [25600/ 2250]\n",
      "loss: 0.071170  [27200/ 2250]\n",
      "loss: 0.073221  [28800/ 2250]\n",
      "loss: 0.073508  [30400/ 2250]\n",
      "loss: 0.063160  [32000/ 2250]\n",
      "loss: 0.062032  [33600/ 2250]\n",
      "loss: 0.079056  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.3%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0\n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.077975  [    0/ 2250]\n",
      "loss: 0.073082  [ 1600/ 2250]\n",
      "loss: 0.068836  [ 3200/ 2250]\n",
      "loss: 0.072760  [ 4800/ 2250]\n",
      "loss: 0.069763  [ 6400/ 2250]\n",
      "loss: 0.073553  [ 8000/ 2250]\n",
      "loss: 0.073548  [ 9600/ 2250]\n",
      "loss: 0.070812  [11200/ 2250]\n",
      "loss: 0.072412  [12800/ 2250]\n",
      "loss: 0.067920  [14400/ 2250]\n",
      "loss: 0.072347  [16000/ 2250]\n",
      "loss: 0.071494  [17600/ 2250]\n",
      "loss: 0.074775  [19200/ 2250]\n",
      "loss: 0.079793  [20800/ 2250]\n",
      "loss: 0.073133  [22400/ 2250]\n",
      "loss: 0.078737  [24000/ 2250]\n",
      "loss: 0.071467  [25600/ 2250]\n",
      "loss: 0.058090  [27200/ 2250]\n",
      "loss: 0.067163  [28800/ 2250]\n",
      "loss: 0.070979  [30400/ 2250]\n",
      "loss: 0.064945  [32000/ 2250]\n",
      "loss: 0.072215  [33600/ 2250]\n",
      "loss: 0.078231  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.070624  [    0/ 2250]\n",
      "loss: 0.073546  [ 1600/ 2250]\n",
      "loss: 0.074940  [ 3200/ 2250]\n",
      "loss: 0.071959  [ 4800/ 2250]\n",
      "loss: 0.081009  [ 6400/ 2250]\n",
      "loss: 0.081012  [ 8000/ 2250]\n",
      "loss: 0.077611  [ 9600/ 2250]\n",
      "loss: 0.076184  [11200/ 2250]\n",
      "loss: 0.072494  [12800/ 2250]\n",
      "loss: 0.075836  [14400/ 2250]\n",
      "loss: 0.075865  [16000/ 2250]\n",
      "loss: 0.069964  [17600/ 2250]\n",
      "loss: 0.078424  [19200/ 2250]\n",
      "loss: 0.072738  [20800/ 2250]\n",
      "loss: 0.073003  [22400/ 2250]\n",
      "loss: 0.072052  [24000/ 2250]\n",
      "loss: 0.067209  [25600/ 2250]\n",
      "loss: 0.074614  [27200/ 2250]\n",
      "loss: 0.075126  [28800/ 2250]\n",
      "loss: 0.072461  [30400/ 2250]\n",
      "loss: 0.076130  [32000/ 2250]\n",
      "loss: 0.066558  [33600/ 2250]\n",
      "loss: 0.078135  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.073865  [    0/ 2250]\n",
      "loss: 0.068853  [ 1600/ 2250]\n",
      "loss: 0.067062  [ 3200/ 2250]\n",
      "loss: 0.078379  [ 4800/ 2250]\n",
      "loss: 0.068514  [ 6400/ 2250]\n",
      "loss: 0.075151  [ 8000/ 2250]\n",
      "loss: 0.074689  [ 9600/ 2250]\n",
      "loss: 0.070872  [11200/ 2250]\n",
      "loss: 0.066804  [12800/ 2250]\n",
      "loss: 0.073526  [14400/ 2250]\n",
      "loss: 0.070817  [16000/ 2250]\n",
      "loss: 0.065753  [17600/ 2250]\n",
      "loss: 0.070825  [19200/ 2250]\n",
      "loss: 0.060663  [20800/ 2250]\n",
      "loss: 0.073663  [22400/ 2250]\n",
      "loss: 0.077389  [24000/ 2250]\n",
      "loss: 0.067994  [25600/ 2250]\n",
      "loss: 0.061929  [27200/ 2250]\n",
      "loss: 0.066934  [28800/ 2250]\n",
      "loss: 0.080160  [30400/ 2250]\n",
      "loss: 0.080763  [32000/ 2250]\n",
      "loss: 0.070477  [33600/ 2250]\n",
      "loss: 0.075900  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.067265  [    0/ 2250]\n",
      "loss: 0.077466  [ 1600/ 2250]\n",
      "loss: 0.066001  [ 3200/ 2250]\n",
      "loss: 0.069927  [ 4800/ 2250]\n",
      "loss: 0.077623  [ 6400/ 2250]\n",
      "loss: 0.075403  [ 8000/ 2250]\n",
      "loss: 0.071729  [ 9600/ 2250]\n",
      "loss: 0.069183  [11200/ 2250]\n",
      "loss: 0.073403  [12800/ 2250]\n",
      "loss: 0.075713  [14400/ 2250]\n",
      "loss: 0.075615  [16000/ 2250]\n",
      "loss: 0.065664  [17600/ 2250]\n",
      "loss: 0.076804  [19200/ 2250]\n",
      "loss: 0.071022  [20800/ 2250]\n",
      "loss: 0.073612  [22400/ 2250]\n",
      "loss: 0.078989  [24000/ 2250]\n",
      "loss: 0.071858  [25600/ 2250]\n",
      "loss: 0.062599  [27200/ 2250]\n",
      "loss: 0.068567  [28800/ 2250]\n",
      "loss: 0.077053  [30400/ 2250]\n",
      "loss: 0.075499  [32000/ 2250]\n",
      "loss: 0.067739  [33600/ 2250]\n",
      "loss: 0.076416  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.072974  [    0/ 2250]\n",
      "loss: 0.075817  [ 1600/ 2250]\n",
      "loss: 0.062791  [ 3200/ 2250]\n",
      "loss: 0.071856  [ 4800/ 2250]\n",
      "loss: 0.070673  [ 6400/ 2250]\n",
      "loss: 0.069069  [ 8000/ 2250]\n",
      "loss: 0.076878  [ 9600/ 2250]\n",
      "loss: 0.071520  [11200/ 2250]\n",
      "loss: 0.065531  [12800/ 2250]\n",
      "loss: 0.063819  [14400/ 2250]\n",
      "loss: 0.073248  [16000/ 2250]\n",
      "loss: 0.070528  [17600/ 2250]\n",
      "loss: 0.071168  [19200/ 2250]\n",
      "loss: 0.070281  [20800/ 2250]\n",
      "loss: 0.078891  [22400/ 2250]\n",
      "loss: 0.068287  [24000/ 2250]\n",
      "loss: 0.074723  [25600/ 2250]\n",
      "loss: 0.073894  [27200/ 2250]\n",
      "loss: 0.063433  [28800/ 2250]\n",
      "loss: 0.080179  [30400/ 2250]\n",
      "loss: 0.078243  [32000/ 2250]\n",
      "loss: 0.075136  [33600/ 2250]\n",
      "loss: 0.077370  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.069572  [    0/ 2250]\n",
      "loss: 0.062316  [ 1600/ 2250]\n",
      "loss: 0.074971  [ 3200/ 2250]\n",
      "loss: 0.071027  [ 4800/ 2250]\n",
      "loss: 0.076710  [ 6400/ 2250]\n",
      "loss: 0.076071  [ 8000/ 2250]\n",
      "loss: 0.075814  [ 9600/ 2250]\n",
      "loss: 0.075753  [11200/ 2250]\n",
      "loss: 0.071159  [12800/ 2250]\n",
      "loss: 0.073631  [14400/ 2250]\n",
      "loss: 0.066576  [16000/ 2250]\n",
      "loss: 0.067932  [17600/ 2250]\n",
      "loss: 0.072890  [19200/ 2250]\n",
      "loss: 0.068349  [20800/ 2250]\n",
      "loss: 0.081051  [22400/ 2250]\n",
      "loss: 0.079358  [24000/ 2250]\n",
      "loss: 0.071424  [25600/ 2250]\n",
      "loss: 0.069040  [27200/ 2250]\n",
      "loss: 0.067267  [28800/ 2250]\n",
      "loss: 0.073099  [30400/ 2250]\n",
      "loss: 0.069233  [32000/ 2250]\n",
      "loss: 0.068803  [33600/ 2250]\n",
      "loss: 0.073255  [35200/ 2250]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 19.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)\n",
    "    test(test_loader, model, criterion)\n",
    "    \n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87c90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713b6c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f409f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2b815c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

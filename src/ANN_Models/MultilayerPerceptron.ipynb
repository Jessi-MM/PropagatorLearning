{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "569a21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "#-----\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#%matplotlib notebook\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c4187",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8d41296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propagator_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data, targets, total_data = 198000, transform=True):\n",
    "        \n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "        self.total_data = total_data\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        total_data = self.total_data  # 198 data by file, 1000 files(from 0 to 999), total data: 198*100 = 19800\n",
    "        \n",
    "        if index > total_data:\n",
    "            print(\"Error, this data does not exist\")\n",
    "        else:\n",
    "            index_data = (index//199)%199  # because there 198 data per file\n",
    "            index_t = (index-199)%199\n",
    "            \n",
    "            # Input data: Wavepacket real and imaginary part + Potential at time t\n",
    "            x_r = (np.load(self.data+str(index_data)+'/Wavepacket/'+str(index_t)+'-wave.npy')).real\n",
    "            x_i = (np.load(self.data+str(index_data)+'/Wavepacket/'+str(index_t)+'-wave.npy')).imag\n",
    "            x_p = np.load(self.data+str(index_data)+'/Potential/'+str(index_t)+'-potential.npy')\n",
    "            # Output data: Wavepacket real and imaginary part at time t+1*step\n",
    "            y_r = (np.load(self.targets+str(index_data)+'/Wavepacket/'+str(index_t+1)+'-wave.npy')).real\n",
    "            y_i = (np.load(self.targets+str(index_data)+'/Wavepacket/'+str(index_t+1)+'-wave.npy')).imag\n",
    "        \n",
    "            x = np.concatenate((x_r, x_i, x_p))  # flat array form\n",
    "\n",
    "            y = np.concatenate((y_r, y_i))  # flat array form\n",
    "        \n",
    "            if self.transform:\n",
    "                x = torch.from_numpy(x)\n",
    "                y = torch.from_numpy(y)\n",
    "        \n",
    "            return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        return self.total_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "18d226be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../Data_Gaussian/data'  # Directory where are saving our data\n",
    "\n",
    "dataset = Propagator_Dataset(data=path, targets=path, transform=True)\n",
    "batch_size = 36\n",
    "validation_split = .1  #9:1 ratio\n",
    "shuffle_dataset = True\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0f1b3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of data  198000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print('Total of data ', dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dce492a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "test_sampler = SubsetRandomSampler(val_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cebe61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of train samples: 178200\n",
      "Total of test samples: 19800\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of train samples: {len(train_sampler)}\")\n",
    "print(f\"Total of test samples: {len(test_sampler)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "68f0b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0359fe61",
   "metadata": {},
   "source": [
    "## Visualization of data and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0f0f337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Shape of X in train loader: torch.Size([36, 96])\n",
      "Shape of y in train loader: torch.Size([36, 64]) torch.float64\n",
      "\n",
      "Test data:\n",
      "Shape of X in test loader: torch.Size([36, 96])\n",
      "Shape of y in test loader: torch.Size([36, 64]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(\"Train data:\")\n",
    "    print(f\"Shape of X in train loader: {X.shape}\")\n",
    "    print(f\"Shape of y in train loader: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "for X, y in test_loader:\n",
    "    print(\"\\nTest data:\")\n",
    "    print(f\"Shape of X in test loader: {X.shape}\")\n",
    "    print(f\"Shape of y in test loader: {y.shape} {y.dtype}\")\n",
    "    break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3984ec0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 parte real\n",
      " tensor([ 4.9862e-07,  9.6355e-04, -2.1288e-03,  3.6774e-03, -5.6735e-03,\n",
      "         5.8585e-03, -1.2732e-02,  2.0504e-02, -1.6905e-02, -2.5976e-02,\n",
      "        -1.4181e-01, -9.7909e-02, -8.8491e-02, -3.6956e-02, -4.4121e-01,\n",
      "        -4.9339e-01, -4.4605e-01,  1.2909e-01,  2.8696e-01, -7.9046e-02,\n",
      "        -4.3403e-01,  2.2145e-01,  5.1366e-02,  6.1022e-02, -1.1390e-01,\n",
      "         2.0527e-02,  3.4772e-03,  5.5859e-03, -9.2664e-03,  3.9572e-03,\n",
      "        -2.7651e-03, -7.8627e-09], dtype=torch.float64)\n",
      "batch: 0pparte imag\n",
      " tensor([-9.9427e-07,  4.3913e-04, -9.3889e-04,  1.8056e-03, -2.0030e-03,\n",
      "         3.5126e-03, -9.3135e-03, -2.1547e-03, -1.0905e-02, -4.4517e-03,\n",
      "         3.2930e-02,  1.9467e-01,  1.4616e-01,  8.0763e-01,  1.0664e+00,\n",
      "         9.7215e-01,  7.9962e-01,  5.9020e-01,  5.3786e-01,  4.8828e-01,\n",
      "        -3.5162e-02, -2.5791e-01, -2.6977e-02,  2.1705e-01,  1.1654e-02,\n",
      "        -2.4017e-02, -3.3147e-02, -4.3031e-03, -4.0663e-03,  1.9456e-03,\n",
      "        -1.4118e-03,  1.0720e-08], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 1 parte real\n",
      " tensor([ 2.2583e-18, -1.1568e-06,  2.6862e-06, -7.7683e-06,  1.1555e-05,\n",
      "        -1.6462e-05,  3.4523e-05, -2.9933e-05,  7.6274e-04, -8.7342e-03,\n",
      "        -8.6854e-02, -2.7054e-02,  7.4167e-01,  1.4845e+00,  1.1840e+00,\n",
      "         4.9360e-01,  1.1542e-01,  7.7234e-03, -4.5140e-04, -3.5106e-04,\n",
      "         3.5697e-04, -3.4320e-04,  2.0592e-04, -1.0326e-04,  7.4933e-05,\n",
      "        -3.8967e-05,  2.4118e-05, -1.8064e-05,  1.1190e-05, -6.2554e-06,\n",
      "         3.3819e-06, -2.9717e-35], dtype=torch.float64)\n",
      "batch: 1pparte imag\n",
      " tensor([-7.7493e-19,  7.2687e-06, -1.5549e-05,  2.6701e-05, -4.6311e-05,\n",
      "         6.1512e-05, -1.0163e-04,  9.5451e-05,  4.6625e-04,  9.6352e-03,\n",
      "        -4.1885e-02, -4.2146e-01, -7.4920e-01, -2.3945e-01,  3.3869e-01,\n",
      "         3.3145e-01,  1.5126e-01,  3.8017e-02,  3.7682e-03,  2.0904e-04,\n",
      "        -2.7473e-05,  1.3797e-04, -2.0826e-04,  1.4711e-04, -1.2331e-04,\n",
      "         8.3241e-05, -6.6487e-05,  4.6176e-05, -3.0316e-05,  1.9434e-05,\n",
      "        -1.1319e-05,  8.1959e-35], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 2 parte real\n",
      " tensor([-8.6355e-12, -1.7391e-04,  7.8376e-04, -9.2384e-04,  2.9106e-03,\n",
      "        -8.3567e-03,  1.8166e-02,  7.0072e-02, -7.0458e-01, -1.4739e-01,\n",
      "         6.9570e-01,  8.9968e-02, -3.3990e-01,  3.4937e-01,  1.6217e-01,\n",
      "        -2.1489e-01, -5.9050e-01, -3.8065e-01,  1.1580e-01, -5.9778e-02,\n",
      "         3.4008e-02, -9.2363e-02,  2.4486e-01, -1.2925e-01,  3.8006e-01,\n",
      "         6.6334e-01,  1.5710e-01, -4.5131e-01, -4.0049e-01, -6.5876e-02,\n",
      "         2.1258e-03,  1.4260e-11], dtype=torch.float64)\n",
      "batch: 2pparte imag\n",
      " tensor([-3.0678e-12,  2.9285e-04, -7.8004e-04,  1.4450e-03, -2.3611e-03,\n",
      "        -2.8432e-03, -8.7018e-02, -1.9168e-03,  4.3821e-01, -2.2707e-01,\n",
      "         1.7616e-01,  2.3091e-01,  1.1286e-01,  1.3330e-01,  8.1046e-02,\n",
      "         3.0703e-01,  6.6166e-01,  3.0132e-01, -6.0932e-01,  2.0426e-01,\n",
      "        -4.5114e-01, -2.7164e-01,  7.1018e-01, -1.9591e-01, -1.7218e-01,\n",
      "         4.7480e-01, -6.9314e-02,  1.5983e-01,  2.2793e-01,  4.6588e-02,\n",
      "        -9.1980e-04, -4.0954e-13], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 3 parte real\n",
      " tensor([-6.1664e-09,  1.2849e-03,  2.0045e-02,  3.2600e-02,  3.4464e-02,\n",
      "         4.7518e-02, -6.5267e-02,  2.7835e-02, -6.5388e-02, -9.6496e-02,\n",
      "        -1.4382e-01,  9.7519e-03,  3.6479e-01,  4.9103e-01, -2.3257e-01,\n",
      "        -1.1730e-01, -1.4143e-01,  2.8489e-01,  5.1526e-01,  1.2477e+00,\n",
      "         6.6095e-01,  2.0989e-01,  7.4428e-02,  4.1125e-02,  1.5342e-02,\n",
      "         5.4204e-02, -1.7792e-02,  4.7551e-03, -4.4105e-03,  2.2966e-03,\n",
      "        -1.4899e-03,  7.3339e-06], dtype=torch.float64)\n",
      "batch: 3pparte imag\n",
      " tensor([ 3.3063e-08, -7.1417e-03, -2.7547e-03,  6.3168e-03,  2.7294e-02,\n",
      "         6.1462e-02, -3.1857e-02,  3.0459e-02,  1.0318e-01,  3.3893e-01,\n",
      "         1.7087e-01,  2.8233e-01, -2.6127e-01,  5.6887e-01,  7.3276e-01,\n",
      "         4.5615e-01, -1.2669e-01, -1.2582e-01,  3.7256e-01,  9.6167e-01,\n",
      "         2.1531e-01,  1.3855e-02, -2.1475e-01, -1.1784e-03, -1.0021e-02,\n",
      "        -1.3612e-02, -1.4943e-02,  3.6844e-03, -8.4604e-03,  2.3836e-03,\n",
      "        -2.5444e-03,  7.8880e-06], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 4 parte real\n",
      " tensor([-1.0207e-31, -3.3486e-05,  6.8072e-05, -1.0042e-04,  1.2678e-04,\n",
      "        -7.5938e-04, -9.6269e-04, -3.0721e-03,  3.5597e-03,  1.6420e-02,\n",
      "        -3.3056e-02, -1.6505e-01, -6.7487e-02,  3.2862e-01,  6.7963e-01,\n",
      "         8.8804e-01,  9.7150e-01,  5.9922e-01, -2.2674e-01, -5.7126e-01,\n",
      "        -1.5502e-01,  6.6469e-02,  1.0103e-02, -7.0226e-04,  1.6115e-03,\n",
      "        -3.3674e-03,  1.9896e-04,  5.6391e-04,  7.6913e-04,  7.6083e-05,\n",
      "         8.4177e-05, -4.8433e-30], dtype=torch.float64)\n",
      "batch: 4pparte imag\n",
      " tensor([-2.2260e-31, -4.5768e-06,  1.1917e-05, -2.0010e-05,  1.1066e-04,\n",
      "        -9.5734e-05, -3.6087e-04,  1.4755e-03,  6.1689e-03, -1.1475e-02,\n",
      "        -5.6030e-02,  4.6870e-02,  3.3568e-01,  4.3106e-01,  2.6017e-01,\n",
      "         1.7527e-01,  4.4864e-01,  9.3365e-01,  8.9952e-01,  1.6509e-01,\n",
      "        -2.2776e-01, -5.8194e-02,  1.4882e-02, -1.5382e-03,  3.2313e-03,\n",
      "        -5.0360e-05, -1.8856e-03, -7.6972e-04, -1.0665e-04, -1.3651e-04,\n",
      "        -2.9433e-05,  3.9563e-31], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 5 parte real\n",
      " tensor([ 9.0715e-05, -6.0147e-04,  3.6380e-04, -2.0447e-04, -3.5719e-03,\n",
      "        -2.5994e-02, -2.9035e-02,  8.0740e-02,  1.1277e-01, -2.2846e-01,\n",
      "        -2.5631e-01, -1.1262e-01,  6.0582e-02,  7.7188e-01,  1.4446e-01,\n",
      "        -7.2526e-01,  2.4599e-01,  2.0812e-01, -3.2552e-01, -1.8051e-01,\n",
      "        -2.9025e-01, -1.1944e-01,  1.6091e-01,  2.2513e-01,  3.9257e-01,\n",
      "         1.2009e-01, -5.7329e-02, -3.7153e-02, -4.3375e-03, -7.9405e-04,\n",
      "         3.7738e-04, -8.1938e-15], dtype=torch.float64)\n",
      "batch: 5pparte imag\n",
      " tensor([ 1.0054e-04,  3.1957e-04,  2.3828e-04,  7.2377e-06, -1.8193e-03,\n",
      "        -5.9082e-03, -7.2496e-02, -7.2783e-02, -4.5723e-03,  3.0573e-01,\n",
      "         4.0754e-01, -1.1751e-01, -3.6917e-01, -2.4504e-01, -6.2023e-02,\n",
      "         3.3212e-01, -6.1794e-01, -9.7458e-01,  2.3627e-02,  8.1970e-01,\n",
      "         8.1729e-01, -1.1414e-01, -5.0456e-01, -1.3360e-01,  1.3765e-01,\n",
      "         9.1375e-02, -1.5638e-02,  1.6903e-02,  1.3005e-03,  6.9923e-04,\n",
      "         3.5931e-04, -1.3180e-14], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 6 parte real\n",
      " tensor([ 2.1556e-15, -1.0699e-04,  2.5832e-04, -4.8266e-04,  6.1438e-04,\n",
      "        -1.0212e-03,  1.3563e-03, -3.7788e-03,  1.3309e-02,  3.4959e-02,\n",
      "         2.0873e-03,  1.1583e-01,  4.2023e-01,  8.2969e-01,  1.0046e+00,\n",
      "         4.2228e-01, -9.7911e-02, -6.0805e-01, -4.4220e-01,  4.2129e-02,\n",
      "         8.3012e-02, -7.6401e-03,  1.6987e-02,  2.2392e-03,  2.5476e-03,\n",
      "        -7.9879e-04,  8.2988e-04, -5.6463e-04,  3.7552e-04, -2.4289e-04,\n",
      "         1.4494e-04,  1.6118e-12], dtype=torch.float64)\n",
      "batch: 6pparte imag\n",
      " tensor([-2.4306e-15, -3.6992e-04,  8.3860e-04, -1.5259e-03,  2.2539e-03,\n",
      "        -3.4393e-03,  5.2357e-03, -5.9501e-03,  2.4343e-02,  8.7031e-03,\n",
      "         2.4947e-02, -5.6765e-02, -3.3335e-01, -9.1655e-01, -9.6768e-01,\n",
      "        -8.2565e-01, -3.2713e-01,  1.0209e-01,  2.1922e-01, -2.7399e-01,\n",
      "         9.9713e-04,  4.2917e-02,  2.3136e-02, -1.1715e-02,  4.5367e-03,\n",
      "        -3.7108e-03,  2.6531e-03, -1.8626e-03,  1.2745e-03, -8.1964e-04,\n",
      "         4.7213e-04,  2.4872e-11], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 7 parte real\n",
      " tensor([-2.4736e-07, -2.5771e-04, -4.2399e-03, -2.1774e-02,  9.6061e-03,\n",
      "        -5.1186e-02,  3.6988e-02,  1.4414e-02, -1.4330e-01, -2.9507e-02,\n",
      "        -7.3874e-01, -3.3995e-01,  2.2513e-01, -2.2995e-01, -5.9393e-02,\n",
      "        -2.9760e-01,  3.8185e-01,  4.0192e-01, -3.7441e-01, -1.6817e-01,\n",
      "         1.1708e-01, -6.4819e-01, -4.1604e-02,  2.4826e-01,  3.2353e-01,\n",
      "        -1.5407e-02,  2.8665e-02, -3.8769e-02, -1.3826e-01,  3.5566e-03,\n",
      "         1.8763e-02,  2.2691e-23], dtype=torch.float64)\n",
      "batch: 7pparte imag\n",
      " tensor([-8.7527e-08, -1.0045e-03,  5.5994e-03,  9.2304e-03,  5.2053e-02,\n",
      "         3.7299e-02,  6.2751e-02, -1.1543e-01,  2.0106e-01, -1.4020e-01,\n",
      "         1.5805e-01,  6.9881e-01, -3.5543e-01, -3.2343e-02,  1.0181e+00,\n",
      "         2.5681e-01,  2.5711e-01,  4.6525e-02,  2.9187e-01, -6.5981e-01,\n",
      "         6.0552e-01,  1.7602e-01, -3.2649e-01,  3.1768e-01,  5.3780e-01,\n",
      "         9.4419e-02,  4.0279e-01,  3.1825e-02,  5.1509e-02,  5.0333e-02,\n",
      "         1.7054e-03, -3.2419e-23], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 8 parte real\n",
      " tensor([ 9.6792e-09,  1.0233e-01,  3.1373e-01,  2.3273e-01,  1.7505e-01,\n",
      "         7.3840e-01,  3.0047e-01, -7.2000e-01, -1.3598e-01, -1.1696e-01,\n",
      "         6.3529e-02, -1.0556e-01,  2.1701e-01, -1.4391e-01, -3.0556e-01,\n",
      "         2.5449e-01, -2.8621e-01,  1.0096e-01,  1.5193e-01, -1.1653e-01,\n",
      "        -4.8350e-02,  2.1039e-01, -2.3249e-01,  6.3253e-02,  2.2134e-01,\n",
      "        -3.5983e-01, -7.8852e-03,  3.8865e-01, -1.1736e-01,  2.1420e-01,\n",
      "         8.7838e-01,  6.3167e-09], dtype=torch.float64)\n",
      "batch: 8pparte imag\n",
      " tensor([-8.1651e-09,  1.5759e-01,  3.0446e-01, -1.1020e-01, -3.6260e-01,\n",
      "         1.0677e-01,  5.9929e-01, -4.8758e-01, -5.9459e-02,  8.2275e-02,\n",
      "        -3.6967e-02,  9.4263e-02, -5.2863e-02, -1.1918e-01, -2.0644e-02,\n",
      "         3.4011e-01,  2.0240e-01, -1.9185e-01,  4.8584e-02,  1.9797e-01,\n",
      "        -2.9235e-01,  2.0444e-01,  5.2861e-03, -2.2450e-01,  3.5648e-01,\n",
      "        -4.4458e-01,  2.0066e-01, -7.4589e-01, -2.8891e-01, -5.3745e-02,\n",
      "        -2.3135e-01, -5.2209e-08], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 9 parte real\n",
      " tensor([-3.3219e-08,  3.1796e-04, -6.4631e-04,  1.1595e-03, -2.1806e-03,\n",
      "         1.8457e-03, -4.7879e-03,  3.2093e-02,  7.1650e-02, -1.6113e-02,\n",
      "        -3.4774e-02,  3.3257e-01, -1.8227e-01, -1.5073e-01,  7.9488e-04,\n",
      "        -1.4958e-02, -6.8578e-02,  9.6603e-02,  1.6538e-01,  1.9268e-01,\n",
      "         8.2444e-02, -7.6730e-02,  1.5606e-02,  1.2428e-02, -5.2515e-02,\n",
      "        -1.8601e-02, -4.3221e-03,  1.0253e-03, -2.5075e-03,  1.3208e-03,\n",
      "        -9.3833e-04, -2.4518e-05], dtype=torch.float64)\n",
      "batch: 9pparte imag\n",
      " tensor([ 4.0512e-08, -1.1985e-03,  2.9314e-03, -5.4274e-03,  8.7913e-03,\n",
      "        -1.4653e-02,  3.0778e-02,  9.4930e-02,  4.4025e-01,  8.4811e-02,\n",
      "        -2.7101e-02,  1.1465e-01,  5.3310e-01,  1.9199e-01,  3.1227e-01,\n",
      "         5.6413e-02,  2.1254e-01,  6.1398e-01,  1.3305e+00,  8.4916e-01,\n",
      "         7.9171e-01,  7.3123e-01,  6.7633e-01,  1.1366e-01,  2.3832e-02,\n",
      "        -7.7180e-02,  1.1654e-02, -1.1547e-02,  8.1572e-03, -6.0573e-03,\n",
      "         3.2009e-03, -4.1584e-05], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 10 parte real\n",
      " tensor([-6.5448e-23, -1.0633e-02,  3.3691e-02, -2.1371e-02, -5.9640e-01,\n",
      "        -3.2309e-01,  8.5101e-01,  6.5725e-03,  1.1783e-01, -4.8644e-01,\n",
      "         2.9743e-01,  2.0233e-01, -3.8363e-01,  2.6212e-01, -8.8191e-02,\n",
      "         3.0762e-02, -2.6095e-01, -7.3255e-02, -4.3121e-01,  6.2546e-02,\n",
      "         4.0788e-02, -7.1102e-02,  2.0517e-01, -4.0782e-01,  2.8422e-01,\n",
      "        -5.6612e-02, -1.1981e-01, -1.1052e-02,  1.1337e-03,  4.0999e-05,\n",
      "         4.6749e-04,  3.5625e-32], dtype=torch.float64)\n",
      "batch: 10pparte imag\n",
      " tensor([-4.7612e-23, -5.7204e-02,  5.4429e-02, -6.4807e-02, -8.4468e-01,\n",
      "         4.5855e-01,  1.7164e-01, -3.6195e-01, -5.4631e-02, -5.4686e-02,\n",
      "         4.5790e-01, -4.5002e-01,  1.6404e-01, -3.9191e-02,  6.7131e-02,\n",
      "         9.2867e-02, -7.5560e-01, -3.2262e-01, -2.7542e-01,  1.6912e-01,\n",
      "        -1.5499e-01,  2.6169e-01, -5.2323e-01, -1.8016e-01,  2.0260e-01,\n",
      "        -5.6985e-01,  4.1293e-02,  1.7458e-02, -2.8921e-03,  1.9414e-03,\n",
      "        -4.4093e-04, -9.3683e-32], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 11 parte real\n",
      " tensor([ 1.4023e-36,  4.3743e-04, -7.3110e-04,  1.4827e-03, -2.0672e-03,\n",
      "         2.9710e-03, -3.8276e-03,  5.4112e-03, -1.1257e-02,  1.5838e-02,\n",
      "         2.8552e-02,  2.6710e-01,  2.0392e-01,  5.6125e-02, -5.6915e-02,\n",
      "         6.3180e-02, -1.1661e-01, -6.8222e-01, -1.4626e+00, -9.6234e-01,\n",
      "         6.8671e-02,  4.5796e-01,  7.4684e-02, -3.8465e-02, -6.2816e-02,\n",
      "         3.5962e-03, -4.7193e-03,  7.7785e-03, -4.4482e-03,  2.8085e-03,\n",
      "        -1.5069e-03, -1.5132e-10], dtype=torch.float64)\n",
      "batch: 11pparte imag\n",
      " tensor([-1.0059e-36, -1.1647e-03,  2.5154e-03, -4.1057e-03,  6.1248e-03,\n",
      "        -8.6906e-03,  1.1704e-02, -1.6486e-02,  2.3511e-02, -2.6980e-04,\n",
      "         2.6720e-01,  3.2381e-01,  3.4234e-01, -4.3045e-01, -3.4662e-01,\n",
      "        -4.2249e-01, -7.4373e-03,  3.1019e-01,  7.3940e-01,  5.7878e-02,\n",
      "        -1.2838e-01, -3.3881e-01, -5.1152e-02, -1.0451e-01,  3.7521e-02,\n",
      "        -3.5518e-02,  2.6282e-02, -1.8818e-02,  1.2546e-02, -8.7586e-03,\n",
      "         5.1633e-03, -2.9194e-10], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 12 parte real\n",
      " tensor([ 7.4352e-06,  6.4680e-04, -9.9941e-04,  2.5429e-03, -2.4763e-05,\n",
      "        -2.3276e-03, -1.7930e-02,  1.0023e-01,  1.0116e-01,  1.7310e-01,\n",
      "         1.3947e-01, -6.4532e-01, -1.0640e-01, -5.0326e-01, -1.0674e+00,\n",
      "         1.3311e-01,  3.3877e-03, -9.8176e-02, -2.9349e-01,  2.6077e-01,\n",
      "        -3.6683e-01, -4.8405e-01, -1.7607e-01, -1.1881e-01, -2.0907e-01,\n",
      "         4.2235e-02,  1.4881e-01, -3.1260e-02, -3.7520e-02,  1.9459e-02,\n",
      "         9.4719e-03, -2.3528e-12], dtype=torch.float64)\n",
      "batch: 12pparte imag\n",
      " tensor([ 1.2043e-05,  7.0375e-04, -1.7403e-03,  2.1218e-03, -1.9650e-03,\n",
      "         9.1312e-03,  2.2650e-03,  7.6294e-02, -9.2243e-03,  2.0087e-01,\n",
      "         3.4491e-02, -4.1420e-01, -8.0945e-02, -5.7593e-02, -1.0726e+00,\n",
      "        -2.3476e-02, -3.4248e-01,  6.5824e-01,  4.1528e-01, -4.0197e-01,\n",
      "        -4.0515e-01,  1.4245e-01,  6.2963e-01, -2.9881e-03, -1.0495e-03,\n",
      "         2.5007e-01,  5.7023e-02,  2.0022e-02,  6.9456e-03,  3.5395e-03,\n",
      "         1.4990e-03, -1.7541e-12], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 13 parte real\n",
      " tensor([ 4.2778e-07, -4.0702e-04,  7.1698e-04,  9.3659e-03,  4.7799e-02,\n",
      "        -1.0862e-01, -2.3056e-01, -3.3869e-01, -3.0399e-02,  6.2270e-02,\n",
      "        -1.2966e-01,  2.7345e-02,  1.7940e-02, -3.1689e-01,  2.3234e-01,\n",
      "        -4.5896e-01, -7.7385e-01,  2.5317e-02,  1.1359e-01,  1.1771e-02,\n",
      "        -1.6288e-01,  3.5549e-01, -3.5966e-01, -2.8183e-01,  6.4769e-01,\n",
      "        -4.6770e-01, -1.5805e-01,  5.8337e-02,  1.3582e-01, -1.4898e-02,\n",
      "        -3.0884e-02,  2.9698e-08], dtype=torch.float64)\n",
      "batch: 13pparte imag\n",
      " tensor([ 2.1633e-07,  9.0475e-05,  2.8778e-04, -1.9049e-03, -2.9665e-02,\n",
      "        -2.5556e-01, -5.7405e-01,  6.4062e-02,  2.1428e-01, -1.8721e-01,\n",
      "         1.0312e-01, -4.4335e-01, -4.0847e-02, -7.2033e-01, -9.2298e-01,\n",
      "        -6.7133e-01,  1.1754e-01,  8.9655e-02, -1.0718e-01,  1.2838e-01,\n",
      "        -1.1715e-01,  2.7413e-02, -2.8019e-01,  2.8182e-01,  8.0522e-02,\n",
      "         8.2692e-02, -5.9386e-01, -2.9836e-01,  1.7246e-01, -1.2379e-01,\n",
      "        -6.3949e-02,  3.7004e-08], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 14 parte real\n",
      " tensor([-5.1334e-28,  2.6538e-04, -7.3438e-04,  1.0143e-03, -2.6146e-03,\n",
      "        -2.1224e-03, -1.1434e-03,  1.0777e-01,  1.0869e-01,  2.5320e-01,\n",
      "        -5.1344e-01,  4.5135e-01,  4.1862e-02, -5.3632e-01,  8.6281e-01,\n",
      "        -6.4370e-01, -1.7738e-01,  6.6632e-01, -2.4104e-01,  1.4442e-01,\n",
      "        -2.3157e-01,  1.7502e-02, -2.7766e-01, -2.2146e-02, -2.6299e-02,\n",
      "         1.0177e-02, -4.3884e-04,  2.9106e-03, -1.5397e-03,  1.0337e-03,\n",
      "        -5.7923e-04,  3.2686e-28], dtype=torch.float64)\n",
      "batch: 14pparte imag\n",
      " tensor([-2.0178e-28, -6.2333e-05, -4.7064e-05, -4.9910e-04,  3.4827e-04,\n",
      "        -1.7303e-03, -5.7516e-03, -1.3805e-02, -3.9388e-01, -1.5331e-01,\n",
      "         4.9098e-01,  7.5866e-02, -2.0343e-01,  4.0177e-02,  3.6702e-01,\n",
      "        -8.9013e-01, -1.0348e+00, -9.3616e-02,  2.8305e-01, -1.0795e-02,\n",
      "        -1.8780e-01,  1.3200e-01, -3.6492e-01, -1.9214e-01,  1.2320e-03,\n",
      "         2.3625e-03, -9.3381e-04, -3.3158e-04,  4.6916e-04,  1.0259e-04,\n",
      "         1.3138e-04, -1.3073e-28], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 15 parte real\n",
      " tensor([ 5.3690e-36,  3.2826e-01,  2.2885e-01,  4.5221e-02,  2.5044e-01,\n",
      "         3.9539e-02, -4.5579e-01,  1.4633e-01,  1.2068e-01, -1.0215e-01,\n",
      "         5.4766e-02, -2.9040e-02,  1.2633e-02, -4.7529e-03,  1.3610e-04,\n",
      "         4.1169e-03, -6.8513e-03,  7.0520e-03, -2.8920e-03,  1.0104e-03,\n",
      "        -3.1413e-03,  4.3430e-03, -2.0906e-03,  4.2067e-02, -3.4926e-02,\n",
      "        -1.9936e-01, -2.4019e-01,  6.1077e-01,  5.2698e-01, -1.2175e-01,\n",
      "         3.4712e-01, -9.7972e-58], dtype=torch.float64)\n",
      "batch: 15pparte imag\n",
      " tensor([-1.0174e-35,  1.2636e-01,  5.4095e-01,  1.5671e-01, -2.5820e-01,\n",
      "        -5.4559e-01,  5.9195e-01,  2.8570e-01,  2.7898e-01, -4.3554e-01,\n",
      "         2.9800e-01, -1.7730e-01,  1.0682e-01, -7.7426e-02,  5.7516e-02,\n",
      "        -4.4697e-02,  3.9593e-02, -3.4711e-02,  1.8498e-02,  2.9259e-03,\n",
      "        -2.9681e-02,  1.0494e-01, -2.1921e-01,  4.2493e-01, -6.4840e-01,\n",
      "         8.0760e-01, -3.4534e-01, -2.9404e-01, -7.5017e-01,  2.8038e-01,\n",
      "        -5.8691e-01,  3.7835e-58], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 16 parte real\n",
      " tensor([ 3.4926e-05,  5.0585e-03, -1.6906e-01, -3.1021e-03, -9.1243e-02,\n",
      "        -1.9947e-01, -1.5741e-01,  6.3043e-02,  1.4166e-01,  3.3571e-01,\n",
      "        -5.7740e-03,  2.6590e-01,  1.1262e-01, -1.4838e-01,  3.9447e-01,\n",
      "         2.6447e-02, -1.0357e-01, -2.3058e-01, -2.1886e-01,  1.6366e-01,\n",
      "        -3.8771e-01, -7.2047e-01,  4.4661e-02, -8.3738e-02,  1.5531e-01,\n",
      "         3.6697e-02,  2.3033e-01,  4.9680e-01,  9.5967e-02,  1.4735e-02,\n",
      "        -2.0896e-01,  3.1541e-12], dtype=torch.float64)\n",
      "batch: 16pparte imag\n",
      " tensor([ 9.6417e-04, -3.8954e-02,  4.5628e-02,  1.2649e-01,  1.2875e-01,\n",
      "         2.8103e-01,  1.8376e-01,  1.4604e-01,  5.8469e-01,  9.1929e-01,\n",
      "         2.6432e-01,  1.2325e-01,  1.2696e-01,  2.1474e-01, -1.3364e-01,\n",
      "        -2.0436e-01,  1.0755e-01,  1.0416e-01, -2.4924e-01, -9.7376e-02,\n",
      "        -1.5350e-01,  3.5388e-01,  3.4578e-01,  6.6625e-01, -1.0945e+00,\n",
      "         9.4642e-04,  1.8424e-01,  1.7381e-01, -9.4297e-02,  3.3777e-01,\n",
      "         1.1183e-01, -2.4266e-13], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 17 parte real\n",
      " tensor([ 1.5076e-24, -4.4686e-04,  9.5760e-04, -1.7220e-03,  2.5857e-03,\n",
      "        -4.2349e-03,  5.7122e-03, -7.8803e-03,  1.0757e-02, -2.8728e-03,\n",
      "         7.4655e-02,  5.8214e-02,  1.3488e-01, -1.1333e+00,  7.1156e-01,\n",
      "         1.9505e-01,  8.7251e-01,  1.7971e-01, -7.4191e-01, -2.5201e-02,\n",
      "        -1.1838e-01, -7.7674e-02,  1.7366e-02, -1.2662e-02,  1.3015e-02,\n",
      "        -8.0474e-03,  5.6152e-03, -3.8836e-03,  2.5378e-03, -1.6440e-03,\n",
      "         9.7571e-04,  6.8945e-14], dtype=torch.float64)\n",
      "batch: 17pparte imag\n",
      " tensor([-1.0150e-24,  8.5866e-05, -2.3020e-04,  3.7835e-04, -6.9929e-04,\n",
      "         7.5612e-04, -1.4072e-03,  1.7167e-03, -5.6236e-03, -2.3168e-02,\n",
      "        -1.1374e-01, -2.5801e-01, -1.4066e-01,  5.8894e-01,  7.2981e-01,\n",
      "         5.7648e-01, -3.5909e-01, -4.4230e-01,  3.2795e-01,  5.7464e-01,\n",
      "         3.5853e-01,  2.0098e-01,  5.9446e-02,  1.4224e-02, -2.3546e-03,\n",
      "         1.7879e-03, -1.2286e-03,  9.9145e-04, -5.8860e-04,  3.2607e-04,\n",
      "        -2.3770e-04,  1.3406e-13], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 18 parte real\n",
      " tensor([ 3.0228e-22, -4.9658e-04,  1.8260e-03, -1.9474e-03,  9.8870e-03,\n",
      "        -6.2921e-03, -1.4103e-02,  3.6484e-02,  2.5979e-01,  3.6175e-01,\n",
      "         3.3894e-01,  1.7545e-01, -9.6305e-02, -5.4315e-01, -1.4248e-01,\n",
      "         1.6229e-02,  6.6146e-02, -1.4670e-02,  3.0881e-01,  4.7645e-01,\n",
      "         7.3487e-01,  6.8545e-01,  9.0658e-01,  4.3240e-01,  1.6840e-01,\n",
      "         3.4686e-02, -2.6464e-02,  2.4190e-02,  3.8730e-02,  3.9285e-03,\n",
      "         6.1430e-03, -2.9936e-09], dtype=torch.float64)\n",
      "batch: 18pparte imag\n",
      " tensor([ 8.4611e-23,  1.7644e-03, -4.4493e-03,  7.6521e-03, -1.0205e-02,\n",
      "         1.1484e-02, -7.0074e-02,  4.6359e-02, -1.5906e-02,  1.5288e-01,\n",
      "         2.1391e-01,  4.0242e-01, -6.7357e-01, -8.9250e-03, -5.7702e-02,\n",
      "         9.1788e-02, -4.4192e-01, -2.0724e-01,  1.8284e-01,  9.6451e-01,\n",
      "         2.3607e-01, -3.8805e-01, -3.8969e-01,  3.5642e-01,  1.0490e-01,\n",
      "         1.0339e-01, -4.9330e-02,  5.4711e-02, -2.4831e-02,  6.5410e-03,\n",
      "        -1.8244e-02,  7.4196e-09], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 19 parte real\n",
      " tensor([-1.2398e-14, -2.9757e-04,  6.5966e-04, -1.2725e-03,  1.6208e-03,\n",
      "        -2.8681e-03,  4.2542e-03, -7.7313e-03, -1.3760e-02, -1.2434e-01,\n",
      "        -3.1999e-01, -5.5780e-01, -4.4780e-01, -2.2202e-01, -2.3420e-02,\n",
      "        -1.4314e-02, -5.1237e-02, -3.2400e-01, -7.7222e-01, -1.1894e+00,\n",
      "        -9.5670e-01, -4.6907e-01, -1.0944e-01, -3.9907e-02, -1.6895e-03,\n",
      "        -9.3982e-03,  3.9913e-03, -3.4309e-03,  2.1482e-03, -1.6531e-03,\n",
      "         8.8805e-04,  2.0548e-40], dtype=torch.float64)\n",
      "batch: 19pparte imag\n",
      " tensor([ 3.3523e-15, -8.5390e-05,  2.9501e-04, -5.3356e-04,  6.7236e-04,\n",
      "        -1.3969e-03,  1.3332e-03, -3.7913e-03, -2.0721e-03, -4.9463e-02,\n",
      "        -1.4358e-01, -2.8704e-01, -2.7227e-01, -1.6882e-01, -6.2293e-02,\n",
      "        -3.7577e-02,  2.7441e-02,  1.9885e-01,  5.5643e-01,  7.4941e-01,\n",
      "         5.8528e-01,  2.2530e-01,  4.7577e-02, -1.0895e-02, -2.5742e-03,\n",
      "        -4.8849e-03,  1.9808e-03, -1.4159e-03,  1.0379e-03, -7.6136e-04,\n",
      "         3.9383e-04,  1.8521e-40], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 20 parte real\n",
      " tensor([-5.8071e-19,  4.8196e-04, -1.0637e-03,  2.0236e-03, -3.0888e-03,\n",
      "         4.8044e-03, -6.4535e-03,  9.6678e-03, -1.9840e-02,  6.8345e-03,\n",
      "        -1.1130e-02,  3.8041e-01,  2.9863e-01, -5.8226e-02, -5.5041e-01,\n",
      "        -3.9871e-01, -2.6106e-01,  7.9479e-01,  1.2738e+00,  5.1891e-01,\n",
      "        -2.9013e-01, -5.6122e-02, -2.7426e-02,  1.5179e-02, -8.2326e-03,\n",
      "         7.2746e-03, -4.5711e-03,  2.9807e-03, -2.1671e-03,  1.2952e-03,\n",
      "        -7.4448e-04, -8.7170e-35], dtype=torch.float64)\n",
      "batch: 20pparte imag\n",
      " tensor([-2.3158e-18,  6.2426e-04, -1.3713e-03,  2.6247e-03, -4.1593e-03,\n",
      "         6.2167e-03, -9.1716e-03,  1.3842e-02, -1.9002e-02,  2.0825e-02,\n",
      "        -1.3853e-01, -4.3461e-01, -8.0854e-01,  1.0953e-01,  1.4747e-01,\n",
      "         1.1688e-01,  5.9734e-02,  2.5462e-01,  3.0273e-01,  8.4814e-01,\n",
      "         5.1026e-01,  1.9285e-01, -1.1901e-02,  2.0749e-02, -1.2195e-02,\n",
      "         9.5280e-03, -5.9563e-03,  4.2927e-03, -2.9045e-03,  1.8347e-03,\n",
      "        -1.0418e-03,  1.3242e-36], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 21 parte real\n",
      " tensor([-6.6671e-06, -4.0821e-04,  1.0399e-03, -2.1010e-03,  4.3978e-03,\n",
      "         1.0987e-04,  6.8366e-03,  1.2245e-01,  1.8873e-01,  1.0829e-02,\n",
      "        -2.6875e-01,  3.2135e-02,  2.5167e-01, -2.3158e-01, -2.7479e-01,\n",
      "        -5.4353e-02, -1.4078e-01,  1.3800e-01, -3.1085e-01, -1.5225e-01,\n",
      "        -3.8897e-01, -9.0077e-01,  4.9038e-01, -8.9222e-02, -6.3141e-02,\n",
      "         1.0130e-01,  8.1716e-02,  1.2240e-02,  2.3231e-03, -1.2960e-03,\n",
      "         6.1460e-04, -2.9173e-13], dtype=torch.float64)\n",
      "batch: 21pparte imag\n",
      " tensor([ 1.2485e-05, -9.2854e-04,  2.4629e-03, -1.9634e-03,  8.9965e-03,\n",
      "        -1.0792e-02, -1.9513e-02, -3.5385e-02, -1.7873e-02, -2.3197e-01,\n",
      "         3.1088e-02,  3.9920e-01, -1.3459e-01,  2.2781e-02,  8.5029e-01,\n",
      "         5.9730e-01,  7.9736e-01,  2.7374e-01,  7.9674e-01,  1.8784e-01,\n",
      "         7.0989e-01,  6.3032e-01,  3.4766e-01,  1.3060e-01, -1.2808e-01,\n",
      "        -7.8782e-02,  9.2090e-03, -2.0271e-02,  4.6539e-03, -3.7798e-03,\n",
      "         2.6030e-03,  2.9202e-12], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 22 parte real\n",
      " tensor([-2.7901e-06,  4.9782e-04, -9.0639e-04,  1.6998e-03, -2.3888e-03,\n",
      "         2.5589e-03, -6.3101e-03,  7.9311e-03, -3.0612e-02, -3.1292e-02,\n",
      "        -9.6820e-02,  1.5368e-02,  5.1373e-01,  1.1848e+00,  1.2963e+00,\n",
      "         9.1840e-01,  3.7220e-01,  4.5178e-01,  2.8246e-01,  1.8926e-01,\n",
      "         6.5048e-02,  3.5768e-02,  1.3023e-03,  7.2022e-03, -5.3134e-03,\n",
      "         3.2312e-03, -2.4420e-03,  1.8952e-03, -1.2981e-03,  8.9877e-04,\n",
      "        -5.3278e-04, -2.5991e-15], dtype=torch.float64)\n",
      "batch: 22pparte imag\n",
      " tensor([-1.3274e-06, -6.0564e-04,  1.3780e-03, -2.3873e-03,  3.4963e-03,\n",
      "        -4.6257e-03,  1.8726e-02,  1.5043e-02,  5.1676e-02,  3.2949e-02,\n",
      "        -9.2135e-02, -3.9293e-01, -3.7500e-01, -1.8067e-01, -1.0344e-01,\n",
      "        -3.9520e-01, -1.0454e-01, -1.0705e-01,  2.4382e-01,  3.9738e-01,\n",
      "         2.2955e-01,  2.5133e-02,  2.1126e-02, -1.0717e-02,  5.0243e-03,\n",
      "        -4.4492e-03,  3.4328e-03, -2.3428e-03,  1.7378e-03, -1.1565e-03,\n",
      "         7.1638e-04, -2.0369e-16], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 23 parte real\n",
      " tensor([ 1.4692e-41,  4.6971e-04, -1.3663e-03,  3.1752e-04, -1.0304e-02,\n",
      "        -2.7864e-02, -4.6174e-02,  1.5220e-01,  3.1016e-01, -8.4466e-02,\n",
      "         2.5539e-02,  4.1543e-02, -9.7207e-02,  5.9894e-02, -3.3064e-01,\n",
      "        -1.9326e-01, -4.0263e-01, -7.9903e-01, -2.2392e-01,  1.0669e+00,\n",
      "         2.2417e-01, -2.9885e-01,  4.5870e-01,  1.2198e-01, -9.8471e-02,\n",
      "        -1.4769e-02, -2.5509e-02, -7.2023e-03, -3.3658e-03,  1.6227e-03,\n",
      "         8.6341e-05, -1.8269e-24], dtype=torch.float64)\n",
      "batch: 23pparte imag\n",
      " tensor([-2.2326e-41, -2.8620e-03,  7.2074e-03, -1.2512e-02,  2.2656e-02,\n",
      "        -1.4981e-02,  1.9083e-01,  1.0510e-01, -4.0467e-01,  5.2796e-02,\n",
      "         2.5804e-01, -5.2594e-01,  6.6088e-01, -3.6460e-01, -1.8777e-01,\n",
      "        -2.6096e-01, -1.7192e-01, -3.0320e-01,  8.7716e-01,  3.5931e-01,\n",
      "         6.7179e-02, -6.9082e-01,  8.9423e-02, -1.1461e-01,  2.0576e-01,\n",
      "         9.5185e-02,  6.5928e-02, -4.3280e-02,  1.4989e-02, -1.3132e-02,\n",
      "         7.1019e-03, -3.3165e-24], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 24 parte real\n",
      " tensor([-2.3217e-08, -1.7594e-04,  9.5902e-04, -1.7967e-03,  3.8624e-03,\n",
      "         3.0646e-02,  1.5896e-01,  3.3141e-01,  2.1927e-01, -3.5012e-01,\n",
      "        -5.8640e-01, -3.1072e-01, -2.3165e-01, -1.3096e-01,  1.4332e-01,\n",
      "         1.1006e-01,  3.9103e-02, -5.7207e-03, -9.2779e-03, -7.1638e-02,\n",
      "        -3.4590e-01, -5.9880e-01, -3.2714e-01, -7.1242e-02, -2.5769e-04,\n",
      "        -3.9647e-04, -8.6298e-04, -1.3597e-03,  2.4434e-04, -1.5898e-04,\n",
      "         2.9865e-04, -2.0088e-26], dtype=torch.float64)\n",
      "batch: 24pparte imag\n",
      " tensor([ 5.9701e-08,  3.4329e-03, -8.1355e-03,  1.5420e-02, -1.9976e-02,\n",
      "         7.9396e-02,  1.4533e-02, -6.8912e-02, -5.3157e-01, -6.0232e-01,\n",
      "        -1.4721e+00, -6.4500e-01,  2.1980e-01,  7.8087e-01,  1.1877e-01,\n",
      "         9.6725e-02, -1.1798e-01,  5.0149e-02, -6.3792e-02,  1.5162e-01,\n",
      "        -5.2457e-03,  2.0261e-01, -9.9083e-02,  3.8517e-02, -3.6627e-02,\n",
      "         2.6886e-02, -1.5631e-02,  1.0344e-02, -7.1923e-03,  4.1981e-03,\n",
      "        -2.3586e-03, -9.8053e-26], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 25 parte real\n",
      " tensor([-3.7229e-41,  2.9652e-07, -9.3785e-07,  1.7091e-06, -2.3512e-06,\n",
      "         4.1380e-06, -8.0216e-06,  1.3265e-05, -1.8429e-05,  2.2559e-05,\n",
      "        -2.5389e-05,  2.7069e-05, -3.5322e-05,  2.0492e-05,  1.2449e-03,\n",
      "         9.6553e-03,  6.2311e-02,  2.6395e-01,  6.9730e-01,  1.1461e+00,\n",
      "         1.1732e+00,  7.4988e-01,  3.0000e-01,  7.5396e-02,  1.1911e-02,\n",
      "         1.2094e-03,  6.5503e-05,  9.6180e-06, -3.5347e-06,  1.9206e-06,\n",
      "        -1.1229e-06,  1.3769e-13], dtype=torch.float64)\n",
      "batch: 25pparte imag\n",
      " tensor([ 5.0264e-39, -4.7116e-07,  1.2336e-06, -1.8859e-06,  3.2168e-06,\n",
      "        -5.6715e-06,  7.9745e-06, -8.7417e-06,  7.8473e-06, -6.0786e-06,\n",
      "         4.1582e-06, -1.8966e-06, -4.2191e-06,  1.6886e-04,  5.6840e-04,\n",
      "         5.3112e-04,  6.6116e-03,  6.1149e-02,  2.5976e-01,  5.9689e-01,\n",
      "         7.9446e-01,  6.3210e-01,  3.0588e-01,  9.0957e-02,  1.6749e-02,\n",
      "         1.9068e-03,  1.4501e-04, -7.7308e-07,  5.0521e-06, -2.8735e-06,\n",
      "         1.4627e-06,  2.1187e-13], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 26 parte real\n",
      " tensor([-8.5977e-04,  8.0287e-04,  1.1854e-02, -1.6811e-02, -9.7244e-03,\n",
      "        -1.2942e-01,  3.8489e-02,  9.0015e-02,  5.0647e-02, -1.1238e-03,\n",
      "         3.5437e-01,  7.9021e-01,  1.4082e+00,  8.3477e-01,  5.3053e-01,\n",
      "        -7.2961e-01,  6.8386e-02,  1.0643e-01,  4.0028e-02, -1.7021e-01,\n",
      "         2.0430e-01, -7.1252e-03, -5.8692e-02, -1.4222e-02, -1.7440e-02,\n",
      "        -1.2134e-02,  1.1511e-02, -7.6741e-03,  5.4678e-03, -3.6775e-03,\n",
      "         2.2522e-03,  9.1177e-13], dtype=torch.float64)\n",
      "batch: 26pparte imag\n",
      " tensor([ 6.9821e-04, -1.3111e-03, -7.7756e-03,  9.1228e-03,  1.4167e-02,\n",
      "        -1.9388e-02,  9.1060e-02,  3.5801e-02,  9.4055e-02,  3.8745e-02,\n",
      "         4.9367e-01,  1.8255e-01,  5.2960e-01,  3.7104e-01,  2.7816e-01,\n",
      "         3.7529e-02,  3.4439e-01, -1.4065e-01, -1.3744e-01,  1.0653e-01,\n",
      "         3.1103e-01,  1.5828e-01,  1.1942e-01,  4.7707e-02,  4.8616e-03,\n",
      "        -2.7744e-02,  3.6414e-03, -5.0619e-03,  3.9663e-03, -2.5476e-03,\n",
      "         1.5525e-03,  2.5407e-12], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 27 parte real\n",
      " tensor([ 6.5646e-04, -3.7697e-03,  8.2093e-04, -4.0906e-02,  9.9568e-03,\n",
      "         1.6697e-01,  2.0373e-01, -2.0214e-01, -1.1255e-01, -1.3932e-01,\n",
      "        -5.4295e-01,  7.2203e-03,  4.5075e-01, -6.2832e-01, -3.0994e-01,\n",
      "        -2.9240e-01,  8.3859e-01, -7.3409e-01,  7.6631e-01,  2.4713e-01,\n",
      "         4.6630e-01,  1.7659e-01,  1.5717e-01,  1.4627e-01, -2.1346e-01,\n",
      "        -1.4931e-02, -1.0319e-01, -5.0143e-01,  2.3268e-01,  6.1456e-02,\n",
      "        -2.4348e-01, -1.1671e-13], dtype=torch.float64)\n",
      "batch: 27pparte imag\n",
      " tensor([-5.0280e-05, -2.7783e-03,  3.1072e-03, -3.3739e-03, -1.1713e-02,\n",
      "         8.6290e-02,  1.1395e-01,  3.9537e-02, -3.2787e-02, -1.1263e-01,\n",
      "         1.4435e-02, -3.3067e-02,  3.2928e-01, -9.7263e-03, -9.0149e-02,\n",
      "         3.2085e-02,  2.7560e-01, -1.7537e-01, -6.6945e-01, -9.4009e-03,\n",
      "        -1.9184e-01, -5.9932e-01, -5.1400e-02, -2.7733e-01, -1.3372e-01,\n",
      "        -5.2441e-01,  1.8304e-01, -7.4609e-02, -1.2909e-01, -1.4373e-01,\n",
      "         2.7154e-01,  1.4136e-13], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 28 parte real\n",
      " tensor([ 1.6814e-06,  2.6370e-04, -5.9691e-04,  1.1686e-03, -1.0499e-03,\n",
      "         3.8392e-03,  4.6054e-03,  1.8525e-02,  1.7097e-02, -3.3824e-02,\n",
      "        -1.0634e-01, -2.5520e-02,  2.0596e-01, -4.7814e-02, -6.5805e-01,\n",
      "        -6.2651e-01, -7.0461e-01, -1.0304e+00, -1.1669e+00, -2.2293e-01,\n",
      "         4.5885e-02, -1.9114e-02, -3.2046e-02,  1.0470e-02,  2.2445e-03,\n",
      "         3.9410e-03, -3.7268e-03,  2.1609e-03, -1.3504e-03,  8.1534e-04,\n",
      "        -5.2661e-04,  1.2760e-06], dtype=torch.float64)\n",
      "batch: 28pparte imag\n",
      " tensor([ 2.5810e-06,  8.7820e-04, -1.8393e-03,  3.1610e-03, -5.6191e-03,\n",
      "         5.5917e-03, -1.3426e-02,  3.4837e-03, -3.6692e-02, -1.2035e-01,\n",
      "        -2.0670e-01, -8.2430e-02, -1.5802e-02,  5.2400e-01,  2.7794e-01,\n",
      "         3.9051e-01,  1.9777e-01,  5.6095e-01,  5.3218e-01,  6.1224e-01,\n",
      "        -1.1077e-01, -8.3795e-02, -9.4630e-02,  1.4416e-02, -1.3853e-02,\n",
      "         1.1465e-02, -8.5339e-03,  6.1500e-03, -4.5758e-03,  2.9566e-03,\n",
      "        -1.7321e-03,  3.6011e-07], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 29 parte real\n",
      " tensor([-7.9268e-22,  1.6004e-01, -1.6234e-01, -7.2793e-01,  5.9384e-02,\n",
      "         7.1873e-01, -4.0646e-01,  3.1337e-01,  3.4504e-01, -2.7343e-01,\n",
      "         1.7797e-01, -1.5324e-01,  3.4734e-02,  1.1306e-01,  2.3164e-01,\n",
      "         5.7766e-01, -1.9510e-03, -2.0773e-02,  1.2588e-01,  6.9730e-04,\n",
      "        -1.5774e-01,  1.9140e-01, -6.0273e-02, -3.5663e-01,  4.8930e-01,\n",
      "         2.1406e-01,  3.4256e-01,  5.8094e-01,  3.6811e-01, -2.5845e-02,\n",
      "        -1.5381e-01, -8.2913e-17], dtype=torch.float64)\n",
      "batch: 29pparte imag\n",
      " tensor([-3.3539e-22, -6.0669e-02, -1.2092e-01,  3.3499e-01, -2.7104e-01,\n",
      "        -6.1656e-01, -4.1589e-01,  3.9899e-01, -1.8096e-01, -1.2122e-01,\n",
      "         1.1105e-01, -7.7887e-02,  1.8854e-02,  2.1535e-01, -8.5007e-01,\n",
      "         4.0436e-02, -1.4254e-01,  2.7374e-02, -2.6208e-01,  1.7920e-01,\n",
      "         1.4908e-02, -1.4875e-01,  2.6372e-01, -1.5922e-01,  1.8869e-01,\n",
      "        -7.9594e-02,  3.2234e-01,  4.2211e-02, -2.3274e-01, -1.0244e-01,\n",
      "         3.5308e-01, -8.0322e-17], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 30 parte real\n",
      " tensor([-1.4397e-08, -1.4025e-04,  3.1630e-04, -5.6986e-04,  8.1155e-04,\n",
      "        -3.0486e-04,  5.1543e-03,  8.8899e-03,  3.5029e-02, -1.3822e-02,\n",
      "        -3.9171e-02, -3.1931e-02, -7.1300e-01, -1.1576e+00, -5.1548e-01,\n",
      "        -8.2357e-02,  2.9449e-01,  7.8416e-01,  6.8030e-01, -5.4784e-01,\n",
      "        -6.9500e-01, -1.0462e-01, -3.4379e-03,  7.8207e-03,  1.5589e-02,\n",
      "         1.0970e-03,  2.7717e-03, -1.1509e-03,  8.7364e-04, -5.8594e-04,\n",
      "         3.2022e-04, -4.9138e-14], dtype=torch.float64)\n",
      "batch: 30pparte imag\n",
      " tensor([-2.6925e-08, -4.9460e-04,  1.1692e-03, -2.0169e-03,  3.3385e-03,\n",
      "        -4.5502e-03,  6.1497e-03, -2.4872e-02,  8.5223e-03, -6.1285e-03,\n",
      "         5.7475e-02,  1.1348e-01, -2.2494e-01, -7.2822e-01, -4.2843e-01,\n",
      "        -2.9527e-01, -1.6758e-01, -6.2920e-01,  5.0035e-02,  2.2569e-01,\n",
      "        -8.5884e-02, -1.7311e-01,  1.8606e-02, -1.2360e-04,  1.8851e-02,\n",
      "        -9.8752e-03,  7.1554e-03, -4.8915e-03,  3.1862e-03, -2.0283e-03,\n",
      "         1.1611e-03, -2.5879e-15], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 31 parte real\n",
      " tensor([-3.8345e-12, -2.2718e-05,  8.4190e-05, -1.7867e-04,  2.8890e-04,\n",
      "        -3.8590e-04,  5.5573e-04, -9.6634e-05,  2.8075e-03,  8.3128e-03,\n",
      "         3.2127e-02,  9.8025e-02,  2.6439e-01,  5.6803e-01,  9.0564e-01,\n",
      "         1.1251e+00,  1.0995e+00,  8.5650e-01,  5.3920e-01,  2.7354e-01,\n",
      "         1.1500e-01,  3.8252e-02,  1.1764e-02,  1.8542e-03,  1.1483e-03,\n",
      "        -5.1421e-04,  5.3053e-04, -4.4036e-04,  3.5620e-04, -2.6644e-04,\n",
      "         1.7563e-04,  1.1153e-11], dtype=torch.float64)\n",
      "batch: 31pparte imag\n",
      " tensor([ 8.3234e-12,  5.5958e-05, -1.1295e-04,  1.4825e-04, -1.5062e-04,\n",
      "         1.1762e-04, -6.0142e-05,  2.2253e-04,  1.7329e-03,  8.6484e-03,\n",
      "         3.2622e-02,  8.8625e-02,  1.6987e-01,  1.8840e-01,  8.2856e-02,\n",
      "         2.3650e-01,  3.9776e-01,  4.3430e-01,  3.4494e-01,  2.0789e-01,\n",
      "         9.7355e-02,  3.5594e-02,  1.0395e-02,  2.2997e-03,  4.6403e-04,\n",
      "         4.4711e-05, -1.3554e-06,  2.9544e-05, -4.4516e-05,  5.1539e-05,\n",
      "        -4.5755e-05, -8.8956e-12], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 32 parte real\n",
      " tensor([-1.1567e-29,  3.9145e-04, -8.4778e-04,  1.7290e-03, -2.8898e-03,\n",
      "         5.3978e-03, -8.3457e-03,  5.9285e-03, -1.6382e-01, -7.7270e-01,\n",
      "        -1.4078e+00, -3.7260e-01,  4.7125e-03,  3.5137e-02, -1.8943e-02,\n",
      "         1.1865e-02, -1.9003e-02,  1.9701e-02, -4.7836e-02, -3.9501e-02,\n",
      "        -2.5332e-01, -9.6894e-02, -4.9801e-02,  6.9242e-02, -1.1438e-02,\n",
      "         1.4179e-02, -9.8491e-03,  6.0717e-03, -4.0813e-03,  2.6108e-03,\n",
      "        -1.2366e-03,  1.0873e-27], dtype=torch.float64)\n",
      "batch: 32pparte imag\n",
      " tensor([-1.8541e-29, -2.8797e-04,  9.1552e-04, -1.6764e-03,  3.2071e-03,\n",
      "        -3.9090e-03,  8.0797e-03, -1.4102e-02, -3.5060e-02, -5.5717e-01,\n",
      "        -1.0774e+00, -9.4628e-01, -1.1928e-01, -2.6827e-02,  1.2329e-02,\n",
      "        -1.2734e-02,  1.4966e-02, -1.9841e-02,  5.8709e-02,  6.6160e-02,\n",
      "         3.0368e-01,  2.1251e-01,  3.1099e-01,  8.6172e-02,  4.4766e-02,\n",
      "        -8.6281e-03,  1.0581e-02, -6.4726e-03,  3.4896e-03, -2.4892e-03,\n",
      "         1.2327e-03,  1.1090e-26], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 33 parte real\n",
      " tensor([-1.7153e-05, -1.1536e-04, -1.5836e-03,  5.2405e-03,  1.9901e-02,\n",
      "         3.6016e-02,  3.8357e-02,  4.1305e-02, -5.0534e-02,  1.8202e-01,\n",
      "         2.1278e-01, -5.4940e-02, -9.9495e-01, -9.2544e-01, -6.3856e-01,\n",
      "         8.4213e-03, -1.7842e-01, -5.0859e-01,  2.9566e-01, -4.3050e-02,\n",
      "         1.2703e-01,  1.9325e-01, -1.5736e-01,  2.2524e-02, -4.7157e-02,\n",
      "        -5.9624e-03, -1.0633e-02,  3.3545e-03,  1.6985e-03,  2.6193e-03,\n",
      "        -7.4228e-04, -2.2608e-16], dtype=torch.float64)\n",
      "batch: 33pparte imag\n",
      " tensor([-1.3433e-04,  1.1537e-04,  4.7959e-04, -1.3136e-03, -1.0188e-02,\n",
      "        -3.1597e-02, -5.7814e-02,  1.2870e-01,  2.1348e-01,  1.8802e-01,\n",
      "         5.7779e-01,  2.9068e-01, -1.3589e-01,  4.1911e-01,  3.3801e-01,\n",
      "        -6.3755e-01, -3.3389e-02,  2.3195e-02, -1.9507e-01,  1.2461e-01,\n",
      "         5.3683e-01,  1.0103e+00,  2.0508e-01, -4.2501e-03,  1.3578e-01,\n",
      "         6.5054e-02, -5.2201e-03, -1.2171e-02, -4.3274e-03, -9.0246e-04,\n",
      "         3.0153e-04,  1.5518e-14], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 34 parte real\n",
      " tensor([-1.9548e-09, -1.1807e-04,  3.5804e-04, -9.2621e-04,  4.9929e-04,\n",
      "        -2.3555e-03, -3.8843e-04, -2.7583e-03,  7.0863e-03, -7.5581e-02,\n",
      "        -5.6131e-01, -7.6122e-01, -1.2206e-01, -2.2138e-01, -6.3015e-01,\n",
      "        -4.4697e-01, -4.9543e-01,  1.8018e-01,  1.0159e+00, -6.0878e-02,\n",
      "        -6.2549e-01, -4.5594e-01, -3.5976e-01, -1.0800e-01, -7.9251e-03,\n",
      "        -3.3293e-03,  1.1634e-03, -8.9714e-04,  6.2716e-04, -4.8080e-04,\n",
      "         3.2790e-04,  4.2859e-25], dtype=torch.float64)\n",
      "batch: 34pparte imag\n",
      " tensor([-1.2989e-09,  4.5575e-04, -1.0435e-03,  2.1368e-03, -2.7967e-03,\n",
      "         2.8982e-03, -1.5328e-02, -2.6926e-02, -6.2229e-02,  5.5560e-02,\n",
      "         1.9407e-01, -6.6493e-02, -6.2658e-01, -3.1956e-01, -9.2136e-02,\n",
      "         2.4874e-01,  1.8283e-01, -5.5535e-01, -4.2610e-01,  5.5189e-01,\n",
      "        -6.1663e-02, -5.8012e-01, -2.6222e-01,  2.5948e-02,  9.6609e-03,\n",
      "         8.3412e-03, -4.3567e-03,  3.0890e-03, -1.9770e-03,  1.3453e-03,\n",
      "        -8.1374e-04, -6.0862e-25], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n",
      "batch: 35 parte real\n",
      " tensor([ 1.7925e-17,  4.7128e-06,  1.3347e-04, -1.5362e-03,  3.2313e-03,\n",
      "         9.4776e-03,  2.1046e-02,  1.1910e-01, -2.1092e-01,  1.9567e-02,\n",
      "         1.9560e-01, -2.2474e-01, -1.0376e-01,  3.2779e-01, -6.7050e-02,\n",
      "         9.0425e-02,  5.2386e-01, -2.5192e-01, -2.5004e-02, -1.8624e-01,\n",
      "         2.4053e-01, -1.0625e-01,  3.4021e-01,  1.3547e+00,  1.1524e-01,\n",
      "         2.1884e-01,  9.5688e-03,  7.7862e-03, -5.1987e-03, -3.5590e-03,\n",
      "         1.5769e-03,  2.4413e-12], dtype=torch.float64)\n",
      "batch: 35pparte imag\n",
      " tensor([-3.7046e-17,  2.5503e-04, -1.0782e-03,  1.7941e-03, -2.7620e-03,\n",
      "         2.3631e-02,  9.9190e-02,  1.2168e-01, -1.8570e-01, -1.0124e-01,\n",
      "         1.2096e-01, -1.2148e-01, -2.7466e-01, -1.3375e-01,  1.8028e-01,\n",
      "         2.0659e-02, -5.2892e-01, -3.3220e-01,  2.2781e-02,  1.9055e-01,\n",
      "        -1.0955e-01, -1.2338e-01, -6.5153e-02, -3.3942e-01, -1.3039e+00,\n",
      "        -4.8125e-01, -1.4921e-02, -3.8466e-03, -5.1877e-02, -1.2596e-02,\n",
      "        -2.3415e-03, -1.7091e-12], dtype=torch.float64)\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        print(f\"batch: {i} parte real\\n {X[i,0:32]}\")\n",
    "        print(f\"batch: {i}pparte imag\\n {X[i,32:64]}\")\n",
    "        print(\"-------------------------------------------\\n\")\n",
    "        \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e215102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choose a random data\n",
    "for X, y in train_loader:\n",
    "    \n",
    "    X_real_vis = X[0,0:32]\n",
    "    X_imag_vis = X[0,32:64]\n",
    "    X_pot_vis = X[0,64:96]\n",
    "    \n",
    "    y_real_vis = y[0,0:32]\n",
    "    y_imag_vis = y[0,32:64]\n",
    "    break\n",
    "    \n",
    "X_real_vis = X_real_vis.numpy()\n",
    "y_real_vis = y_real_vis.numpy()\n",
    "pot = X_pot_vis.numpy()\n",
    "    \n",
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(r\"$\\Psi(r,t)$\")\n",
    "ax.set_xlabel('Position ($\\AA$)')\n",
    "ax.set_ylabel('$\\Psi(r,t)$')\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "ax.plot(r_n, X_real_vis*100, label=\"$\\Psi_{real}(r, t=0)_{generate}$\")  #Escaled\n",
    "ax.plot(r_n, y_real_vis*100, label=\"$\\Psi_{real}(r, t=1)_{generate}$\")  # Escaled\n",
    "ax.plot(r_n, pot*(1/1.5936e-3), label=\"$V(r, t=0)_{generate}$\")  # kcal/mol\n",
    "\n",
    "ax.legend()\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1fea7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_overlap_prueba(Psi_true, Psi_ANN):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Psi_true: Evolution of wavepacket from dataset test\n",
    "    Psi_ANN: Evolution of wavepacket predicted with the model\n",
    "    \n",
    "    Output:\n",
    "    S: Absolute magnitude\n",
    "    angle: phase\n",
    "    Characterizes the quality of the predictions. See equation (11) of Main article\n",
    "    \n",
    "    \"\"\"\n",
    "    S_tot = []\n",
    "    angle_tot = []\n",
    "    for j in range(batch_size):\n",
    "        Psi_true_re = Psi_true[j,0:32]  # real part of wavepacket\n",
    "        Psi_true_im = Psi_true[j,32:64]  # imaginary part of wavepacket\n",
    "        Psi_t = torch.view_as_complex(torch.stack((Psi_true_re,Psi_true_im), -1))\n",
    "    \n",
    "    \n",
    "        Psi_ANN_re = Psi_ANN[j,0:32]  # realpart of wavepacket predicted\n",
    "        Psi_ANN_im = -Psi_ANN[j,32:64]  # imaginary part of wavepacket predicted (- because conjugate)\n",
    "        Psi_A = torch.view_as_complex(torch.stack((Psi_ANN_re,Psi_ANN_im), -1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        overlap = []\n",
    "        for i in range(32):\n",
    "            overlap.append(torch.tensor([Psi_A[i]*Psi_t[i]]))\n",
    "        overl = torch.tensor(overlap)\n",
    "        \n",
    "        # Integrate over r (real integral + complex integral)\n",
    "        # Simpson method in the grid r_n (angstroms -> au)\n",
    "        r_n = np.linspace(-1.5,1.5,32)*(1/0.5291775)\n",
    "        overl_real = overl.real.numpy()\n",
    "        overl_imag = overl.imag.numpy()\n",
    "    \n",
    "        real_integ = integrate.simpson(overl_real, r_n)\n",
    "        imag_integ = integrate.simpson(overl_imag, r_n)\n",
    "    \n",
    "        # Covert to phase and magnitude of the complex result\n",
    "        S_tot.append(np.sqrt(real_integ**2 + imag_integ**2))\n",
    "        angle_tot.append(np.arctan(imag_integ/real_integ))\n",
    "        \n",
    "    S = sum(S_tot)/batch_size\n",
    "    angle = sum(angle_tot)/batch_size\n",
    "    \n",
    "    return S, angle\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159ecc5",
   "metadata": {},
   "source": [
    "## Test of accuracy function\n",
    "Two same vectors should give S=1 & and angle=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e0ac565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "6.961061822446732e-19\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    S, angle = S_overlap_prueba(y,y)\n",
    "    print(S)\n",
    "    print(angle)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8fe7907c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size1 = len(test_loader.dataset)  # total of data ?\n",
    "size1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4e350dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches1 = len(test_loader)  # 1650*12=19800 that is the total of samples in test data and 12 is the baths size\n",
    "num_batches1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "15c76ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test over test loader\n",
    "correct1 = 0\n",
    "for X, y in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "    X, y = X.to(device), y.to(device)\n",
    "    S, angle = S_overlap(y, y)  # Accuracy by equation (11) Main Article       \n",
    "    correct1 += S\n",
    "correct1 /= num_batches1\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct1):>0.1f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a19889",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df0ec11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=96, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): ReLU()\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=1024, out_features=64, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(96, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 64)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a8da7064",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('./runs/MLP')  # To use tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224fd17f",
   "metadata": {},
   "source": [
    "## Loss function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2ac9b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b66ab8",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aff93280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_overlap(Psi_true, Psi_ANN):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Psi_true: Evolution of wavepacket from dataset test\n",
    "    Psi_ANN: Evolution of wavepacket predicted with the model\n",
    "    \n",
    "    Output:\n",
    "    S: Absolute magnitude\n",
    "    angle: phase\n",
    "    Characterizes the quality of the predictions. See equation (11) of Main article\n",
    "    \n",
    "    \"\"\"\n",
    "    S_tot = []\n",
    "    angle_tot = []\n",
    "    for j in range(batch_size):\n",
    "        Psi_true_re = Psi_true[j,0:32]  # real part of wavepacket\n",
    "        Psi_true_im = Psi_true[j,32:64]  # imaginary part of wavepacket\n",
    "        Psi_t = torch.view_as_complex(torch.stack((Psi_true_re,Psi_true_im), -1))\n",
    "    \n",
    "    \n",
    "        Psi_ANN_re = Psi_ANN[j,0:32]  # realpart of wavepacket predicted\n",
    "        Psi_ANN_im = -Psi_ANN[j,32:64]  # imaginary part of wavepacket predicted (- because conjugate)\n",
    "        Psi_A = torch.view_as_complex(torch.stack((Psi_ANN_re,Psi_ANN_im), -1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        overlap = []\n",
    "        for i in range(32):\n",
    "            overlap.append(torch.tensor([Psi_A[i]*Psi_t[i]]))\n",
    "        overl = torch.tensor(overlap)\n",
    "        \n",
    "        # Integrate over r (real integral + complex integral)\n",
    "        # Simpson method in the grid r_n (angstroms -> au)\n",
    "        r_n = np.linspace(-1.5,1.5,32)*(1/0.5291775)\n",
    "        overl_real = overl.real.numpy()\n",
    "        overl_imag = overl.imag.numpy()\n",
    "    \n",
    "        real_integ = integrate.simpson(overl_real, r_n)\n",
    "        imag_integ = integrate.simpson(overl_imag, r_n)\n",
    "    \n",
    "        # Covert to phase and magnitude of the complex result\n",
    "        S_tot.append(np.sqrt(real_integ**2 + imag_integ**2))\n",
    "        angle_tot.append(np.arctan(imag_integ/real_integ))\n",
    "        \n",
    "    S = sum(S_tot)/batch_size\n",
    "    angle = sum(angle_tot)/batch_size\n",
    "    \n",
    "    return S, angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5616881b",
   "metadata": {},
   "source": [
    "## Train & Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c27efc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float())\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        writer.add_scalar(\"Loss/train\", loss, epoch)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8fa3a4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y, pred)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    test_loss /= num_batches\n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "    writer.add_scalar('Accuracy Magnitude |S| /test', 100*correctS, epoch)  # Should be 100%\n",
    "    writer.add_scalar('Accuracy phase /test', correct_phase, epoch)  # Should be 0\n",
    "    \n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b7e04cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.094486  [    0/198000]\n",
      "loss: 0.090735  [ 3600/198000]\n",
      "loss: 0.091231  [ 7200/198000]\n",
      "loss: 0.091337  [10800/198000]\n",
      "loss: 0.092434  [14400/198000]\n",
      "loss: 0.090690  [18000/198000]\n",
      "loss: 0.091440  [21600/198000]\n",
      "loss: 0.090838  [25200/198000]\n",
      "loss: 0.091766  [28800/198000]\n",
      "loss: 0.091763  [32400/198000]\n",
      "loss: 0.091588  [36000/198000]\n",
      "loss: 0.090273  [39600/198000]\n",
      "loss: 0.090162  [43200/198000]\n",
      "loss: 0.091533  [46800/198000]\n",
      "loss: 0.090158  [50400/198000]\n",
      "loss: 0.090819  [54000/198000]\n",
      "loss: 0.092715  [57600/198000]\n",
      "loss: 0.091178  [61200/198000]\n",
      "loss: 0.091019  [64800/198000]\n",
      "loss: 0.090561  [68400/198000]\n",
      "loss: 0.090502  [72000/198000]\n",
      "loss: 0.091417  [75600/198000]\n",
      "loss: 0.092097  [79200/198000]\n",
      "loss: 0.091528  [82800/198000]\n",
      "loss: 0.090031  [86400/198000]\n",
      "loss: 0.091595  [90000/198000]\n",
      "loss: 0.090371  [93600/198000]\n",
      "loss: 0.091675  [97200/198000]\n",
      "loss: 0.091362  [100800/198000]\n",
      "loss: 0.090338  [104400/198000]\n",
      "loss: 0.090112  [108000/198000]\n",
      "loss: 0.090608  [111600/198000]\n",
      "loss: 0.092569  [115200/198000]\n",
      "loss: 0.089297  [118800/198000]\n",
      "loss: 0.089846  [122400/198000]\n",
      "loss: 0.090868  [126000/198000]\n",
      "loss: 0.089446  [129600/198000]\n",
      "loss: 0.090387  [133200/198000]\n",
      "loss: 0.089551  [136800/198000]\n",
      "loss: 0.089624  [140400/198000]\n",
      "loss: 0.089674  [144000/198000]\n",
      "loss: 0.091024  [147600/198000]\n",
      "loss: 0.089535  [151200/198000]\n",
      "loss: 0.091719  [154800/198000]\n",
      "loss: 0.091230  [158400/198000]\n",
      "loss: 0.090330  [162000/198000]\n",
      "loss: 0.090866  [165600/198000]\n",
      "loss: 0.089975  [169200/198000]\n",
      "loss: 0.091310  [172800/198000]\n",
      "loss: 0.089651  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.8%\n",
      "Test Error: \n",
      " Accuracy phase: 0.0%\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.091453  [    0/198000]\n",
      "loss: 0.090159  [ 3600/198000]\n",
      "loss: 0.089240  [ 7200/198000]\n",
      "loss: 0.089872  [10800/198000]\n",
      "loss: 0.090586  [14400/198000]\n",
      "loss: 0.089522  [18000/198000]\n",
      "loss: 0.088848  [21600/198000]\n",
      "loss: 0.090406  [25200/198000]\n",
      "loss: 0.090242  [28800/198000]\n",
      "loss: 0.088747  [32400/198000]\n",
      "loss: 0.090373  [36000/198000]\n",
      "loss: 0.091097  [39600/198000]\n",
      "loss: 0.090237  [43200/198000]\n",
      "loss: 0.089533  [46800/198000]\n",
      "loss: 0.087713  [50400/198000]\n",
      "loss: 0.090495  [54000/198000]\n",
      "loss: 0.089972  [57600/198000]\n",
      "loss: 0.088428  [61200/198000]\n",
      "loss: 0.089431  [64800/198000]\n",
      "loss: 0.091545  [68400/198000]\n",
      "loss: 0.088311  [72000/198000]\n",
      "loss: 0.088792  [75600/198000]\n",
      "loss: 0.089743  [79200/198000]\n",
      "loss: 0.090408  [82800/198000]\n",
      "loss: 0.090003  [86400/198000]\n",
      "loss: 0.089003  [90000/198000]\n",
      "loss: 0.090192  [93600/198000]\n",
      "loss: 0.088270  [97200/198000]\n",
      "loss: 0.089128  [100800/198000]\n",
      "loss: 0.089454  [104400/198000]\n",
      "loss: 0.087356  [108000/198000]\n",
      "loss: 0.089168  [111600/198000]\n",
      "loss: 0.090578  [115200/198000]\n",
      "loss: 0.088963  [118800/198000]\n",
      "loss: 0.089275  [122400/198000]\n",
      "loss: 0.089079  [126000/198000]\n",
      "loss: 0.089026  [129600/198000]\n",
      "loss: 0.088553  [133200/198000]\n",
      "loss: 0.090151  [136800/198000]\n",
      "loss: 0.089167  [140400/198000]\n",
      "loss: 0.089479  [144000/198000]\n",
      "loss: 0.087243  [147600/198000]\n",
      "loss: 0.089952  [151200/198000]\n",
      "loss: 0.088146  [154800/198000]\n",
      "loss: 0.089347  [158400/198000]\n",
      "loss: 0.089094  [162000/198000]\n",
      "loss: 0.088461  [165600/198000]\n",
      "loss: 0.089006  [169200/198000]\n",
      "loss: 0.088828  [172800/198000]\n",
      "loss: 0.088754  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.089681  [    0/198000]\n",
      "loss: 0.089075  [ 3600/198000]\n",
      "loss: 0.088520  [ 7200/198000]\n",
      "loss: 0.088746  [10800/198000]\n",
      "loss: 0.090106  [14400/198000]\n",
      "loss: 0.089031  [18000/198000]\n",
      "loss: 0.088787  [21600/198000]\n",
      "loss: 0.089509  [25200/198000]\n",
      "loss: 0.089599  [28800/198000]\n",
      "loss: 0.088523  [32400/198000]\n",
      "loss: 0.089051  [36000/198000]\n",
      "loss: 0.088594  [39600/198000]\n",
      "loss: 0.089626  [43200/198000]\n",
      "loss: 0.088929  [46800/198000]\n",
      "loss: 0.089988  [50400/198000]\n",
      "loss: 0.088011  [54000/198000]\n",
      "loss: 0.089421  [57600/198000]\n",
      "loss: 0.088352  [61200/198000]\n",
      "loss: 0.088569  [64800/198000]\n",
      "loss: 0.089514  [68400/198000]\n",
      "loss: 0.087933  [72000/198000]\n",
      "loss: 0.090095  [75600/198000]\n",
      "loss: 0.088868  [79200/198000]\n",
      "loss: 0.088339  [82800/198000]\n",
      "loss: 0.089249  [86400/198000]\n",
      "loss: 0.087957  [90000/198000]\n",
      "loss: 0.087988  [93600/198000]\n",
      "loss: 0.087993  [97200/198000]\n",
      "loss: 0.089387  [100800/198000]\n",
      "loss: 0.087725  [104400/198000]\n",
      "loss: 0.088111  [108000/198000]\n",
      "loss: 0.089212  [111600/198000]\n",
      "loss: 0.088254  [115200/198000]\n",
      "loss: 0.087089  [118800/198000]\n",
      "loss: 0.088419  [122400/198000]\n",
      "loss: 0.088058  [126000/198000]\n",
      "loss: 0.087230  [129600/198000]\n",
      "loss: 0.088424  [133200/198000]\n",
      "loss: 0.090901  [136800/198000]\n",
      "loss: 0.087126  [140400/198000]\n",
      "loss: 0.088545  [144000/198000]\n",
      "loss: 0.089665  [147600/198000]\n",
      "loss: 0.089419  [151200/198000]\n",
      "loss: 0.089500  [154800/198000]\n",
      "loss: 0.087058  [158400/198000]\n",
      "loss: 0.087835  [162000/198000]\n",
      "loss: 0.087651  [165600/198000]\n",
      "loss: 0.088067  [169200/198000]\n",
      "loss: 0.088947  [172800/198000]\n",
      "loss: 0.088724  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.088950  [    0/198000]\n",
      "loss: 0.088510  [ 3600/198000]\n",
      "loss: 0.088556  [ 7200/198000]\n",
      "loss: 0.088438  [10800/198000]\n",
      "loss: 0.088624  [14400/198000]\n",
      "loss: 0.087574  [18000/198000]\n",
      "loss: 0.088283  [21600/198000]\n",
      "loss: 0.089034  [25200/198000]\n",
      "loss: 0.089031  [28800/198000]\n",
      "loss: 0.088746  [32400/198000]\n",
      "loss: 0.087907  [36000/198000]\n",
      "loss: 0.087880  [39600/198000]\n",
      "loss: 0.088951  [43200/198000]\n",
      "loss: 0.088300  [46800/198000]\n",
      "loss: 0.089891  [50400/198000]\n",
      "loss: 0.089023  [54000/198000]\n",
      "loss: 0.088034  [57600/198000]\n",
      "loss: 0.087031  [61200/198000]\n",
      "loss: 0.088319  [64800/198000]\n",
      "loss: 0.087619  [68400/198000]\n",
      "loss: 0.087308  [72000/198000]\n",
      "loss: 0.087469  [75600/198000]\n",
      "loss: 0.088936  [79200/198000]\n",
      "loss: 0.087739  [82800/198000]\n",
      "loss: 0.088043  [86400/198000]\n",
      "loss: 0.088522  [90000/198000]\n",
      "loss: 0.089278  [93600/198000]\n",
      "loss: 0.086492  [97200/198000]\n",
      "loss: 0.087044  [100800/198000]\n",
      "loss: 0.089479  [104400/198000]\n",
      "loss: 0.088614  [108000/198000]\n",
      "loss: 0.088413  [111600/198000]\n",
      "loss: 0.088255  [115200/198000]\n",
      "loss: 0.087865  [118800/198000]\n",
      "loss: 0.088420  [122400/198000]\n",
      "loss: 0.087635  [126000/198000]\n",
      "loss: 0.086920  [129600/198000]\n",
      "loss: 0.088605  [133200/198000]\n",
      "loss: 0.087633  [136800/198000]\n",
      "loss: 0.087766  [140400/198000]\n",
      "loss: 0.088378  [144000/198000]\n",
      "loss: 0.088010  [147600/198000]\n",
      "loss: 0.087986  [151200/198000]\n",
      "loss: 0.086717  [154800/198000]\n",
      "loss: 0.088077  [158400/198000]\n",
      "loss: 0.086113  [162000/198000]\n",
      "loss: 0.086095  [165600/198000]\n",
      "loss: 0.087609  [169200/198000]\n",
      "loss: 0.088589  [172800/198000]\n",
      "loss: 0.088041  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.087502  [    0/198000]\n",
      "loss: 0.089656  [ 3600/198000]\n",
      "loss: 0.087310  [ 7200/198000]\n",
      "loss: 0.087848  [10800/198000]\n",
      "loss: 0.086883  [14400/198000]\n",
      "loss: 0.087282  [18000/198000]\n",
      "loss: 0.086522  [21600/198000]\n",
      "loss: 0.087372  [25200/198000]\n",
      "loss: 0.087678  [28800/198000]\n",
      "loss: 0.088504  [32400/198000]\n",
      "loss: 0.086948  [36000/198000]\n",
      "loss: 0.087290  [39600/198000]\n",
      "loss: 0.086593  [43200/198000]\n",
      "loss: 0.088488  [46800/198000]\n",
      "loss: 0.087841  [50400/198000]\n",
      "loss: 0.088116  [54000/198000]\n",
      "loss: 0.087399  [57600/198000]\n",
      "loss: 0.087476  [61200/198000]\n",
      "loss: 0.086902  [64800/198000]\n",
      "loss: 0.087343  [68400/198000]\n",
      "loss: 0.087471  [72000/198000]\n",
      "loss: 0.088322  [75600/198000]\n",
      "loss: 0.087361  [79200/198000]\n",
      "loss: 0.086987  [82800/198000]\n",
      "loss: 0.088713  [86400/198000]\n",
      "loss: 0.088026  [90000/198000]\n",
      "loss: 0.087973  [93600/198000]\n",
      "loss: 0.087963  [97200/198000]\n",
      "loss: 0.085441  [100800/198000]\n",
      "loss: 0.086462  [104400/198000]\n",
      "loss: 0.088689  [108000/198000]\n",
      "loss: 0.086458  [111600/198000]\n",
      "loss: 0.087547  [115200/198000]\n",
      "loss: 0.086795  [118800/198000]\n",
      "loss: 0.088012  [122400/198000]\n",
      "loss: 0.087303  [126000/198000]\n",
      "loss: 0.086384  [129600/198000]\n",
      "loss: 0.087284  [133200/198000]\n",
      "loss: 0.086782  [136800/198000]\n",
      "loss: 0.087355  [140400/198000]\n",
      "loss: 0.087153  [144000/198000]\n",
      "loss: 0.087296  [147600/198000]\n",
      "loss: 0.088569  [151200/198000]\n",
      "loss: 0.086615  [154800/198000]\n",
      "loss: 0.088029  [158400/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.087325  [162000/198000]\n",
      "loss: 0.087409  [165600/198000]\n",
      "loss: 0.087500  [169200/198000]\n",
      "loss: 0.087043  [172800/198000]\n",
      "loss: 0.087175  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.087274  [    0/198000]\n",
      "loss: 0.086447  [ 3600/198000]\n",
      "loss: 0.086038  [ 7200/198000]\n",
      "loss: 0.087117  [10800/198000]\n",
      "loss: 0.087130  [14400/198000]\n",
      "loss: 0.087757  [18000/198000]\n",
      "loss: 0.087418  [21600/198000]\n",
      "loss: 0.088109  [25200/198000]\n",
      "loss: 0.087363  [28800/198000]\n",
      "loss: 0.088377  [32400/198000]\n",
      "loss: 0.087299  [36000/198000]\n",
      "loss: 0.086767  [39600/198000]\n",
      "loss: 0.087305  [43200/198000]\n",
      "loss: 0.088148  [46800/198000]\n",
      "loss: 0.087183  [50400/198000]\n",
      "loss: 0.087290  [54000/198000]\n",
      "loss: 0.086644  [57600/198000]\n",
      "loss: 0.086163  [61200/198000]\n",
      "loss: 0.087713  [64800/198000]\n",
      "loss: 0.086711  [68400/198000]\n",
      "loss: 0.085961  [72000/198000]\n",
      "loss: 0.087250  [75600/198000]\n",
      "loss: 0.085629  [79200/198000]\n",
      "loss: 0.086253  [82800/198000]\n",
      "loss: 0.086794  [86400/198000]\n",
      "loss: 0.088220  [90000/198000]\n",
      "loss: 0.086511  [93600/198000]\n",
      "loss: 0.086468  [97200/198000]\n",
      "loss: 0.086776  [100800/198000]\n",
      "loss: 0.086684  [104400/198000]\n",
      "loss: 0.085322  [108000/198000]\n",
      "loss: 0.087134  [111600/198000]\n",
      "loss: 0.087671  [115200/198000]\n",
      "loss: 0.086157  [118800/198000]\n",
      "loss: 0.084210  [122400/198000]\n",
      "loss: 0.085720  [126000/198000]\n",
      "loss: 0.085548  [129600/198000]\n",
      "loss: 0.088025  [133200/198000]\n",
      "loss: 0.087639  [136800/198000]\n",
      "loss: 0.085639  [140400/198000]\n",
      "loss: 0.086125  [144000/198000]\n",
      "loss: 0.086289  [147600/198000]\n",
      "loss: 0.085857  [151200/198000]\n",
      "loss: 0.086146  [154800/198000]\n",
      "loss: 0.088230  [158400/198000]\n",
      "loss: 0.086800  [162000/198000]\n",
      "loss: 0.087403  [165600/198000]\n",
      "loss: 0.086859  [169200/198000]\n",
      "loss: 0.086337  [172800/198000]\n",
      "loss: 0.087672  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.085692  [    0/198000]\n",
      "loss: 0.086596  [ 3600/198000]\n",
      "loss: 0.087252  [ 7200/198000]\n",
      "loss: 0.084637  [10800/198000]\n",
      "loss: 0.085934  [14400/198000]\n",
      "loss: 0.085902  [18000/198000]\n",
      "loss: 0.084841  [21600/198000]\n",
      "loss: 0.086873  [25200/198000]\n",
      "loss: 0.085833  [28800/198000]\n",
      "loss: 0.088176  [32400/198000]\n",
      "loss: 0.085870  [36000/198000]\n",
      "loss: 0.087125  [39600/198000]\n",
      "loss: 0.087945  [43200/198000]\n",
      "loss: 0.085769  [46800/198000]\n",
      "loss: 0.086010  [50400/198000]\n",
      "loss: 0.085626  [54000/198000]\n",
      "loss: 0.086014  [57600/198000]\n",
      "loss: 0.085666  [61200/198000]\n",
      "loss: 0.087321  [64800/198000]\n",
      "loss: 0.087254  [68400/198000]\n",
      "loss: 0.087193  [72000/198000]\n",
      "loss: 0.087256  [75600/198000]\n",
      "loss: 0.085407  [79200/198000]\n",
      "loss: 0.086816  [82800/198000]\n",
      "loss: 0.085875  [86400/198000]\n",
      "loss: 0.085542  [90000/198000]\n",
      "loss: 0.086098  [93600/198000]\n",
      "loss: 0.085262  [97200/198000]\n",
      "loss: 0.088444  [100800/198000]\n",
      "loss: 0.087122  [104400/198000]\n",
      "loss: 0.086070  [108000/198000]\n",
      "loss: 0.085358  [111600/198000]\n",
      "loss: 0.086231  [115200/198000]\n",
      "loss: 0.086534  [118800/198000]\n",
      "loss: 0.086879  [122400/198000]\n",
      "loss: 0.086532  [126000/198000]\n",
      "loss: 0.086753  [129600/198000]\n",
      "loss: 0.087693  [133200/198000]\n",
      "loss: 0.085714  [136800/198000]\n",
      "loss: 0.087358  [140400/198000]\n",
      "loss: 0.087517  [144000/198000]\n",
      "loss: 0.086331  [147600/198000]\n",
      "loss: 0.084739  [151200/198000]\n",
      "loss: 0.085650  [154800/198000]\n",
      "loss: 0.085313  [158400/198000]\n",
      "loss: 0.088420  [162000/198000]\n",
      "loss: 0.086077  [165600/198000]\n",
      "loss: 0.086111  [169200/198000]\n",
      "loss: 0.086378  [172800/198000]\n",
      "loss: 0.086101  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.085699  [    0/198000]\n",
      "loss: 0.086128  [ 3600/198000]\n",
      "loss: 0.085854  [ 7200/198000]\n",
      "loss: 0.087297  [10800/198000]\n",
      "loss: 0.085472  [14400/198000]\n",
      "loss: 0.085843  [18000/198000]\n",
      "loss: 0.085218  [21600/198000]\n",
      "loss: 0.084901  [25200/198000]\n",
      "loss: 0.085885  [28800/198000]\n",
      "loss: 0.085975  [32400/198000]\n",
      "loss: 0.086880  [36000/198000]\n",
      "loss: 0.085457  [39600/198000]\n",
      "loss: 0.085445  [43200/198000]\n",
      "loss: 0.086089  [46800/198000]\n",
      "loss: 0.086263  [50400/198000]\n",
      "loss: 0.085739  [54000/198000]\n",
      "loss: 0.085006  [57600/198000]\n",
      "loss: 0.085741  [61200/198000]\n",
      "loss: 0.086159  [64800/198000]\n",
      "loss: 0.086042  [68400/198000]\n",
      "loss: 0.085101  [72000/198000]\n",
      "loss: 0.085942  [75600/198000]\n",
      "loss: 0.086068  [79200/198000]\n",
      "loss: 0.086114  [82800/198000]\n",
      "loss: 0.086365  [86400/198000]\n",
      "loss: 0.085859  [90000/198000]\n",
      "loss: 0.087550  [93600/198000]\n",
      "loss: 0.085994  [97200/198000]\n",
      "loss: 0.085909  [100800/198000]\n",
      "loss: 0.085592  [104400/198000]\n",
      "loss: 0.086651  [108000/198000]\n",
      "loss: 0.085793  [111600/198000]\n",
      "loss: 0.084981  [115200/198000]\n",
      "loss: 0.085038  [118800/198000]\n",
      "loss: 0.084116  [122400/198000]\n",
      "loss: 0.084396  [126000/198000]\n",
      "loss: 0.086092  [129600/198000]\n",
      "loss: 0.086849  [133200/198000]\n",
      "loss: 0.085955  [136800/198000]\n",
      "loss: 0.088403  [140400/198000]\n",
      "loss: 0.086723  [144000/198000]\n",
      "loss: 0.085619  [147600/198000]\n",
      "loss: 0.086079  [151200/198000]\n",
      "loss: 0.085579  [154800/198000]\n",
      "loss: 0.085939  [158400/198000]\n",
      "loss: 0.085530  [162000/198000]\n",
      "loss: 0.086390  [165600/198000]\n",
      "loss: 0.085542  [169200/198000]\n",
      "loss: 0.085309  [172800/198000]\n",
      "loss: 0.084580  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.7%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.084978  [    0/198000]\n",
      "loss: 0.085031  [ 3600/198000]\n",
      "loss: 0.086334  [ 7200/198000]\n",
      "loss: 0.084605  [10800/198000]\n",
      "loss: 0.085146  [14400/198000]\n",
      "loss: 0.084976  [18000/198000]\n",
      "loss: 0.085479  [21600/198000]\n",
      "loss: 0.085642  [25200/198000]\n",
      "loss: 0.084403  [28800/198000]\n",
      "loss: 0.086636  [32400/198000]\n",
      "loss: 0.086795  [36000/198000]\n",
      "loss: 0.086601  [39600/198000]\n",
      "loss: 0.085447  [43200/198000]\n",
      "loss: 0.087071  [46800/198000]\n",
      "loss: 0.085328  [50400/198000]\n",
      "loss: 0.086802  [54000/198000]\n",
      "loss: 0.085323  [57600/198000]\n",
      "loss: 0.085758  [61200/198000]\n",
      "loss: 0.086206  [64800/198000]\n",
      "loss: 0.086059  [68400/198000]\n",
      "loss: 0.086772  [72000/198000]\n",
      "loss: 0.085171  [75600/198000]\n",
      "loss: 0.084839  [79200/198000]\n",
      "loss: 0.086502  [82800/198000]\n",
      "loss: 0.085662  [86400/198000]\n",
      "loss: 0.085138  [90000/198000]\n",
      "loss: 0.087511  [93600/198000]\n",
      "loss: 0.085296  [97200/198000]\n",
      "loss: 0.083986  [100800/198000]\n",
      "loss: 0.084884  [104400/198000]\n",
      "loss: 0.085767  [108000/198000]\n",
      "loss: 0.085674  [111600/198000]\n",
      "loss: 0.085868  [115200/198000]\n",
      "loss: 0.085017  [118800/198000]\n",
      "loss: 0.084535  [122400/198000]\n",
      "loss: 0.086348  [126000/198000]\n",
      "loss: 0.084278  [129600/198000]\n",
      "loss: 0.087380  [133200/198000]\n",
      "loss: 0.085285  [136800/198000]\n",
      "loss: 0.085978  [140400/198000]\n",
      "loss: 0.085842  [144000/198000]\n",
      "loss: 0.084758  [147600/198000]\n",
      "loss: 0.085622  [151200/198000]\n",
      "loss: 0.087143  [154800/198000]\n",
      "loss: 0.085105  [158400/198000]\n",
      "loss: 0.085252  [162000/198000]\n",
      "loss: 0.086572  [165600/198000]\n",
      "loss: 0.084656  [169200/198000]\n",
      "loss: 0.084496  [172800/198000]\n",
      "loss: 0.085165  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 3.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.086097  [    0/198000]\n",
      "loss: 0.084865  [ 3600/198000]\n",
      "loss: 0.086127  [ 7200/198000]\n",
      "loss: 0.085372  [10800/198000]\n",
      "loss: 0.084089  [14400/198000]\n",
      "loss: 0.085701  [18000/198000]\n",
      "loss: 0.086605  [21600/198000]\n",
      "loss: 0.086964  [25200/198000]\n",
      "loss: 0.084876  [28800/198000]\n",
      "loss: 0.084599  [32400/198000]\n",
      "loss: 0.085238  [36000/198000]\n",
      "loss: 0.085424  [39600/198000]\n",
      "loss: 0.086888  [43200/198000]\n",
      "loss: 0.084425  [46800/198000]\n",
      "loss: 0.084973  [50400/198000]\n",
      "loss: 0.082731  [54000/198000]\n",
      "loss: 0.087065  [57600/198000]\n",
      "loss: 0.084958  [61200/198000]\n",
      "loss: 0.086287  [64800/198000]\n",
      "loss: 0.085404  [68400/198000]\n",
      "loss: 0.085758  [72000/198000]\n",
      "loss: 0.085144  [75600/198000]\n",
      "loss: 0.086134  [79200/198000]\n",
      "loss: 0.085291  [82800/198000]\n",
      "loss: 0.086204  [86400/198000]\n",
      "loss: 0.086540  [90000/198000]\n",
      "loss: 0.084169  [93600/198000]\n",
      "loss: 0.084887  [97200/198000]\n",
      "loss: 0.084041  [100800/198000]\n",
      "loss: 0.084471  [104400/198000]\n",
      "loss: 0.085082  [108000/198000]\n",
      "loss: 0.082750  [111600/198000]\n",
      "loss: 0.086214  [115200/198000]\n",
      "loss: 0.085752  [118800/198000]\n",
      "loss: 0.085140  [122400/198000]\n",
      "loss: 0.085249  [126000/198000]\n",
      "loss: 0.084165  [129600/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.085793  [133200/198000]\n",
      "loss: 0.084849  [136800/198000]\n",
      "loss: 0.085308  [140400/198000]\n",
      "loss: 0.084413  [144000/198000]\n",
      "loss: 0.084030  [147600/198000]\n",
      "loss: 0.085283  [151200/198000]\n",
      "loss: 0.085246  [154800/198000]\n",
      "loss: 0.086390  [158400/198000]\n",
      "loss: 0.083702  [162000/198000]\n",
      "loss: 0.085102  [165600/198000]\n",
      "loss: 0.085970  [169200/198000]\n",
      "loss: 0.085260  [172800/198000]\n",
      "loss: 0.085489  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.085248  [    0/198000]\n",
      "loss: 0.085761  [ 3600/198000]\n",
      "loss: 0.084017  [ 7200/198000]\n",
      "loss: 0.084645  [10800/198000]\n",
      "loss: 0.086834  [14400/198000]\n",
      "loss: 0.084509  [18000/198000]\n",
      "loss: 0.084525  [21600/198000]\n",
      "loss: 0.085178  [25200/198000]\n",
      "loss: 0.084378  [28800/198000]\n",
      "loss: 0.083800  [32400/198000]\n",
      "loss: 0.085658  [36000/198000]\n",
      "loss: 0.082395  [39600/198000]\n",
      "loss: 0.083928  [43200/198000]\n",
      "loss: 0.085914  [46800/198000]\n",
      "loss: 0.083364  [50400/198000]\n",
      "loss: 0.085371  [54000/198000]\n",
      "loss: 0.086753  [57600/198000]\n",
      "loss: 0.085316  [61200/198000]\n",
      "loss: 0.084718  [64800/198000]\n",
      "loss: 0.084115  [68400/198000]\n",
      "loss: 0.083056  [72000/198000]\n",
      "loss: 0.085695  [75600/198000]\n",
      "loss: 0.085814  [79200/198000]\n",
      "loss: 0.084166  [82800/198000]\n",
      "loss: 0.083650  [86400/198000]\n",
      "loss: 0.086781  [90000/198000]\n",
      "loss: 0.084388  [93600/198000]\n",
      "loss: 0.084980  [97200/198000]\n",
      "loss: 0.083992  [100800/198000]\n",
      "loss: 0.084858  [104400/198000]\n",
      "loss: 0.084032  [108000/198000]\n",
      "loss: 0.085598  [111600/198000]\n",
      "loss: 0.083437  [115200/198000]\n",
      "loss: 0.083229  [118800/198000]\n",
      "loss: 0.085411  [122400/198000]\n",
      "loss: 0.083238  [126000/198000]\n",
      "loss: 0.084084  [129600/198000]\n",
      "loss: 0.086089  [133200/198000]\n",
      "loss: 0.084947  [136800/198000]\n",
      "loss: 0.083395  [140400/198000]\n",
      "loss: 0.084163  [144000/198000]\n",
      "loss: 0.085101  [147600/198000]\n",
      "loss: 0.084972  [151200/198000]\n",
      "loss: 0.084218  [154800/198000]\n",
      "loss: 0.084399  [158400/198000]\n",
      "loss: 0.085472  [162000/198000]\n",
      "loss: 0.086098  [165600/198000]\n",
      "loss: 0.085829  [169200/198000]\n",
      "loss: 0.086077  [172800/198000]\n",
      "loss: 0.086376  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.084733  [    0/198000]\n",
      "loss: 0.084891  [ 3600/198000]\n",
      "loss: 0.083639  [ 7200/198000]\n",
      "loss: 0.084612  [10800/198000]\n",
      "loss: 0.085227  [14400/198000]\n",
      "loss: 0.083326  [18000/198000]\n",
      "loss: 0.085322  [21600/198000]\n",
      "loss: 0.085957  [25200/198000]\n",
      "loss: 0.084414  [28800/198000]\n",
      "loss: 0.086194  [32400/198000]\n",
      "loss: 0.084662  [36000/198000]\n",
      "loss: 0.085355  [39600/198000]\n",
      "loss: 0.084852  [43200/198000]\n",
      "loss: 0.083721  [46800/198000]\n",
      "loss: 0.081968  [50400/198000]\n",
      "loss: 0.083602  [54000/198000]\n",
      "loss: 0.085532  [57600/198000]\n",
      "loss: 0.085037  [61200/198000]\n",
      "loss: 0.086275  [64800/198000]\n",
      "loss: 0.084184  [68400/198000]\n",
      "loss: 0.086129  [72000/198000]\n",
      "loss: 0.082951  [75600/198000]\n",
      "loss: 0.084960  [79200/198000]\n",
      "loss: 0.083429  [82800/198000]\n",
      "loss: 0.084986  [86400/198000]\n",
      "loss: 0.083306  [90000/198000]\n",
      "loss: 0.083179  [93600/198000]\n",
      "loss: 0.084297  [97200/198000]\n",
      "loss: 0.085745  [100800/198000]\n",
      "loss: 0.083395  [104400/198000]\n",
      "loss: 0.084236  [108000/198000]\n",
      "loss: 0.084190  [111600/198000]\n",
      "loss: 0.083119  [115200/198000]\n",
      "loss: 0.084013  [118800/198000]\n",
      "loss: 0.085252  [122400/198000]\n",
      "loss: 0.085347  [126000/198000]\n",
      "loss: 0.084811  [129600/198000]\n",
      "loss: 0.084788  [133200/198000]\n",
      "loss: 0.083504  [136800/198000]\n",
      "loss: 0.084503  [140400/198000]\n",
      "loss: 0.086165  [144000/198000]\n",
      "loss: 0.083853  [147600/198000]\n",
      "loss: 0.083472  [151200/198000]\n",
      "loss: 0.084597  [154800/198000]\n",
      "loss: 0.085003  [158400/198000]\n",
      "loss: 0.084063  [162000/198000]\n",
      "loss: 0.084470  [165600/198000]\n",
      "loss: 0.082041  [169200/198000]\n",
      "loss: 0.084436  [172800/198000]\n",
      "loss: 0.084043  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.084911  [    0/198000]\n",
      "loss: 0.084648  [ 3600/198000]\n",
      "loss: 0.084029  [ 7200/198000]\n",
      "loss: 0.085799  [10800/198000]\n",
      "loss: 0.084664  [14400/198000]\n",
      "loss: 0.083795  [18000/198000]\n",
      "loss: 0.083716  [21600/198000]\n",
      "loss: 0.084871  [25200/198000]\n",
      "loss: 0.084884  [28800/198000]\n",
      "loss: 0.084103  [32400/198000]\n",
      "loss: 0.084787  [36000/198000]\n",
      "loss: 0.082738  [39600/198000]\n",
      "loss: 0.083904  [43200/198000]\n",
      "loss: 0.083781  [46800/198000]\n",
      "loss: 0.083574  [50400/198000]\n",
      "loss: 0.083777  [54000/198000]\n",
      "loss: 0.083712  [57600/198000]\n",
      "loss: 0.083381  [61200/198000]\n",
      "loss: 0.084484  [64800/198000]\n",
      "loss: 0.081790  [68400/198000]\n",
      "loss: 0.084922  [72000/198000]\n",
      "loss: 0.083748  [75600/198000]\n",
      "loss: 0.084315  [79200/198000]\n",
      "loss: 0.082207  [82800/198000]\n",
      "loss: 0.083224  [86400/198000]\n",
      "loss: 0.083662  [90000/198000]\n",
      "loss: 0.083746  [93600/198000]\n",
      "loss: 0.083354  [97200/198000]\n",
      "loss: 0.083932  [100800/198000]\n",
      "loss: 0.083862  [104400/198000]\n",
      "loss: 0.081584  [108000/198000]\n",
      "loss: 0.084886  [111600/198000]\n",
      "loss: 0.084666  [115200/198000]\n",
      "loss: 0.084607  [118800/198000]\n",
      "loss: 0.083870  [122400/198000]\n",
      "loss: 0.084652  [126000/198000]\n",
      "loss: 0.083953  [129600/198000]\n",
      "loss: 0.083631  [133200/198000]\n",
      "loss: 0.084685  [136800/198000]\n",
      "loss: 0.084681  [140400/198000]\n",
      "loss: 0.084854  [144000/198000]\n",
      "loss: 0.084709  [147600/198000]\n",
      "loss: 0.082943  [151200/198000]\n",
      "loss: 0.085191  [154800/198000]\n",
      "loss: 0.083213  [158400/198000]\n",
      "loss: 0.083465  [162000/198000]\n",
      "loss: 0.082923  [165600/198000]\n",
      "loss: 0.084717  [169200/198000]\n",
      "loss: 0.084910  [172800/198000]\n",
      "loss: 0.085120  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.084343  [    0/198000]\n",
      "loss: 0.083793  [ 3600/198000]\n",
      "loss: 0.084296  [ 7200/198000]\n",
      "loss: 0.083097  [10800/198000]\n",
      "loss: 0.083050  [14400/198000]\n",
      "loss: 0.084716  [18000/198000]\n",
      "loss: 0.085885  [21600/198000]\n",
      "loss: 0.084833  [25200/198000]\n",
      "loss: 0.085940  [28800/198000]\n",
      "loss: 0.084431  [32400/198000]\n",
      "loss: 0.082020  [36000/198000]\n",
      "loss: 0.083688  [39600/198000]\n",
      "loss: 0.080978  [43200/198000]\n",
      "loss: 0.083179  [46800/198000]\n",
      "loss: 0.084962  [50400/198000]\n",
      "loss: 0.083240  [54000/198000]\n",
      "loss: 0.084958  [57600/198000]\n",
      "loss: 0.083770  [61200/198000]\n",
      "loss: 0.084220  [64800/198000]\n",
      "loss: 0.084113  [68400/198000]\n",
      "loss: 0.084268  [72000/198000]\n",
      "loss: 0.083602  [75600/198000]\n",
      "loss: 0.085358  [79200/198000]\n",
      "loss: 0.084978  [82800/198000]\n",
      "loss: 0.082110  [86400/198000]\n",
      "loss: 0.085260  [90000/198000]\n",
      "loss: 0.083245  [93600/198000]\n",
      "loss: 0.083785  [97200/198000]\n",
      "loss: 0.083855  [100800/198000]\n",
      "loss: 0.082618  [104400/198000]\n",
      "loss: 0.085475  [108000/198000]\n",
      "loss: 0.083260  [111600/198000]\n",
      "loss: 0.083704  [115200/198000]\n",
      "loss: 0.084858  [118800/198000]\n",
      "loss: 0.082311  [122400/198000]\n",
      "loss: 0.083889  [126000/198000]\n",
      "loss: 0.081784  [129600/198000]\n",
      "loss: 0.084381  [133200/198000]\n",
      "loss: 0.083601  [136800/198000]\n",
      "loss: 0.083889  [140400/198000]\n",
      "loss: 0.083801  [144000/198000]\n",
      "loss: 0.083602  [147600/198000]\n",
      "loss: 0.084764  [151200/198000]\n",
      "loss: 0.082406  [154800/198000]\n",
      "loss: 0.082699  [158400/198000]\n",
      "loss: 0.082282  [162000/198000]\n",
      "loss: 0.083627  [165600/198000]\n",
      "loss: 0.083268  [169200/198000]\n",
      "loss: 0.083617  [172800/198000]\n",
      "loss: 0.083303  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.082757  [    0/198000]\n",
      "loss: 0.085712  [ 3600/198000]\n",
      "loss: 0.083998  [ 7200/198000]\n",
      "loss: 0.083413  [10800/198000]\n",
      "loss: 0.084979  [14400/198000]\n",
      "loss: 0.083097  [18000/198000]\n",
      "loss: 0.084581  [21600/198000]\n",
      "loss: 0.082276  [25200/198000]\n",
      "loss: 0.081895  [28800/198000]\n",
      "loss: 0.082972  [32400/198000]\n",
      "loss: 0.083697  [36000/198000]\n",
      "loss: 0.081918  [39600/198000]\n",
      "loss: 0.083952  [43200/198000]\n",
      "loss: 0.083551  [46800/198000]\n",
      "loss: 0.084945  [50400/198000]\n",
      "loss: 0.082634  [54000/198000]\n",
      "loss: 0.083373  [57600/198000]\n",
      "loss: 0.083975  [61200/198000]\n",
      "loss: 0.083789  [64800/198000]\n",
      "loss: 0.083480  [68400/198000]\n",
      "loss: 0.083548  [72000/198000]\n",
      "loss: 0.083705  [75600/198000]\n",
      "loss: 0.082442  [79200/198000]\n",
      "loss: 0.083162  [82800/198000]\n",
      "loss: 0.083984  [86400/198000]\n",
      "loss: 0.083418  [90000/198000]\n",
      "loss: 0.082584  [93600/198000]\n",
      "loss: 0.082968  [97200/198000]\n",
      "loss: 0.081621  [100800/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.084771  [104400/198000]\n",
      "loss: 0.082199  [108000/198000]\n",
      "loss: 0.083889  [111600/198000]\n",
      "loss: 0.083333  [115200/198000]\n",
      "loss: 0.083316  [118800/198000]\n",
      "loss: 0.082511  [122400/198000]\n",
      "loss: 0.084580  [126000/198000]\n",
      "loss: 0.082754  [129600/198000]\n",
      "loss: 0.082464  [133200/198000]\n",
      "loss: 0.084440  [136800/198000]\n",
      "loss: 0.083486  [140400/198000]\n",
      "loss: 0.084278  [144000/198000]\n",
      "loss: 0.084726  [147600/198000]\n",
      "loss: 0.084860  [151200/198000]\n",
      "loss: 0.082805  [154800/198000]\n",
      "loss: 0.082856  [158400/198000]\n",
      "loss: 0.084195  [162000/198000]\n",
      "loss: 0.082445  [165600/198000]\n",
      "loss: 0.083413  [169200/198000]\n",
      "loss: 0.083450  [172800/198000]\n",
      "loss: 0.083031  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 4.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.083864  [    0/198000]\n",
      "loss: 0.083855  [ 3600/198000]\n",
      "loss: 0.082188  [ 7200/198000]\n",
      "loss: 0.083936  [10800/198000]\n",
      "loss: 0.082856  [14400/198000]\n",
      "loss: 0.083800  [18000/198000]\n",
      "loss: 0.084635  [21600/198000]\n",
      "loss: 0.083149  [25200/198000]\n",
      "loss: 0.081264  [28800/198000]\n",
      "loss: 0.083285  [32400/198000]\n",
      "loss: 0.083072  [36000/198000]\n",
      "loss: 0.083588  [39600/198000]\n",
      "loss: 0.083154  [43200/198000]\n",
      "loss: 0.085005  [46800/198000]\n",
      "loss: 0.084425  [50400/198000]\n",
      "loss: 0.083296  [54000/198000]\n",
      "loss: 0.082933  [57600/198000]\n",
      "loss: 0.082310  [61200/198000]\n",
      "loss: 0.082180  [64800/198000]\n",
      "loss: 0.081671  [68400/198000]\n",
      "loss: 0.081437  [72000/198000]\n",
      "loss: 0.082837  [75600/198000]\n",
      "loss: 0.084211  [79200/198000]\n",
      "loss: 0.083406  [82800/198000]\n",
      "loss: 0.083590  [86400/198000]\n",
      "loss: 0.084792  [90000/198000]\n",
      "loss: 0.085367  [93600/198000]\n",
      "loss: 0.085189  [97200/198000]\n",
      "loss: 0.084117  [100800/198000]\n",
      "loss: 0.085640  [104400/198000]\n",
      "loss: 0.084560  [108000/198000]\n",
      "loss: 0.083564  [111600/198000]\n",
      "loss: 0.084042  [115200/198000]\n",
      "loss: 0.083416  [118800/198000]\n",
      "loss: 0.082152  [122400/198000]\n",
      "loss: 0.084737  [126000/198000]\n",
      "loss: 0.082146  [129600/198000]\n",
      "loss: 0.083092  [133200/198000]\n",
      "loss: 0.083744  [136800/198000]\n",
      "loss: 0.082015  [140400/198000]\n",
      "loss: 0.084069  [144000/198000]\n",
      "loss: 0.083114  [147600/198000]\n",
      "loss: 0.082483  [151200/198000]\n",
      "loss: 0.081488  [154800/198000]\n",
      "loss: 0.083892  [158400/198000]\n",
      "loss: 0.081290  [162000/198000]\n",
      "loss: 0.084171  [165600/198000]\n",
      "loss: 0.082279  [169200/198000]\n",
      "loss: 0.083857  [172800/198000]\n",
      "loss: 0.082581  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.083839  [    0/198000]\n",
      "loss: 0.082816  [ 3600/198000]\n",
      "loss: 0.082538  [ 7200/198000]\n",
      "loss: 0.083552  [10800/198000]\n",
      "loss: 0.084533  [14400/198000]\n",
      "loss: 0.082699  [18000/198000]\n",
      "loss: 0.083981  [21600/198000]\n",
      "loss: 0.083562  [25200/198000]\n",
      "loss: 0.084362  [28800/198000]\n",
      "loss: 0.083625  [32400/198000]\n",
      "loss: 0.082156  [36000/198000]\n",
      "loss: 0.082851  [39600/198000]\n",
      "loss: 0.084117  [43200/198000]\n",
      "loss: 0.082646  [46800/198000]\n",
      "loss: 0.081231  [50400/198000]\n",
      "loss: 0.083076  [54000/198000]\n",
      "loss: 0.083842  [57600/198000]\n",
      "loss: 0.085068  [61200/198000]\n",
      "loss: 0.083229  [64800/198000]\n",
      "loss: 0.082678  [68400/198000]\n",
      "loss: 0.082160  [72000/198000]\n",
      "loss: 0.084833  [75600/198000]\n",
      "loss: 0.081422  [79200/198000]\n",
      "loss: 0.081572  [82800/198000]\n",
      "loss: 0.082743  [86400/198000]\n",
      "loss: 0.083952  [90000/198000]\n",
      "loss: 0.082267  [93600/198000]\n",
      "loss: 0.082746  [97200/198000]\n",
      "loss: 0.081003  [100800/198000]\n",
      "loss: 0.084270  [104400/198000]\n",
      "loss: 0.081993  [108000/198000]\n",
      "loss: 0.083461  [111600/198000]\n",
      "loss: 0.083588  [115200/198000]\n",
      "loss: 0.082399  [118800/198000]\n",
      "loss: 0.084155  [122400/198000]\n",
      "loss: 0.083469  [126000/198000]\n",
      "loss: 0.083790  [129600/198000]\n",
      "loss: 0.081224  [133200/198000]\n",
      "loss: 0.082352  [136800/198000]\n",
      "loss: 0.082412  [140400/198000]\n",
      "loss: 0.082629  [144000/198000]\n",
      "loss: 0.081626  [147600/198000]\n",
      "loss: 0.082063  [151200/198000]\n",
      "loss: 0.082859  [154800/198000]\n",
      "loss: 0.081529  [158400/198000]\n",
      "loss: 0.082948  [162000/198000]\n",
      "loss: 0.082745  [165600/198000]\n",
      "loss: 0.083490  [169200/198000]\n",
      "loss: 0.082347  [172800/198000]\n",
      "loss: 0.080757  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.081030  [    0/198000]\n",
      "loss: 0.082828  [ 3600/198000]\n",
      "loss: 0.082648  [ 7200/198000]\n",
      "loss: 0.081708  [10800/198000]\n",
      "loss: 0.082032  [14400/198000]\n",
      "loss: 0.082798  [18000/198000]\n",
      "loss: 0.084370  [21600/198000]\n",
      "loss: 0.084566  [25200/198000]\n",
      "loss: 0.081027  [28800/198000]\n",
      "loss: 0.083420  [32400/198000]\n",
      "loss: 0.082015  [36000/198000]\n",
      "loss: 0.084959  [39600/198000]\n",
      "loss: 0.084225  [43200/198000]\n",
      "loss: 0.082910  [46800/198000]\n",
      "loss: 0.082565  [50400/198000]\n",
      "loss: 0.080703  [54000/198000]\n",
      "loss: 0.082658  [57600/198000]\n",
      "loss: 0.084543  [61200/198000]\n",
      "loss: 0.083601  [64800/198000]\n",
      "loss: 0.082819  [68400/198000]\n",
      "loss: 0.081414  [72000/198000]\n",
      "loss: 0.084297  [75600/198000]\n",
      "loss: 0.083633  [79200/198000]\n",
      "loss: 0.082381  [82800/198000]\n",
      "loss: 0.083510  [86400/198000]\n",
      "loss: 0.085577  [90000/198000]\n",
      "loss: 0.082696  [93600/198000]\n",
      "loss: 0.082258  [97200/198000]\n",
      "loss: 0.081761  [100800/198000]\n",
      "loss: 0.079865  [104400/198000]\n",
      "loss: 0.082932  [108000/198000]\n",
      "loss: 0.081200  [111600/198000]\n",
      "loss: 0.080841  [115200/198000]\n",
      "loss: 0.083516  [118800/198000]\n",
      "loss: 0.080874  [122400/198000]\n",
      "loss: 0.083488  [126000/198000]\n",
      "loss: 0.080424  [129600/198000]\n",
      "loss: 0.082065  [133200/198000]\n",
      "loss: 0.081324  [136800/198000]\n",
      "loss: 0.080697  [140400/198000]\n",
      "loss: 0.082429  [144000/198000]\n",
      "loss: 0.085026  [147600/198000]\n",
      "loss: 0.079818  [151200/198000]\n",
      "loss: 0.081547  [154800/198000]\n",
      "loss: 0.082030  [158400/198000]\n",
      "loss: 0.080552  [162000/198000]\n",
      "loss: 0.084546  [165600/198000]\n",
      "loss: 0.082288  [169200/198000]\n",
      "loss: 0.084330  [172800/198000]\n",
      "loss: 0.081618  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.083349  [    0/198000]\n",
      "loss: 0.082862  [ 3600/198000]\n",
      "loss: 0.083453  [ 7200/198000]\n",
      "loss: 0.080896  [10800/198000]\n",
      "loss: 0.081059  [14400/198000]\n",
      "loss: 0.080492  [18000/198000]\n",
      "loss: 0.082809  [21600/198000]\n",
      "loss: 0.082625  [25200/198000]\n",
      "loss: 0.083040  [28800/198000]\n",
      "loss: 0.082979  [32400/198000]\n",
      "loss: 0.083594  [36000/198000]\n",
      "loss: 0.080625  [39600/198000]\n",
      "loss: 0.082789  [43200/198000]\n",
      "loss: 0.082821  [46800/198000]\n",
      "loss: 0.082786  [50400/198000]\n",
      "loss: 0.081387  [54000/198000]\n",
      "loss: 0.081707  [57600/198000]\n",
      "loss: 0.080047  [61200/198000]\n",
      "loss: 0.082771  [64800/198000]\n",
      "loss: 0.080461  [68400/198000]\n",
      "loss: 0.082118  [72000/198000]\n",
      "loss: 0.082607  [75600/198000]\n",
      "loss: 0.082544  [79200/198000]\n",
      "loss: 0.084525  [82800/198000]\n",
      "loss: 0.080488  [86400/198000]\n",
      "loss: 0.084040  [90000/198000]\n",
      "loss: 0.082289  [93600/198000]\n",
      "loss: 0.083267  [97200/198000]\n",
      "loss: 0.082200  [100800/198000]\n",
      "loss: 0.084007  [104400/198000]\n",
      "loss: 0.081835  [108000/198000]\n",
      "loss: 0.081004  [111600/198000]\n",
      "loss: 0.081892  [115200/198000]\n",
      "loss: 0.080120  [118800/198000]\n",
      "loss: 0.085088  [122400/198000]\n",
      "loss: 0.081839  [126000/198000]\n",
      "loss: 0.083526  [129600/198000]\n",
      "loss: 0.083808  [133200/198000]\n",
      "loss: 0.081517  [136800/198000]\n",
      "loss: 0.083354  [140400/198000]\n",
      "loss: 0.082143  [144000/198000]\n",
      "loss: 0.080851  [147600/198000]\n",
      "loss: 0.083829  [151200/198000]\n",
      "loss: 0.083581  [154800/198000]\n",
      "loss: 0.080743  [158400/198000]\n",
      "loss: 0.080521  [162000/198000]\n",
      "loss: 0.083973  [165600/198000]\n",
      "loss: 0.080904  [169200/198000]\n",
      "loss: 0.082899  [172800/198000]\n",
      "loss: 0.081435  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.081807  [    0/198000]\n",
      "loss: 0.083308  [ 3600/198000]\n",
      "loss: 0.082974  [ 7200/198000]\n",
      "loss: 0.082241  [10800/198000]\n",
      "loss: 0.084455  [14400/198000]\n",
      "loss: 0.083635  [18000/198000]\n",
      "loss: 0.080869  [21600/198000]\n",
      "loss: 0.081452  [25200/198000]\n",
      "loss: 0.082612  [28800/198000]\n",
      "loss: 0.082284  [32400/198000]\n",
      "loss: 0.084430  [36000/198000]\n",
      "loss: 0.082613  [39600/198000]\n",
      "loss: 0.081091  [43200/198000]\n",
      "loss: 0.082275  [46800/198000]\n",
      "loss: 0.080417  [50400/198000]\n",
      "loss: 0.080878  [54000/198000]\n",
      "loss: 0.082248  [57600/198000]\n",
      "loss: 0.083218  [61200/198000]\n",
      "loss: 0.081603  [64800/198000]\n",
      "loss: 0.081712  [68400/198000]\n",
      "loss: 0.082625  [72000/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.081243  [75600/198000]\n",
      "loss: 0.080487  [79200/198000]\n",
      "loss: 0.081037  [82800/198000]\n",
      "loss: 0.081432  [86400/198000]\n",
      "loss: 0.082109  [90000/198000]\n",
      "loss: 0.081753  [93600/198000]\n",
      "loss: 0.082933  [97200/198000]\n",
      "loss: 0.082091  [100800/198000]\n",
      "loss: 0.082381  [104400/198000]\n",
      "loss: 0.083107  [108000/198000]\n",
      "loss: 0.082646  [111600/198000]\n",
      "loss: 0.081242  [115200/198000]\n",
      "loss: 0.079942  [118800/198000]\n",
      "loss: 0.081240  [122400/198000]\n",
      "loss: 0.079878  [126000/198000]\n",
      "loss: 0.081837  [129600/198000]\n",
      "loss: 0.083449  [133200/198000]\n",
      "loss: 0.082814  [136800/198000]\n",
      "loss: 0.084852  [140400/198000]\n",
      "loss: 0.082925  [144000/198000]\n",
      "loss: 0.082176  [147600/198000]\n",
      "loss: 0.082739  [151200/198000]\n",
      "loss: 0.083707  [154800/198000]\n",
      "loss: 0.082962  [158400/198000]\n",
      "loss: 0.082827  [162000/198000]\n",
      "loss: 0.079819  [165600/198000]\n",
      "loss: 0.081990  [169200/198000]\n",
      "loss: 0.080436  [172800/198000]\n",
      "loss: 0.081674  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 5.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.080894  [    0/198000]\n",
      "loss: 0.081620  [ 3600/198000]\n",
      "loss: 0.081486  [ 7200/198000]\n",
      "loss: 0.082183  [10800/198000]\n",
      "loss: 0.082054  [14400/198000]\n",
      "loss: 0.082750  [18000/198000]\n",
      "loss: 0.081432  [21600/198000]\n",
      "loss: 0.082564  [25200/198000]\n",
      "loss: 0.083296  [28800/198000]\n",
      "loss: 0.079254  [32400/198000]\n",
      "loss: 0.080181  [36000/198000]\n",
      "loss: 0.081923  [39600/198000]\n",
      "loss: 0.082952  [43200/198000]\n",
      "loss: 0.081717  [46800/198000]\n",
      "loss: 0.080442  [50400/198000]\n",
      "loss: 0.079181  [54000/198000]\n",
      "loss: 0.080942  [57600/198000]\n",
      "loss: 0.081534  [61200/198000]\n",
      "loss: 0.084114  [64800/198000]\n",
      "loss: 0.080997  [68400/198000]\n",
      "loss: 0.080105  [72000/198000]\n",
      "loss: 0.079713  [75600/198000]\n",
      "loss: 0.080313  [79200/198000]\n",
      "loss: 0.081799  [82800/198000]\n",
      "loss: 0.080783  [86400/198000]\n",
      "loss: 0.082633  [90000/198000]\n",
      "loss: 0.082530  [93600/198000]\n",
      "loss: 0.081419  [97200/198000]\n",
      "loss: 0.081528  [100800/198000]\n",
      "loss: 0.080964  [104400/198000]\n",
      "loss: 0.080316  [108000/198000]\n",
      "loss: 0.083541  [111600/198000]\n",
      "loss: 0.079722  [115200/198000]\n",
      "loss: 0.081932  [118800/198000]\n",
      "loss: 0.082437  [122400/198000]\n",
      "loss: 0.080360  [126000/198000]\n",
      "loss: 0.081923  [129600/198000]\n",
      "loss: 0.082389  [133200/198000]\n",
      "loss: 0.083054  [136800/198000]\n",
      "loss: 0.082548  [140400/198000]\n",
      "loss: 0.081688  [144000/198000]\n",
      "loss: 0.081205  [147600/198000]\n",
      "loss: 0.079357  [151200/198000]\n",
      "loss: 0.081187  [154800/198000]\n",
      "loss: 0.082779  [158400/198000]\n",
      "loss: 0.082488  [162000/198000]\n",
      "loss: 0.081808  [165600/198000]\n",
      "loss: 0.080352  [169200/198000]\n",
      "loss: 0.084139  [172800/198000]\n",
      "loss: 0.082768  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 6.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1%\n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.082525  [    0/198000]\n",
      "loss: 0.081298  [ 3600/198000]\n",
      "loss: 0.081225  [ 7200/198000]\n",
      "loss: 0.082929  [10800/198000]\n",
      "loss: 0.079377  [14400/198000]\n",
      "loss: 0.082068  [18000/198000]\n",
      "loss: 0.079394  [21600/198000]\n",
      "loss: 0.081331  [25200/198000]\n",
      "loss: 0.079661  [28800/198000]\n",
      "loss: 0.081425  [32400/198000]\n",
      "loss: 0.081747  [36000/198000]\n",
      "loss: 0.081717  [39600/198000]\n",
      "loss: 0.081217  [43200/198000]\n",
      "loss: 0.081112  [46800/198000]\n",
      "loss: 0.078981  [50400/198000]\n",
      "loss: 0.083713  [54000/198000]\n",
      "loss: 0.081485  [57600/198000]\n",
      "loss: 0.079100  [61200/198000]\n",
      "loss: 0.078851  [64800/198000]\n",
      "loss: 0.080651  [68400/198000]\n",
      "loss: 0.080106  [72000/198000]\n",
      "loss: 0.082527  [75600/198000]\n",
      "loss: 0.081339  [79200/198000]\n",
      "loss: 0.082094  [82800/198000]\n",
      "loss: 0.083897  [86400/198000]\n",
      "loss: 0.082201  [90000/198000]\n",
      "loss: 0.080361  [93600/198000]\n",
      "loss: 0.081151  [97200/198000]\n",
      "loss: 0.081504  [100800/198000]\n",
      "loss: 0.081135  [104400/198000]\n",
      "loss: 0.081484  [108000/198000]\n",
      "loss: 0.080578  [111600/198000]\n",
      "loss: 0.078781  [115200/198000]\n",
      "loss: 0.082029  [118800/198000]\n",
      "loss: 0.083576  [122400/198000]\n",
      "loss: 0.081416  [126000/198000]\n",
      "loss: 0.080260  [129600/198000]\n",
      "loss: 0.080660  [133200/198000]\n",
      "loss: 0.081283  [136800/198000]\n",
      "loss: 0.080577  [140400/198000]\n",
      "loss: 0.081451  [144000/198000]\n",
      "loss: 0.082038  [147600/198000]\n",
      "loss: 0.083597  [151200/198000]\n",
      "loss: 0.084265  [154800/198000]\n",
      "loss: 0.080789  [158400/198000]\n",
      "loss: 0.081706  [162000/198000]\n",
      "loss: 0.081466  [165600/198000]\n",
      "loss: 0.081940  [169200/198000]\n",
      "loss: 0.082180  [172800/198000]\n",
      "loss: 0.081425  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 6.2%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.078546  [    0/198000]\n",
      "loss: 0.082727  [ 3600/198000]\n",
      "loss: 0.082390  [ 7200/198000]\n",
      "loss: 0.086271  [10800/198000]\n",
      "loss: 0.078341  [14400/198000]\n",
      "loss: 0.081743  [18000/198000]\n",
      "loss: 0.081946  [21600/198000]\n",
      "loss: 0.082698  [25200/198000]\n",
      "loss: 0.079983  [28800/198000]\n",
      "loss: 0.079598  [32400/198000]\n",
      "loss: 0.080506  [36000/198000]\n",
      "loss: 0.082153  [39600/198000]\n",
      "loss: 0.084510  [43200/198000]\n",
      "loss: 0.082136  [46800/198000]\n",
      "loss: 0.080305  [50400/198000]\n",
      "loss: 0.080841  [54000/198000]\n",
      "loss: 0.078848  [57600/198000]\n",
      "loss: 0.080460  [61200/198000]\n",
      "loss: 0.078870  [64800/198000]\n",
      "loss: 0.079303  [68400/198000]\n",
      "loss: 0.080164  [72000/198000]\n",
      "loss: 0.082407  [75600/198000]\n",
      "loss: 0.080331  [79200/198000]\n",
      "loss: 0.080154  [82800/198000]\n",
      "loss: 0.080099  [86400/198000]\n",
      "loss: 0.082223  [90000/198000]\n",
      "loss: 0.080872  [93600/198000]\n",
      "loss: 0.080284  [97200/198000]\n",
      "loss: 0.081971  [100800/198000]\n",
      "loss: 0.080555  [104400/198000]\n",
      "loss: 0.079493  [108000/198000]\n",
      "loss: 0.082521  [111600/198000]\n",
      "loss: 0.081626  [115200/198000]\n",
      "loss: 0.081106  [118800/198000]\n",
      "loss: 0.081536  [122400/198000]\n",
      "loss: 0.083465  [126000/198000]\n",
      "loss: 0.080568  [129600/198000]\n",
      "loss: 0.080713  [133200/198000]\n",
      "loss: 0.078823  [136800/198000]\n",
      "loss: 0.079874  [140400/198000]\n",
      "loss: 0.080450  [144000/198000]\n",
      "loss: 0.077036  [147600/198000]\n",
      "loss: 0.082485  [151200/198000]\n",
      "loss: 0.082934  [154800/198000]\n",
      "loss: 0.079952  [158400/198000]\n",
      "loss: 0.082991  [162000/198000]\n",
      "loss: 0.082814  [165600/198000]\n",
      "loss: 0.081141  [169200/198000]\n",
      "loss: 0.083209  [172800/198000]\n",
      "loss: 0.082041  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 6.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.080920  [    0/198000]\n",
      "loss: 0.081567  [ 3600/198000]\n",
      "loss: 0.081403  [ 7200/198000]\n",
      "loss: 0.080988  [10800/198000]\n",
      "loss: 0.082108  [14400/198000]\n",
      "loss: 0.079990  [18000/198000]\n",
      "loss: 0.082457  [21600/198000]\n",
      "loss: 0.080990  [25200/198000]\n",
      "loss: 0.083626  [28800/198000]\n",
      "loss: 0.080935  [32400/198000]\n",
      "loss: 0.080139  [36000/198000]\n",
      "loss: 0.080026  [39600/198000]\n",
      "loss: 0.082814  [43200/198000]\n",
      "loss: 0.082715  [46800/198000]\n",
      "loss: 0.081838  [50400/198000]\n",
      "loss: 0.080734  [54000/198000]\n",
      "loss: 0.079548  [57600/198000]\n",
      "loss: 0.081346  [61200/198000]\n",
      "loss: 0.081473  [64800/198000]\n",
      "loss: 0.081306  [68400/198000]\n",
      "loss: 0.080273  [72000/198000]\n",
      "loss: 0.081629  [75600/198000]\n",
      "loss: 0.079826  [79200/198000]\n",
      "loss: 0.080039  [82800/198000]\n",
      "loss: 0.080282  [86400/198000]\n",
      "loss: 0.080710  [90000/198000]\n",
      "loss: 0.080870  [93600/198000]\n",
      "loss: 0.080031  [97200/198000]\n",
      "loss: 0.082228  [100800/198000]\n",
      "loss: 0.084121  [104400/198000]\n",
      "loss: 0.078990  [108000/198000]\n",
      "loss: 0.082684  [111600/198000]\n",
      "loss: 0.079570  [115200/198000]\n",
      "loss: 0.082809  [118800/198000]\n",
      "loss: 0.079536  [122400/198000]\n",
      "loss: 0.081088  [126000/198000]\n",
      "loss: 0.083088  [129600/198000]\n",
      "loss: 0.081668  [133200/198000]\n",
      "loss: 0.079214  [136800/198000]\n",
      "loss: 0.080585  [140400/198000]\n",
      "loss: 0.079567  [144000/198000]\n",
      "loss: 0.080388  [147600/198000]\n",
      "loss: 0.081417  [151200/198000]\n",
      "loss: 0.078904  [154800/198000]\n",
      "loss: 0.080216  [158400/198000]\n",
      "loss: 0.081890  [162000/198000]\n",
      "loss: 0.078728  [165600/198000]\n",
      "loss: 0.080862  [169200/198000]\n",
      "loss: 0.082491  [172800/198000]\n",
      "loss: 0.079084  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 6.6%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.081139  [    0/198000]\n",
      "loss: 0.081331  [ 3600/198000]\n",
      "loss: 0.081152  [ 7200/198000]\n",
      "loss: 0.082575  [10800/198000]\n",
      "loss: 0.083123  [14400/198000]\n",
      "loss: 0.080266  [18000/198000]\n",
      "loss: 0.081102  [21600/198000]\n",
      "loss: 0.082045  [25200/198000]\n",
      "loss: 0.081800  [28800/198000]\n",
      "loss: 0.081201  [32400/198000]\n",
      "loss: 0.080769  [36000/198000]\n",
      "loss: 0.078715  [39600/198000]\n",
      "loss: 0.079508  [43200/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.080444  [46800/198000]\n",
      "loss: 0.082286  [50400/198000]\n",
      "loss: 0.080783  [54000/198000]\n",
      "loss: 0.080452  [57600/198000]\n",
      "loss: 0.080381  [61200/198000]\n",
      "loss: 0.078468  [64800/198000]\n",
      "loss: 0.077305  [68400/198000]\n",
      "loss: 0.077976  [72000/198000]\n",
      "loss: 0.082104  [75600/198000]\n",
      "loss: 0.079496  [79200/198000]\n",
      "loss: 0.081780  [82800/198000]\n",
      "loss: 0.082248  [86400/198000]\n",
      "loss: 0.079794  [90000/198000]\n",
      "loss: 0.079070  [93600/198000]\n",
      "loss: 0.082341  [97200/198000]\n",
      "loss: 0.080839  [100800/198000]\n",
      "loss: 0.082889  [104400/198000]\n",
      "loss: 0.080052  [108000/198000]\n",
      "loss: 0.079495  [111600/198000]\n",
      "loss: 0.078624  [115200/198000]\n",
      "loss: 0.082109  [118800/198000]\n",
      "loss: 0.082376  [122400/198000]\n",
      "loss: 0.082521  [126000/198000]\n",
      "loss: 0.082061  [129600/198000]\n",
      "loss: 0.080923  [133200/198000]\n",
      "loss: 0.081498  [136800/198000]\n",
      "loss: 0.078628  [140400/198000]\n",
      "loss: 0.081268  [144000/198000]\n",
      "loss: 0.079356  [147600/198000]\n",
      "loss: 0.079937  [151200/198000]\n",
      "loss: 0.079708  [154800/198000]\n",
      "loss: 0.079862  [158400/198000]\n",
      "loss: 0.078641  [162000/198000]\n",
      "loss: 0.082870  [165600/198000]\n",
      "loss: 0.077306  [169200/198000]\n",
      "loss: 0.078917  [172800/198000]\n",
      "loss: 0.079145  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 6.8%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.080490  [    0/198000]\n",
      "loss: 0.081712  [ 3600/198000]\n",
      "loss: 0.080075  [ 7200/198000]\n",
      "loss: 0.082137  [10800/198000]\n",
      "loss: 0.080052  [14400/198000]\n",
      "loss: 0.082207  [18000/198000]\n",
      "loss: 0.080890  [21600/198000]\n",
      "loss: 0.080424  [25200/198000]\n",
      "loss: 0.080187  [28800/198000]\n",
      "loss: 0.081096  [32400/198000]\n",
      "loss: 0.080078  [36000/198000]\n",
      "loss: 0.081763  [39600/198000]\n",
      "loss: 0.080264  [43200/198000]\n",
      "loss: 0.082803  [46800/198000]\n",
      "loss: 0.081740  [50400/198000]\n",
      "loss: 0.082677  [54000/198000]\n",
      "loss: 0.080019  [57600/198000]\n",
      "loss: 0.081560  [61200/198000]\n",
      "loss: 0.079097  [64800/198000]\n",
      "loss: 0.079710  [68400/198000]\n",
      "loss: 0.080714  [72000/198000]\n",
      "loss: 0.079999  [75600/198000]\n",
      "loss: 0.084338  [79200/198000]\n",
      "loss: 0.081247  [82800/198000]\n",
      "loss: 0.079107  [86400/198000]\n",
      "loss: 0.079209  [90000/198000]\n",
      "loss: 0.081801  [93600/198000]\n",
      "loss: 0.078375  [97200/198000]\n",
      "loss: 0.077913  [100800/198000]\n",
      "loss: 0.078503  [104400/198000]\n",
      "loss: 0.081315  [108000/198000]\n",
      "loss: 0.082918  [111600/198000]\n",
      "loss: 0.082186  [115200/198000]\n",
      "loss: 0.079475  [118800/198000]\n",
      "loss: 0.080206  [122400/198000]\n",
      "loss: 0.078960  [126000/198000]\n",
      "loss: 0.080617  [129600/198000]\n",
      "loss: 0.077439  [133200/198000]\n",
      "loss: 0.079964  [136800/198000]\n",
      "loss: 0.078186  [140400/198000]\n",
      "loss: 0.081369  [144000/198000]\n",
      "loss: 0.081170  [147600/198000]\n",
      "loss: 0.077923  [151200/198000]\n",
      "loss: 0.080707  [154800/198000]\n",
      "loss: 0.080066  [158400/198000]\n",
      "loss: 0.081178  [162000/198000]\n",
      "loss: 0.081162  [165600/198000]\n",
      "loss: 0.083324  [169200/198000]\n",
      "loss: 0.079303  [172800/198000]\n",
      "loss: 0.079828  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 7.0%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.075201  [    0/198000]\n",
      "loss: 0.080274  [ 3600/198000]\n",
      "loss: 0.078611  [ 7200/198000]\n",
      "loss: 0.080975  [10800/198000]\n",
      "loss: 0.079058  [14400/198000]\n",
      "loss: 0.082231  [18000/198000]\n",
      "loss: 0.080415  [21600/198000]\n",
      "loss: 0.077915  [25200/198000]\n",
      "loss: 0.083004  [28800/198000]\n",
      "loss: 0.080626  [32400/198000]\n",
      "loss: 0.080880  [36000/198000]\n",
      "loss: 0.081222  [39600/198000]\n",
      "loss: 0.079089  [43200/198000]\n",
      "loss: 0.080415  [46800/198000]\n",
      "loss: 0.079561  [50400/198000]\n",
      "loss: 0.080182  [54000/198000]\n",
      "loss: 0.083246  [57600/198000]\n",
      "loss: 0.077412  [61200/198000]\n",
      "loss: 0.080546  [64800/198000]\n",
      "loss: 0.080837  [68400/198000]\n",
      "loss: 0.081306  [72000/198000]\n",
      "loss: 0.080149  [75600/198000]\n",
      "loss: 0.079444  [79200/198000]\n",
      "loss: 0.079488  [82800/198000]\n",
      "loss: 0.081452  [86400/198000]\n",
      "loss: 0.082164  [90000/198000]\n",
      "loss: 0.081049  [93600/198000]\n",
      "loss: 0.081106  [97200/198000]\n",
      "loss: 0.079212  [100800/198000]\n",
      "loss: 0.082294  [104400/198000]\n",
      "loss: 0.079722  [108000/198000]\n",
      "loss: 0.078074  [111600/198000]\n",
      "loss: 0.079082  [115200/198000]\n",
      "loss: 0.081143  [118800/198000]\n",
      "loss: 0.080813  [122400/198000]\n",
      "loss: 0.079419  [126000/198000]\n",
      "loss: 0.080757  [129600/198000]\n",
      "loss: 0.082073  [133200/198000]\n",
      "loss: 0.081087  [136800/198000]\n",
      "loss: 0.079763  [140400/198000]\n",
      "loss: 0.080893  [144000/198000]\n",
      "loss: 0.079399  [147600/198000]\n",
      "loss: 0.080438  [151200/198000]\n",
      "loss: 0.081382  [154800/198000]\n",
      "loss: 0.080575  [158400/198000]\n",
      "loss: 0.080903  [162000/198000]\n",
      "loss: 0.077733  [165600/198000]\n",
      "loss: 0.079129  [169200/198000]\n",
      "loss: 0.081512  [172800/198000]\n",
      "loss: 0.078965  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 7.1%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.082193  [    0/198000]\n",
      "loss: 0.079562  [ 3600/198000]\n",
      "loss: 0.079777  [ 7200/198000]\n",
      "loss: 0.083369  [10800/198000]\n",
      "loss: 0.078901  [14400/198000]\n",
      "loss: 0.077588  [18000/198000]\n",
      "loss: 0.082956  [21600/198000]\n",
      "loss: 0.079668  [25200/198000]\n",
      "loss: 0.082990  [28800/198000]\n",
      "loss: 0.082240  [32400/198000]\n",
      "loss: 0.081006  [36000/198000]\n",
      "loss: 0.082465  [39600/198000]\n",
      "loss: 0.080534  [43200/198000]\n",
      "loss: 0.080742  [46800/198000]\n",
      "loss: 0.081884  [50400/198000]\n",
      "loss: 0.078767  [54000/198000]\n",
      "loss: 0.079749  [57600/198000]\n",
      "loss: 0.079376  [61200/198000]\n",
      "loss: 0.080098  [64800/198000]\n",
      "loss: 0.079674  [68400/198000]\n",
      "loss: 0.077324  [72000/198000]\n",
      "loss: 0.077181  [75600/198000]\n",
      "loss: 0.079926  [79200/198000]\n",
      "loss: 0.078745  [82800/198000]\n",
      "loss: 0.080623  [86400/198000]\n",
      "loss: 0.079174  [90000/198000]\n",
      "loss: 0.081006  [93600/198000]\n",
      "loss: 0.080613  [97200/198000]\n",
      "loss: 0.078819  [100800/198000]\n",
      "loss: 0.080910  [104400/198000]\n",
      "loss: 0.082179  [108000/198000]\n",
      "loss: 0.078739  [111600/198000]\n",
      "loss: 0.079103  [115200/198000]\n",
      "loss: 0.077562  [118800/198000]\n",
      "loss: 0.079381  [122400/198000]\n",
      "loss: 0.082219  [126000/198000]\n",
      "loss: 0.079289  [129600/198000]\n",
      "loss: 0.083260  [133200/198000]\n",
      "loss: 0.076921  [136800/198000]\n",
      "loss: 0.082150  [140400/198000]\n",
      "loss: 0.079386  [144000/198000]\n",
      "loss: 0.080263  [147600/198000]\n",
      "loss: 0.078940  [151200/198000]\n",
      "loss: 0.080202  [154800/198000]\n",
      "loss: 0.078228  [158400/198000]\n",
      "loss: 0.081852  [162000/198000]\n",
      "loss: 0.082105  [165600/198000]\n",
      "loss: 0.081371  [169200/198000]\n",
      "loss: 0.080343  [172800/198000]\n",
      "loss: 0.079404  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 7.3%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.079224  [    0/198000]\n",
      "loss: 0.079451  [ 3600/198000]\n",
      "loss: 0.078752  [ 7200/198000]\n",
      "loss: 0.078704  [10800/198000]\n",
      "loss: 0.079574  [14400/198000]\n",
      "loss: 0.080302  [18000/198000]\n",
      "loss: 0.079839  [21600/198000]\n",
      "loss: 0.077435  [25200/198000]\n",
      "loss: 0.080237  [28800/198000]\n",
      "loss: 0.079971  [32400/198000]\n",
      "loss: 0.080076  [36000/198000]\n",
      "loss: 0.080135  [39600/198000]\n",
      "loss: 0.081365  [43200/198000]\n",
      "loss: 0.079468  [46800/198000]\n",
      "loss: 0.080449  [50400/198000]\n",
      "loss: 0.082017  [54000/198000]\n",
      "loss: 0.082082  [57600/198000]\n",
      "loss: 0.080048  [61200/198000]\n",
      "loss: 0.077387  [64800/198000]\n",
      "loss: 0.080076  [68400/198000]\n",
      "loss: 0.079253  [72000/198000]\n",
      "loss: 0.080285  [75600/198000]\n",
      "loss: 0.079860  [79200/198000]\n",
      "loss: 0.079956  [82800/198000]\n",
      "loss: 0.080097  [86400/198000]\n",
      "loss: 0.078864  [90000/198000]\n",
      "loss: 0.081900  [93600/198000]\n",
      "loss: 0.076865  [97200/198000]\n",
      "loss: 0.080190  [100800/198000]\n",
      "loss: 0.077293  [104400/198000]\n",
      "loss: 0.078789  [108000/198000]\n",
      "loss: 0.079443  [111600/198000]\n",
      "loss: 0.079642  [115200/198000]\n",
      "loss: 0.078478  [118800/198000]\n",
      "loss: 0.079893  [122400/198000]\n",
      "loss: 0.078795  [126000/198000]\n",
      "loss: 0.078138  [129600/198000]\n",
      "loss: 0.078265  [133200/198000]\n",
      "loss: 0.078260  [136800/198000]\n",
      "loss: 0.078539  [140400/198000]\n",
      "loss: 0.078268  [144000/198000]\n",
      "loss: 0.081561  [147600/198000]\n",
      "loss: 0.079478  [151200/198000]\n",
      "loss: 0.080154  [154800/198000]\n",
      "loss: 0.078994  [158400/198000]\n",
      "loss: 0.081137  [162000/198000]\n",
      "loss: 0.078695  [165600/198000]\n",
      "loss: 0.079798  [169200/198000]\n",
      "loss: 0.079419  [172800/198000]\n",
      "loss: 0.076276  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 7.5%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.079419  [    0/198000]\n",
      "loss: 0.079466  [ 3600/198000]\n",
      "loss: 0.080528  [ 7200/198000]\n",
      "loss: 0.079633  [10800/198000]\n",
      "loss: 0.080210  [14400/198000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.080140  [18000/198000]\n",
      "loss: 0.078317  [21600/198000]\n",
      "loss: 0.081238  [25200/198000]\n",
      "loss: 0.079434  [28800/198000]\n",
      "loss: 0.077322  [32400/198000]\n",
      "loss: 0.081750  [36000/198000]\n",
      "loss: 0.081580  [39600/198000]\n",
      "loss: 0.077529  [43200/198000]\n",
      "loss: 0.081185  [46800/198000]\n",
      "loss: 0.077687  [50400/198000]\n",
      "loss: 0.079960  [54000/198000]\n",
      "loss: 0.079853  [57600/198000]\n",
      "loss: 0.082005  [61200/198000]\n",
      "loss: 0.077750  [64800/198000]\n",
      "loss: 0.078526  [68400/198000]\n",
      "loss: 0.075843  [72000/198000]\n",
      "loss: 0.080950  [75600/198000]\n",
      "loss: 0.079700  [79200/198000]\n",
      "loss: 0.079852  [82800/198000]\n",
      "loss: 0.076706  [86400/198000]\n",
      "loss: 0.080752  [90000/198000]\n",
      "loss: 0.080651  [93600/198000]\n",
      "loss: 0.079497  [97200/198000]\n",
      "loss: 0.078928  [100800/198000]\n",
      "loss: 0.078621  [104400/198000]\n",
      "loss: 0.080725  [108000/198000]\n",
      "loss: 0.079230  [111600/198000]\n",
      "loss: 0.080912  [115200/198000]\n",
      "loss: 0.082607  [118800/198000]\n",
      "loss: 0.077197  [122400/198000]\n",
      "loss: 0.079104  [126000/198000]\n",
      "loss: 0.079382  [129600/198000]\n",
      "loss: 0.078708  [133200/198000]\n",
      "loss: 0.078892  [136800/198000]\n",
      "loss: 0.079796  [140400/198000]\n",
      "loss: 0.078992  [144000/198000]\n",
      "loss: 0.079677  [147600/198000]\n",
      "loss: 0.080967  [151200/198000]\n",
      "loss: 0.079872  [154800/198000]\n",
      "loss: 0.080343  [158400/198000]\n",
      "loss: 0.080750  [162000/198000]\n",
      "loss: 0.080461  [165600/198000]\n",
      "loss: 0.079470  [169200/198000]\n",
      "loss: 0.078008  [172800/198000]\n",
      "loss: 0.078500  [176400/198000]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 7.7%\n",
      "Test Error: \n",
      " Accuracy phase: -0.0%\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_fn, optimizer)\n",
    "    test(test_loader, model, loss_fn)\n",
    "print(\"Done!\")\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64ac0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de07f9f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f891af1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c00e1038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, './MLPmodel02.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1923e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad17aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16265344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a74bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6a718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f7706a8",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e7fb955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota : Crear datos nuevos gaussianos\n",
    "\n",
    "X1 = np.load(\"../../Data_Gaussian_Test/data0/Wavepacket/10-wave.npy\")\n",
    "X1p = np.load(\"../../Data_Gaussian_Test/data0/Potential/10-potential.npy\")\n",
    "\n",
    "Y1 = np.load(\"../../Data_Gaussian_Test/data0/Wavepacket/11-wave.npy\")\n",
    "\n",
    "\n",
    "X1_t = np.concatenate((X1.real,X1.imag, X1p))\n",
    "Y1_t = np.concatenate((Y1.real, Y1.imag))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f9647625",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model,torch.from_numpy(X1_t).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b86d5426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"360pt\" height=\"802pt\"\n",
       " viewBox=\"0.00 0.00 360.00 802.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 798)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-798 356,-798 356,4 -4,4\"/>\n",
       "<!-- 139882701721216 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139882701721216</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"265.5,-31 211.5,-31 211.5,0 265.5,0 265.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 139882722012944 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139882722012944</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"283,-86 194,-86 194,-67 283,-67 283,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139882722012944&#45;&gt;139882701721216 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>139882722012944&#45;&gt;139882701721216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M238.5,-66.79C238.5,-60.07 238.5,-50.4 238.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"242,-41.19 238.5,-31.19 235,-41.19 242,-41.19\"/>\n",
       "</g>\n",
       "<!-- 139882722009392 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139882722009392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"233,-141 120,-141 120,-122 233,-122 233,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SqueezeBackward3</text>\n",
       "</g>\n",
       "<!-- 139882722009392&#45;&gt;139882722012944 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139882722009392&#45;&gt;139882722012944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M186.46,-121.98C195.63,-114.15 209.44,-102.34 220.53,-92.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.03,-95.33 228.36,-86.17 218.48,-90.01 223.03,-95.33\"/>\n",
       "</g>\n",
       "<!-- 139882722009872 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>139882722009872</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"215,-202 138,-202 138,-183 215,-183 215,-202\"/>\n",
       "<text text-anchor=\"middle\" x=\"176.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139882722009872&#45;&gt;139882722009392 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139882722009872&#45;&gt;139882722009392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M176.5,-182.79C176.5,-174.6 176.5,-162.06 176.5,-151.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180,-151.24 176.5,-141.24 173,-151.24 180,-151.24\"/>\n",
       "</g>\n",
       "<!-- 139882722012704 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>139882722012704</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-263 56,-263 56,-244 181,-244 181,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">UnsqueezeBackward0</text>\n",
       "</g>\n",
       "<!-- 139882722012704&#45;&gt;139882722009872 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>139882722012704&#45;&gt;139882722009872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.06,-243.79C135.88,-234.82 149.84,-220.62 160.68,-209.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"163.39,-211.83 167.91,-202.24 158.4,-206.92 163.39,-211.83\"/>\n",
       "</g>\n",
       "<!-- 139882722010256 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>139882722010256</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"166,-318 71,-318 71,-299 166,-299 166,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139882722010256&#45;&gt;139882722012704 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>139882722010256&#45;&gt;139882722012704</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.5,-298.75C118.5,-291.8 118.5,-281.85 118.5,-273.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122,-273.09 118.5,-263.09 115,-273.09 122,-273.09\"/>\n",
       "</g>\n",
       "<!-- 139882701205808 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>139882701205808</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"166,-379 71,-379 71,-360 166,-360 166,-379\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-367\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139882701205808&#45;&gt;139882722010256 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>139882701205808&#45;&gt;139882722010256</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.5,-359.79C118.5,-351.6 118.5,-339.06 118.5,-328.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122,-328.24 118.5,-318.24 115,-328.24 122,-328.24\"/>\n",
       "</g>\n",
       "<!-- 139882701209264 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>139882701209264</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"166,-440 71,-440 71,-421 166,-421 166,-440\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-428\" font-family=\"monospace\" font-size=\"10.00\">ReluBackward0</text>\n",
       "</g>\n",
       "<!-- 139882701209264&#45;&gt;139882701205808 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>139882701209264&#45;&gt;139882701205808</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.5,-420.79C118.5,-412.6 118.5,-400.06 118.5,-389.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122,-389.24 118.5,-379.24 115,-389.24 122,-389.24\"/>\n",
       "</g>\n",
       "<!-- 139882701205616 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>139882701205616</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"163,-495 74,-495 74,-476 163,-476 163,-495\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-483\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 139882701205616&#45;&gt;139882701209264 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>139882701205616&#45;&gt;139882701209264</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.5,-475.75C118.5,-468.8 118.5,-458.85 118.5,-450.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122,-450.09 118.5,-440.09 115,-450.09 122,-450.09\"/>\n",
       "</g>\n",
       "<!-- 139882701206960 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>139882701206960</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"113,-550 0,-550 0,-531 113,-531 113,-550\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-538\" font-family=\"monospace\" font-size=\"10.00\">SqueezeBackward3</text>\n",
       "</g>\n",
       "<!-- 139882701206960&#45;&gt;139882701205616 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>139882701206960&#45;&gt;139882701205616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M66.46,-530.98C75.63,-523.15 89.44,-511.34 100.53,-501.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"103.03,-504.33 108.36,-495.17 98.48,-499.01 103.03,-504.33\"/>\n",
       "</g>\n",
       "<!-- 139882722990400 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>139882722990400</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"95,-611 18,-611 18,-592 95,-592 95,-611\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-599\" font-family=\"monospace\" font-size=\"10.00\">MmBackward</text>\n",
       "</g>\n",
       "<!-- 139882722990400&#45;&gt;139882701206960 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>139882722990400&#45;&gt;139882701206960</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.5,-591.79C56.5,-583.6 56.5,-571.06 56.5,-560.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60,-560.24 56.5,-550.24 53,-560.24 60,-560.24\"/>\n",
       "</g>\n",
       "<!-- 139882722989488 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>139882722989488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"92,-672 21,-672 21,-653 92,-653 92,-672\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-660\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139882722989488&#45;&gt;139882722990400 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>139882722989488&#45;&gt;139882722990400</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.5,-652.79C56.5,-644.6 56.5,-632.06 56.5,-621.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60,-621.24 56.5,-611.24 53,-621.24 60,-621.24\"/>\n",
       "</g>\n",
       "<!-- 139882722991216 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>139882722991216</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"107,-727 6,-727 6,-708 107,-708 107,-727\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-715\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139882722991216&#45;&gt;139882722989488 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>139882722991216&#45;&gt;139882722989488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.5,-707.75C56.5,-700.8 56.5,-690.85 56.5,-682.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60,-682.09 56.5,-672.09 53,-682.09 60,-682.09\"/>\n",
       "</g>\n",
       "<!-- 139882694670080 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>139882694670080</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"98,-794 15,-794 15,-763 98,-763 98,-794\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.5\" y=\"-770\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 96)</text>\n",
       "</g>\n",
       "<!-- 139882694670080&#45;&gt;139882722991216 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>139882694670080&#45;&gt;139882722991216</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.5,-762.92C56.5,-755.22 56.5,-745.69 56.5,-737.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"60,-737.25 56.5,-727.25 53,-737.25 60,-737.25\"/>\n",
       "</g>\n",
       "<!-- 139882722989152 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>139882722989152</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"232,-550 131,-550 131,-531 232,-531 232,-550\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-538\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139882722989152&#45;&gt;139882701205616 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>139882722989152&#45;&gt;139882701205616</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M171.38,-530.98C162.06,-523.15 148.03,-511.34 136.76,-501.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"138.71,-498.93 128.81,-495.17 134.21,-504.29 138.71,-498.93\"/>\n",
       "</g>\n",
       "<!-- 139882694668864 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>139882694668864</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"211,-617 152,-617 152,-586 211,-586 211,-617\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-593\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 139882694668864&#45;&gt;139882722989152 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>139882694668864&#45;&gt;139882722989152</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.5,-585.92C181.5,-578.22 181.5,-568.69 181.5,-560.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"185,-560.25 181.5,-550.25 178,-560.25 185,-560.25\"/>\n",
       "</g>\n",
       "<!-- 139882722010112 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>139882722010112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"270,-263 199,-263 199,-244 270,-244 270,-263\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\">TBackward</text>\n",
       "</g>\n",
       "<!-- 139882722010112&#45;&gt;139882722009872 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>139882722010112&#45;&gt;139882722009872</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M225.94,-243.79C217.12,-234.82 203.16,-220.62 192.32,-209.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"194.6,-206.92 185.09,-202.24 189.61,-211.83 194.6,-206.92\"/>\n",
       "</g>\n",
       "<!-- 139882701209312 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>139882701209312</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"285,-318 184,-318 184,-299 285,-299 285,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139882701209312&#45;&gt;139882722010112 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>139882701209312&#45;&gt;139882722010112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.5,-298.75C234.5,-291.8 234.5,-281.85 234.5,-273.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238,-273.09 234.5,-263.09 231,-273.09 238,-273.09\"/>\n",
       "</g>\n",
       "<!-- 139885141941888 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>139885141941888</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"276,-385 193,-385 193,-354 276,-354 276,-385\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\"> (64, 1024)</text>\n",
       "</g>\n",
       "<!-- 139885141941888&#45;&gt;139882701209312 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>139885141941888&#45;&gt;139882701209312</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M234.5,-353.92C234.5,-346.22 234.5,-336.69 234.5,-328.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"238,-328.25 234.5,-318.25 231,-328.25 238,-328.25\"/>\n",
       "</g>\n",
       "<!-- 139882722011648 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>139882722011648</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"352,-141 251,-141 251,-122 352,-122 352,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 139882722011648&#45;&gt;139882722012944 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>139882722011648&#45;&gt;139882722012944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M291.38,-121.98C282.06,-114.15 268.03,-102.34 256.76,-92.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"258.71,-89.93 248.81,-86.17 254.21,-95.29 258.71,-89.93\"/>\n",
       "</g>\n",
       "<!-- 139882694400128 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>139882694400128</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"328.5,-208 274.5,-208 274.5,-177 328.5,-177 328.5,-208\"/>\n",
       "<text text-anchor=\"middle\" x=\"301.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (64)</text>\n",
       "</g>\n",
       "<!-- 139882694400128&#45;&gt;139882722011648 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>139882694400128&#45;&gt;139882722011648</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M301.5,-176.92C301.5,-169.22 301.5,-159.69 301.5,-151.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"305,-151.25 301.5,-141.25 298,-151.25 305,-151.25\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f38fbf4a880>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchviz import make_dot\n",
    "out = model(torch.from_numpy(X1_t).float())\n",
    "make_dot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7b68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e58c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred = model(torch.from_numpy(X1_t).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a0f68ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0056,  0.0172,  0.0091, -0.0112,  0.0023,  0.0195,  0.0035, -0.0099,\n",
       "        -0.0081,  0.0352,  0.0209,  0.0314,  0.0076, -0.0359, -0.0445, -0.1610,\n",
       "        -0.2585, -0.3411, -0.2917, -0.0036,  0.2094,  0.2336,  0.1122,  0.0562,\n",
       "         0.0162,  0.0264, -0.0260, -0.0270, -0.0019,  0.0219, -0.0126, -0.0049],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred[0:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a3ade3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e7ebd807",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_r = [-0.0056,  0.0172,  0.0091, -0.0112,  0.0023,  0.0195,  0.0035, -0.0099,\n",
    "        -0.0081,  0.0352,  0.0209,  0.0314,  0.0076, -0.0359, -0.0445, -0.1610,\n",
    "        -0.2585, -0.3411, -0.2917, -0.0036,  0.2094,  0.2336,  0.1122,  0.0562,\n",
    "         0.0162,  0.0264, -0.0260, -0.0270, -0.0019,  0.0219, -0.0126, -0.0049]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5939e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_r = np.array(y1_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b742ba5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(r\"$\\Psi(r,t)$\")\n",
    "ax.set_xlabel('Position ($\\AA$)')\n",
    "ax.set_ylabel('$\\Psi(r,t)$')\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "#ax.plot(r_n, X1.real, label=\"$\\Psi_{real}(r, t=0)_{generate}$\")\n",
    "ax.plot(r_n, Y1.real, label=\"$\\Psi_{real}(r, t=1)_{true}$\")\n",
    "\n",
    "ax.plot(r_n, y1_r, label=\"$\\Psi_{real}(r, t=1)_{ANN}$\")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b6cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe375c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
